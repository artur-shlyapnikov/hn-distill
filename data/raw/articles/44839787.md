Title: AI industry horrified to face largest copyright class action ever certified

URL Source: https://arstechnica.com/tech-policy/2025/08/ai-industry-horrified-to-face-largest-copyright-class-action-ever-certified/

Published Time: 2025-08-08T17:44:05+00:00

Markdown Content:
AI industry horrified to face largest copyright class action ever certified - Ars Technica

===============

Manage your consent preferences

If you are a resident of California, Colorado, Connecticut, Virginia, Utah, Oregon, Texas, Montana, Delaware, Iowa, Nebraska, New Hampshire, and New Jersey, Tennessee, or Minnesota you have the right to opt-out of Targeted Advertising, including our “sale” and/or “sharing” of your Personal Information (“Opt-Out”). We and our third-party business partners use Personal Information in accordance with our [Privacy Policy](https://www.condenast.com/privacy-policy) to serve advertising believed to be of interest to you (“Targeted Advertising”). If you are a California resident, you also have the right to limit the use and disclosure of your Sensitive Personal information in particular circumstances. Please note that you may need to Opt-Out on each website, mobile app, browser, and device you use, and if you clear your browser cookies, you may need to repeat this process. However, if you have created an account to log in across several of our websites and/or mobile apps, we will make reasonable efforts to apply your Opt-Out request to each of those websites and apps. ◦ To Opt-Out of Targeted Advertising on this site: Move the “Allow Targeted Advertising" toggle below to the left and press “Confirm My Choices”◦ To Opt-Out of other “sales”, including for list rentals, data co-ops, and to limit the use and disclosure of your Sensitive Personal Information:
Please provide information on the [privacy center](https://privacy.condenastdigital.com/) and press “submit.” You can also submit this request by calling 1-877-241-4999. This information will not be used or disclosed for any purpose other than for processing this request.

Performance

- [x] On

These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.

* * *

Functional

- [x] On

This website uses functional cookies and services to remember your preferences and choices, such as language preferences, font sizes, region selections, and customized layouts. They enable this website to offer enhanced and personalized functionalities.

* * *

Audience Measurement

- [x] On

We use audience measurement cookies in order to carry out aggregated traffic measurement and generate performance statistics essential for the proper functioning of the site and the provision of its content (for example to measure performance, to detect navigation problems, to optimization technical performance or ergonomics, to estimate server power needed and to analyse content performance). The use of these cookies is strictly limited to measuring the site's audience. These cookies do not allow the tracking of navigation on other websites and the data collected is not combined or shared with third parties. You can refuse the use of this cookie by switching off the slider to the right.

* * *

Essential

- [x] On

These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.

* * *

Allow targeted advertising?

- [x] On

We may transfer or share your personal information to third parties for the purposes of targeted advertising. You can learn more about what information is used for this purpose in our privacy notice.

Confirm My Choices Reject All Accept All

[Privacy Policy](https://www.condenast.com/privacy-policy)

[Powered by](https://ethyca.com/)

[Skip to content](https://arstechnica.com/tech-policy/2025/08/ai-industry-horrified-to-face-largest-copyright-class-action-ever-certified/#main)[Ars Technica home](https://arstechnica.com/)

 Sections 

[Forum](https://arstechnica.com/civis/)[Subscribe](https://arstechnica.com/subscribe/)[Search](https://arstechnica.com/search/)

*   [AI](https://arstechnica.com/ai/)
*   [Biz & IT](https://arstechnica.com/information-technology/)
*   [Cars](https://arstechnica.com/cars/)
*   [Culture](https://arstechnica.com/culture/)
*   [Gaming](https://arstechnica.com/gaming/)
*   [Health](https://arstechnica.com/health/)
*   [Policy](https://arstechnica.com/tech-policy/)
*   [Science](https://arstechnica.com/science/)
*   [Security](https://arstechnica.com/security/)
*   [Space](https://arstechnica.com/space/)
*   [Tech](https://arstechnica.com/gadgets/)

*   [Feature](https://arstechnica.com/features/)
*   [Reviews](https://arstechnica.com/reviews/)

*   [AI](https://arstechnica.com/ai/)
*   [Biz & IT](https://arstechnica.com/information-technology/)
*   [Cars](https://arstechnica.com/cars/)
*   [Culture](https://arstechnica.com/culture/)
*   [Gaming](https://arstechnica.com/gaming/)
*   [Health](https://arstechnica.com/health/)
*   [Policy](https://arstechnica.com/tech-policy/)
*   [Science](https://arstechnica.com/science/)
*   [Security](https://arstechnica.com/security/)
*   [Space](https://arstechnica.com/space/)
*   [Tech](https://arstechnica.com/gadgets/)

[Forum](https://arstechnica.com/civis/)[Subscribe](https://arstechnica.com/subscribe/)

Story text

Size Width * Links 

* Subscribers only

[Learn more](https://arstechnica.com/store/product/subscriptions/)

 Pin to story 

Theme

*    HyperLight 
*    Day & Night 
*    Dark 
*    System 

 Search dialog... 

 Sign In 

 Sign in dialog... 

 Sign in 

 Judging books by their covers? 

AI industry horrified to face largest copyright class action ever certified
===========================================================================

Copyright class actions could financially ruin AI industry, trade groups say.

[Ashley Belanger](https://arstechnica.com/author/ashleybelanger/) – Aug 8, 2025 5:44 PM|[11](https://arstechnica.com/tech-policy/2025/08/ai-industry-horrified-to-face-largest-copyright-class-action-ever-certified/#comments "11 comments")

[](https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-165852910.jpg)

 Credit: [monap | E+](https://www.gettyimages.com/detail/photo/lots-of-books-royalty-free-image/165852910?phrase=pile%20of%20books&searchscope=image,film&adppopup=true)

 Credit: [monap | E+](https://www.gettyimages.com/detail/photo/lots-of-books-royalty-free-image/165852910?phrase=pile%20of%20books&searchscope=image,film&adppopup=true)

Text settings

Story text

Size Width * Links 

* Subscribers only

[Learn more](https://arstechnica.com/store/product/subscriptions/)

 Minimize to nav 

[](https://arstechnica.com/tech-policy/2025/08/ai-industry-horrified-to-face-largest-copyright-class-action-ever-certified/)

AI industry groups are urging an appeals court to block what they say is the largest copyright class action ever certified. They've warned that a single lawsuit raised by three authors over Anthropic's AI training now threatens to "financially ruin" the entire AI industry if up to 7 million claimants end up joining the litigation and forcing a settlement.

Last week, Anthropic [petitioned](https://storage.courtlistener.com/recap/gov.uscourts.ca9.8d0d59a1-7a6e-f011-a2d9-001dd80ea460/gov.uscourts.ca9.8d0d59a1-7a6e-f011-a2d9-001dd80ea460.1.0.pdf) to appeal the class certification, urging the court to weigh questions that the district court judge, William Alsup, seemingly did not. Alsup allegedly failed to conduct a "rigorous analysis" of the potential class and instead based his judgment on his "50 years" of experience, Anthropic said.

If the appeals court denies the petition, Anthropic argued, the emerging company may be doomed. As Anthropic argued, it now "faces hundreds of billions of dollars in potential damages liability at trial in four months" based on a class certification rushed at "warp speed" that involves "up to seven million potential claimants, whose works span a century of publishing history," each possibly triggering a $150,000 fine.

Confronted with such extreme potential damages, Anthropic may lose its rights to raise valid defenses of its AI training, deciding it would be more prudent to settle, the company argued. And that could set an alarming precedent, considering all the other lawsuits generative AI (GenAI) companies face over training on copyrighted materials, Anthropic argued.

"One district court's errors should not be allowed to decide the fate of a transformational GenAI company like Anthropic or so heavily influence the future of the GenAI industry generally," Anthropic wrote. "This Court can and should intervene now."

### Ars Video

[### How Scientists Respond to Science Deniers](https://www.arstechnica.com/video/watch/how-scientists-respond-to-science-deniers)

In a court [filing](https://ccianet.org/library/amicus-brief-of-technet-ccia-et-al-in-bartz-v-anthopic-9th-cir/) Thursday, the Consumer Technology Association and the Computer and Communications Industry Association backed Anthropic, warning the appeals court that "the district court’s erroneous class certification" would threaten "immense harm not only to a single AI company, but to the entire fledgling AI industry and to America’s global technological competitiveness."

According to the groups, allowing copyright class actions in AI training cases will result in a future where copyright questions remain unresolved and the risk of "emboldened" claimants forcing enormous settlements will chill investments in AI.

"Such potential liability in this case exerts incredibly coercive settlement pressure for Anthropic," industry groups argued, concluding that "as generative AI begins to shape the trajectory of the global economy, the technology industry cannot withstand such devastating litigation. The United States currently may be the global leader in AI development, but that could change if litigation stymies investment by imposing excessive damages on AI companies."

Some authors won’t benefit from class actions
---------------------------------------------

Industry groups joined Anthropic in arguing that, generally, copyright suits are considered a bad fit for class actions because each individual author must prove ownership of their works. And the groups weren't alone.

Also backing Anthropic's appeal, advocates representing authors—including Authors Alliance, the Electronic Frontier Foundation, American Library Association, Association of Research Libraries, and Public Knowledge—[pointed out](https://storage.courtlistener.com/recap/gov.uscourts.ca9.8d0d59a1-7a6e-f011-a2d9-001dd80ea460/gov.uscourts.ca9.8d0d59a1-7a6e-f011-a2d9-001dd80ea460.8.1.pdf) that the Google Books case showed that proving ownership is anything but straightforward.

[](https://arstechnica.com/tech-policy/2025/08/ai-industry-horrified-to-face-largest-copyright-class-action-ever-certified/)

In the Anthropic case, advocates for authors criticized Alsup for basically judging all 7 million books in the lawsuit by their covers. The judge allegedly made "almost no meaningful inquiry into who the actual members are likely to be," as well as "no analysis of what types of books are included in the class, who authored them, what kinds of licenses are likely to apply to those works, what the rightsholders’ interests might be, or whether they are likely to support the class representatives’ positions."

Ignoring "decades of research, multiple bills in Congress, and numerous studies from the US Copyright Office attempting to address the challenges of determining rights across a vast number of books," the district court seemed to expect that authors and publishers would easily be able to "work out the best way to recover" damages.

But it's never easy, groups said. Consider, for example, how now-defunct publishers might add a wrinkle to ownership questions with some books involved in the litigation. Or how rightsholders might be affected if they only own a portion of a work, like a chapter or inserts in academic texts. The district court apparently didn't even consider "what will be done with authors who are dead and whose literary estates hold rights split across multiple parties." There are also many so-called "orphan works," where "identifying rightsholders to address ownership questions will be impossible." If the class action moves forward, groups warned that the court may have to review "hundreds of mini-trials to sort out these issues."

Further, some authors may never even find out the lawsuit is happening. The court's suggested notification scheme "would require class claimants to themselves notify other potential rightsholders," groups said, overlooking the fact that it cost Google $34.5 million "to set up a 'Books Rights Registry' to identify owners for payouts under the proposed settlement" in one of the largest cases involving book authors prior to the AI avalanche of lawsuits.

Additionally concerning, the court suggested that it was acceptable to certify the massive class because any authors who did not want to join could opt out. But groups warned that a lackadaisical approach put authors who may never hear about the lawsuit—and perhaps would have litigated their claims differently—in a difficult position, therefore serving as "an inadequate answer to a fundamental fairness problem in the formulation of the class and the due process concerns of absent class members."

Some authors and publishers are "already at odds over AI," which may further complicate these cases, if one side representing legal owners (usually publishers) wants to join but beneficial owners (usually authors) don't.

Simply put, "there is no realistic pathway to resolving these issues in a common way," advocates said, despite the district court seeing a common question in Anthropic downloading all their books. And authors ultimately risk sustaining the cloud of uncertainty over AI training on copyrighted materials by seeking a path likely to force settlements.

"This case is of exceptional importance, addressing the legality of using copyrighted works" for generative AI, "a transformative technology used by hundreds of millions of researchers, authors, and others," groups argued. "The district court’s rushed decision to certify the class represents a 'death knell' scenario that will mean important issues affecting the rights of millions of authors with respect to AI will never be adequately resolved."

[](https://arstechnica.com/author/ashleybelanger/)

[Ashley Belanger](https://arstechnica.com/author/ashleybelanger/)Senior Policy Reporter

[Ashley Belanger](https://arstechnica.com/author/ashleybelanger/)Senior Policy Reporter

 Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience. 

[11 Comments](https://arstechnica.com/tech-policy/2025/08/ai-industry-horrified-to-face-largest-copyright-class-action-ever-certified/#comments "11 comments")

 Comments 

[Forum view](https://arstechnica.com/civis/threads/ai-industry-horrified-to-face-largest-copyright-class-action-ever-certified.1508756/)

 Loading comments... 

[Prev story](https://arstechnica.com/ai/2025/08/chatgpt-users-outraged-as-gpt-5-replaces-the-models-they-love/ "Go to: ChatGPT users hate GPT-5’s “overworked secretary” energy, miss their GPT-4o buddy")

 Most Read

1.   [](https://arstechnica.com/health/2025/08/after-using-chatgpt-man-swaps-his-salt-for-sodium-bromide-and-suffers-psychosis/) 1.[After using ChatGPT, man swaps his salt for sodium bromide—and suffers psychosis](https://arstechnica.com/health/2025/08/after-using-chatgpt-man-swaps-his-salt-for-sodium-bromide-and-suffers-psychosis/) 
2.    2.[New executive order puts all grants under political control](https://arstechnica.com/science/2025/08/new-executive-order-puts-all-grants-under-political-control/) 
3.    3.[Trump wanted a US-made iPhone. Apple gave him a gold statue.](https://arstechnica.com/tech-policy/2025/08/trump-wanted-a-us-made-iphone-apple-gave-him-a-gold-statue/) 
4.    4.[OpenAI launches GPT-5 free to all ChatGPT users](https://arstechnica.com/ai/2025/08/openai-launches-gpt-5-free-to-all-chatgpt-users/) 
5.    5.[RFK Jr. defends $500M cut for mRNA vaccines with pseudoscience gobbledygook](https://arstechnica.com/health/2025/08/rfk-jr-defends-500m-cut-for-mrna-vaccines-with-pseudoscience-gobbledygook/) 

Customize

Ars Technica has been separating the signal from the noise for over 25 years. With our unique combination of technical savvy and wide-ranging interest in the technological arts and sciences, Ars is the trusted source in a sea of information. After all, you don’t need to know everything, only what’s important.

[](https://bsky.app/profile/arstechnica.com)[](https://mastodon.social/@arstechnica)[](https://www.facebook.com/arstechnica)[](https://www.youtube.com/@arstechnica)[](https://www.instagram.com/arstechnica/)

More from Ars 
*   [About Us](https://arstechnica.com/about-us/)
*   [Staff Directory](https://arstechnica.com/staff-directory/)
*   [Newsletters](https://arstechnica.com/newsletters/)
*   [General FAQ](https://arstechnica.com/general-faq/)
*   [Posting Guidelines](https://arstechnica.com/ars-technica-posting-guidelines-v3-0/)
*   [RSS Feeds](https://arstechnica.com/rss-feeds/)

Contact
*   [Contact us](https://arstechnica.com/contact-us/)
*   [Advertise with us](mailto:adinquiries@condenast.com)
*   [Reprints](https://arstechnica.com/reprints/)

 Manage Preferences 

 © 2025 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our [User Agreement](https://www.condenast.com/user-agreement/) and [Privacy Policy and Cookie Statement](https://www.condenast.com/privacy-policy/) and [Ars Technica Addendum](https://arstechnica.com/amendment-to-conde-nast-user-agreement-privacy-policy/) and [Your California Privacy Rights](https://www.condenast.com/privacy-policy/#california). Ars Technica may earn compensation on sales from links on this site. [Read our affiliate link policy](https://arstechnica.com/affiliate-link-policy/). The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. [Ad Choices](https://www.aboutads.info/)

 Search dialog... 

 Sign in dialog... 

 Sign in 

×