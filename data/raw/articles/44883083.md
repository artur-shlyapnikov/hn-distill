Scapegoating the Algorithm—Asterisk                            

*   [Current Issue](https://asteriskmag.com)
*   [All Issues](https://asteriskmag.com/issues)
*   [All Articles](https://asteriskmag.com/articles)
*   [Contributors](https://asteriskmag.com/contributors)
*   [About](https://asteriskmag.com/about)
*   [Print Subscriptions](https://store.asteriskmag.com)
*   [Support Us](https://donorbox.org/asterisk-fundraising)

©2025 Asterisk Magazine [Privacy Policy](/privacy/)

[![Issue Asterisk Logo](https://asteriskmag.com/media/pages/issues/11/1c8be2ae66-1752593941/asterisk_marks_5.svg)](https://asteriskmag.com)

![](https://asteriskmag.com/assets/img/asterisk_mark.png "save highlight") 

![](https://asteriskmag.com/assets/img/asterisk_x.png "remove highlight") 

# Scapegoating the Algorithm

## Dan Williams

America’s epistemic challenges run deeper than social media.

Many people sense that the United States is undergoing an [epistemic crisis](https://www.theatlantic.com/ideas/archive/2020/11/why-obama-fears-for-our-democracy/617087/?utm_source=newsletter&utm_medium=email&utm_campaign=atlantic-daily-newsletter&utm_content=20201116&silverid-ref=MzM1MDQ4NjU4NTk5S0), a breakdown in the country’s collective capacity to agree on basic facts, distinguish truth from falsehood, and adhere to norms of rational debate. 

This crisis encompasses many things: rampant political lies; misinformation; and conspiracy theories; widespread beliefs in demonstrable falsehoods (“[misperceptions](https://www.aeaweb.org/articles?id=10.1257/jep.34.3.220)”); intense [polarization](https://www.science.org/doi/10.1126/science.abe1715) in [preferred information sources](https://www.pewresearch.org/journalism/2025/06/10/the-political-gap-in-americans-news-sources/); and collapsing trust in institutions meant to uphold basic standards of truth and evidence (such as [science](https://www.pewresearch.org/science/2023/11/14/americans-trust-in-scientists-positive-views-of-science-continue-to-decline/), [universities](https://www.forbes.com/sites/michaeltnietzel/2024/07/09/americans-confidence-in-higher-education-drops-again-finds-gallup/), [professional journalism](https://news.gallup.com/poll/651977/americans-trust-media-remains-trend-low.aspx), and [public health agencies](https://www.independent.co.uk/news/health/fda-cdc-vaccine-covid-poll-b2745701.html)). 

According to survey data, over 60% of Republicans [believe](https://edition.cnn.com/2023/08/03/politics/cnn-poll-republicans-think-2020-election-illegitimate/index.html) Joe Biden’s presidency was illegitimate. 20% of Americans [think](https://news.gallup.com/poll/648308/far-fewer-regard-childhood-vaccinations-important.aspx?utm_source=twitter&utm_medium=o_social&utm_term=gallup&utm_campaign=x-news-vaccines_080824) vaccines are more dangerous than the diseases they prevent, and 36% [think](https://www.pewresearch.org/science/2023/05/16/what-americans-think-about-covid-19-vaccines/) the specific risks of COVID-19 vaccines outweigh their benefits. Only 31% of Americans [have](https://news.gallup.com/poll/651977/americans-trust-media-remains-trend-low.aspx) at least a “fair amount” of confidence in mainstream media, while a record-high 36% have no trust at all. 

What is driving these problems? One influential narrative blames social media platforms like Facebook, Twitter (now X), and YouTube. In the most extreme form of this narrative, such platforms are depicted as technological wrecking balls responsible for [shattering](https://www.theatlantic.com/magazine/archive/2022/05/social-media-democracy-trust-babel/629369/) the norms and institutions that kept citizens tethered to a shared reality, creating an informational Wild West dominated by viral falsehoods, bias-confirming echo chambers, and know-nothing punditry.

The timing is certainly suspicious. Facebook launched in 2004, YouTube in 2005, and Twitter in 2006. As they and other platforms acquired hundreds of millions of users over the next decade, the health of American democracy and its public sphere deteriorated. By 2016, when Donald Trump was first elected president, many experts were writing about a new “[post-truth](https://mitpress.mit.edu/9780262535045/post-truth/)” or “[misinformation](https://yalebooks.co.uk/book/9780300251852/the-misinformation-age/)” age. 

Moreover, the fundamental architecture of social media platforms seems hostile to rational discourse. Algorithms that recommend content prioritize [engagement](https://knightcolumbia.org/content/engagement-user-satisfaction-and-the-amplification-of-divisive-content-on-social-media) over accuracy. This can amplify sensational and polarizing material or bias-confirming content, which can drag users into [filter bubbles](https://en.wikipedia.org/wiki/Filter_bubble). Meanwhile, the absence of traditional gatekeepers means that influencers with no expertise or ethical scruples can reach vast audiences. 

The dangerous consequences of these problems seem obvious to many casual observers of social media. And some scientific research corroborates this widespread impression. For example, a [systematic review](https://www.nature.com/articles/s41562-022-01460-1) of nearly five hundred studies finds suggestive evidence for a link between digital media use and declining political trust, increasing populism, and growing polarization. Evidence also consistently [shows](https://pmc.ncbi.nlm.nih.gov/articles/PMC8262430/) an association between social media use and beliefs in conspiracy theories and misinformation. 

But there are compelling reasons to be skeptical that social media is a leading cause of America’s epistemic challenges. The “wrecking ball” narrative exaggerates the novelty of these challenges, overstates social media’s responsibility for them, and overlooks deeper political and institutional problems that are reflected on social media, not created by it.

The platforms are not harmless. They may accelerate worrying trends, amplify fringe voices, and facilitate radicalization. However, the current balance of evidence suggests that the most consequential drivers of America’s large-scale epistemic challenges run much deeper than algorithms. 

## America’s long epistemic struggles

To evaluate whether social media is responsible for America’s epistemic crisis, we must first clarify what that crisis is. And here, it is essential to note that many of America’s epistemic challenges are not new. Problems such as political ignorance, conspiracy theories, propaganda, and bitter intergroup conflict have plagued the country throughout its history. 

Research in political science has consistently [documented](https://www.sup.org/books/law/democracy-and-political-ignorance) astonishingly high rates of political ignorance among American voters. A landmark [1964 study](https://www.tandfonline.com/doi/abs/10.1080/08913810608443650) found that most voters were unaware of basic political facts, estimating that roughly 70% were unable to identify which party controlled Congress**.** Similarly, from the Salem witch trials in the late seventeenth century to the widespread [Satanic panic](https://www.amazon.co.uk/Status-Game-Will-Storr/dp/0008354634) of the late twentieth century, false rumors, misinformation, and widespread misperceptions have been [ubiquitous](https://www.conspicuouscognition.com/p/why-do-people-believe-true-things) throughout American history. As political scientist Brendan Nyhan [writes](https://www.aeaweb.org/articles?id=10.1257/jep.34.3.220), there was never a “golden age in which political debate was based on facts and truth,” and “no systematic evidence exists to demonstrate that the prevalence of misperceptions today (while worrisome) is worse than in the past.”

Political polarization and vicious intergroup conflict have been more intense at previous stages in American history, not least during the Civil War. Although there was little polarization between the parties in the mid-twentieth century, this was a historical anomaly. It was also partially due to the parties’ [shared interests](https://en.wikipedia.org/wiki/Why_We're_Polarized) in upholding a system of racial apartheid in the South. This system was, in turn, supported by [widespread lies, racist myths, and censorship](https://academic.oup.com/book/5106/chapter/147688449), from “scientific” racism painting Black people as inferior to the suppression of anti-lynching journalism. 

Elite-driven disinformation has also been a pervasive force throughout American history. Both the tobacco and fossil fuel industries waged [sophisticated propaganda campaigns](https://www.bloomsbury.com/uk/merchants-of-doubt-9781408824832/) to deny the harms caused by their products. McCarthyism involved systematic political repression based on largely fabricated communist threats. And there is nothing new about catastrophic, elite-driven epistemic failures, including their role in events as recent as the Iraq War and the 2007-08 financial crisis. 

Perhaps most surprisingly, there is little evidence to suggest that rates of conspiracy theorizing have increased in prevalence in the social media age. In a recent [study](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0270429), political scientist Joe Uscinski and colleagues conducted four separate analyses to test for possible changes over time. They conclude: “In no instance do we observe systematic evidence for an increase in conspiracism, however operationalized.” 

Today, many are reasonably worried about the dangers demagoguery and populism pose to American democracy. However, these forces have always posed profound political challenges. Nearly 2,000 years before the emergence of the printing press, Plato argued that democracy inevitably leads to tyranny by elevating demagogues who are skilled at catering to voters’ prejudices.

Of course, these observations do not disprove the hypothesis that social media has exacerbated America’s epistemic challenges in recent years. Nevertheless, they serve to remind us that many of the problems attributed to social media can arise (and have historically arisen) in the absence of social media.

Moreover, such observations should encourage us to be more specific about the nature of these problems. To the extent that we lack systematic evidence that issues such as political ignorance, misperceptions, and conspiracism in the mass public are worse today than in the past, what is new about America’s current epistemic crisis? 

At least relative to several decades ago, three developments stand out. First, rates of political polarization are incredibly high. Second, rates of institutional trust are low and seem to be falling. And third, even if there is little evidence that misperceptions and conspiracy theorizing are more prevalent among the mass public, they seem to play a far more consequential role among political elites, not least in the figure of Donald Trump.  

 To what extent can social media be blamed for such developments? 

![](https://asteriskmag.com/media/pages/issues/11/scapegoating-the-algorithm/6aa2b099ab-1752695825/williams_1.png)

“The Yellow Press,” by L. M. Glackens, portrays William Randolph Hearst as a jester distributing sensational stories. Published October 12, 1910. Courtesy the Library of Congress.

## The deep roots of political polarization

Begin with polarization. Although the scientific literature on political polarization and its causes is highly complex and evolving, there is [scholarly consensus](https://www.science.org/doi/10.1126/science.abe1715) that the unusually low polarization of the mid-twentieth century began to decay decades before the advent of social media. 

After the Democratic Party embraced civil rights and the Republican Party pursued a “Southern Strategy” to appeal to white voters opposed to racial integration, American politics entered a period of political realignment that has created more internally consistent and differentiated political coalitions. As political scientist Lilliana Mason and others have [documented](https://press.uchicago.edu/ucp/books/book/chicago/U/bo27527354.html), this process of realignment and social sorting has increasingly transformed partisanship into a “mega-identity” that encompasses a wide range of other identities and characteristics, including race, religion, geography, and even personality traits. 

The emergence of a thriving partisan media ecosystem exacerbated this trend of increasing polarization. But this, too, predates the internet and social media: it’s typically [traced](https://academic.oup.com/book/26406) to the Reagan administration’s 1987 termination of the “fairness doctrine,” which had required broadcasters to discuss controversial topics in an unbiased manner. Famously, Rush Limbaugh’s enormously influential conservative radio program was nationally syndicated the following year. The next decade then saw the emergence of cable news like MSNBC and Fox News. 

Of course, social media plays a large and [growing](https://reutersinstitute.politics.ox.ac.uk/digital-news-report/2025) role within this partisan media ecosystem. Nevertheless, there are several reasons for thinking its impact is smaller than is often assumed. 

First, it is easy to forget that most Americans still consume vast amounts of political information through traditional media channels, such as television, radio, and print. For example, Fox News remains by far the [most prominent](https://www.pewresearch.org/journalism/2025/06/10/the-political-gap-in-americans-news-sources/) source of news for Republicans and Independents who lean Republican, with 57% saying they regularly get news from the cable network. The next most popular, ABC News, is at 27%. Among Democrats, traditional news sources are even more dominant. 

Second, one landmark 2017 [study](https://www.pnas.org/doi/10.1073/pnas.1706588114) led by Levi Boxell found that rates of polarization between 1996 and 2016 had increased the most among older Americans, the group least likely to use social media. 

Third, polarization has moved in different directions in countries with similar rates of social media use. A recent [study](https://direct.mit.edu/rest/article/106/2/557/109262/Cross-Country-Trends-in-Affective-Polarization) also led by Boxell measured affective polarization (roughly, negative feelings towards opposing political parties) over the past four decades in twelve OECD countries. The United States experienced the largest increase in a trend that began decades before the advent of social media. However, half of the countries underwent a decrease in affective polarization during that time, including during the emergence of widespread social media use. 

![](https://asteriskmag.com/media/pages/issues/11/scapegoating-the-algorithm/2583e3bff5-1752695856/williams_2.png)

“The fin de siècle newspaper proprietor,” by  Frederick Burr Opper. Published March 7, 1984. Courtesy the Library of Congress.

## Asymmetric polarization

It is also important to note that a focus on polarization obscures a feature of America’s epistemic challenges that sits uneasily with the “wrecking ball” narrative: just as social media cannot explain why countries with similar rates of social media use are experiencing very different political trends and outcomes, it also struggles to explain why America’s epistemic challenges are overwhelmingly concentrated on the political right.

Of course, this does not mean that there are no problems with the information environment favoured by liberals. Research suggests that tendencies towards politically motivated reasoning are [equally prominent](https://psycnet.apa.org/record/2019-13382-009) among conservatives and liberals, and baseless [conspiracy theories](https://pmc.ncbi.nlm.nih.gov/articles/PMC9307120/%23:~:text=Finally,%2520several%2520studies%2520find%2520that,a%2520counterweight%2520showing%2520the%2520opposite.), [political propaganda](https://www.conspicuouscognition.com/p/bidens-age-and-the-problem-with-the), and [media bias](https://www.astralcodexten.com/p/the-media-very-rarely-lies) exist on both sides. For example, conservatives could reasonably point to the [coverage](https://www.conspicuouscognition.com/p/bidens-age-and-the-problem-with-the) (or conspicuous absence of coverage) of Joe Biden’s cognitive decline as a prominent example of propaganda and media bias on the left. 

Nevertheless, a considerable body of empirical research [suggests](https://academic.oup.com/book/26406) that the most acute epistemic challenges the country confronts today are concentrated among conservatives and the right-wing media ecosystem. 

Most obviously, there is the character of Donald Trump himself, as well as other elites associated with the Republican Party, such as Elon Musk or Marjorie Taylor Greene. Although it is difficult to quantify these things scientifically, the frequency and brazenness with which such figures spread false and misleading content seems unprecedented in recent American politics and finds no parallels among mainstream liberal politicians and pundits.

Second, research consistently [finds](https://www.nature.com/articles/s41586-024-07942-8) that fake news and low-quality news more broadly are far more prominent among conservative audiences. Moreover, although surprisingly high rates (roughly 30-40%) of liberal voters endorse beliefs about election fraud when their party loses, this is much lower than the [over 60% of Republicans](https://prri.org/spotlight/after-three-years-and-many-indictments-the-big-lie-that-led-to-the-january-6th-insurrection-is-still-believed-by-most-republicans/) who believe the “Big Lie” about the 2020 election, which was supported by an intensive top-down disinformation campaign by Trump and other Republican elites. 

Finally, the mistrust of established knowledge-producing institutions like [science](https://www.pewresearch.org/science/2024/11/14/public-trust-in-scientists-and-views-on-their-role-in-policymaking/), [public health authorities](https://www.kff.org/health-information-trust/poll-finding/kff-tracking-poll-on-health-information-and-trust-january-2025/), and [mainstream media](https://news.gallup.com/poll/651977/americans-trust-media-remains-trend-low.aspx) is overwhelmingly concentrated among Republican voters. Although a measured mistrust might be [warranted](https://www.theguardian.com/commentisfree/2022/feb/15/this-is-why-some-people-dont-want-to-get-the-covid-vaccine) or at least [understandable](https://iai.tv/articles/misinformation-is-the-symptom-not-the-disease-daniel-walliams-auid-2690) in some cases, the estrangement of many Republican voters from these institutions means that punditry and media coverage on the political right are much [less constrained](https://academic.oup.com/book/26406) by scientific evidence, fact-checking, and professional journalistic norms. 

This partisan asymmetry presents a challenge for narratives that place significant blame on social media platforms for America’s current epistemic challenges. These platforms do not run different algorithms for liberal and conservative users. If social media is a wrecking ball, why is it so selective in the buildings it destroys? 

## The diploma divide

While there is significant scholarly controversy over the causes of epistemic dysfunction on the American right today, some of the most important factors appear to have little to do with social media.

Perhaps the most consequential trend concerns America’s intense “[diploma divide](https://journals.sagepub.com/doi/full/10.1177/10659129221079862),” a fundamental realignment of American politics along educational lines. In recent decades, the Democratic Party’s voter base has shifted towards highly educated, urban professionals who dominate the knowledge economy and prestigious institutions. In contrast, the Republican Party has become the political home for white Americans who lack four-year college degrees. 

As Matt Grossmann and David Hopkins document in [_Polarized by Degrees_](https://www.cambridge.org/core/books/polarized-by-degrees/73B3136DC05749099EB07787A48FE522), this diploma divide has politicized institutions (including science, media, and public health authorities) dominated by educated professionals with liberal values and allegiances to the Democratic Party, and driven many conservatives to feel alienated from experts and institutions they perceive as arrogant and biased against them. Given this, the conservative base has become increasingly receptive to alternative, “[anti-establishment](https://www.jstor.org/stable/45415724)” sources of information that validate their “[common sense](https://www.conspicuouscognition.com/p/americas-epistemological-crisis)” worldview and skepticism of the expert class. 

This diploma divide and its political consequences are not unique to America. However, Grossman and Hopkins point out that America is unique in how educational polarization interacts with the country’s intense affective polarization and strict two-party system. In other words, America is unique in the degree to which the sharp divisions created by educational polarization are channeled through and amplified by its intense partisan polarization.

## The surprising science of social media

These lessons are difficult to reconcile with the “wrecking ball” narrative. However, they are consistent with the possibility that social media has substantially exacerbated the epistemic dysfunction of the contemporary political right. 

Nevertheless, when we turn to the highest quality scientific evidence on social media’s effects, it does not offer much support for this view.

If social media is a major contributor to political trends, one would expect to observe dramatic effects on people’s beliefs and attitudes when their social media experience changes. A [2020 Facebook and Instagram Election Study](https://research.facebook.com/2020-election-research/), conducted in collaboration between Meta and a team of academic researchers led by Talia Stroud and Joshua Tucker, has provided unprecedented opportunities to test this prediction through large-scale, randomized field experiments — the gold standard for establishing causality. The findings are as striking as they are consistent. 

One of these [experiment](https://www.nature.com/articles/s41586-023-06297-w)s, led by Brendan Nyhan, tested the effects of echo chambers on Facebook by reducing users’ exposure to like-minded sources. [Another](https://www.science.org/doi/10.1126/science.abp9364) led by Andrew Guess tested the effects of algorithmic curation on Facebook and Instagram by switching users from an algorithmic to a reverse-chronological feed. And [another](https://www.science.org/doi/10.1126/science.add8424), also led by Guess, tested the effects of exposure to viral content on Facebook by removing exposure to reshared content. The headline result across each study was the same: researchers detected no meaningful changes in users’ political attitudes or polarization. 

Importantly, these findings did not arise because the interventions had no effects. For example, users randomized to encounter a reverse-chronological feed spent significantly less time on the platforms as a result, and those who stopped encountering reshared content saw substantially less political news, including content from untrustworthy sources. However, these effects did not translate into detectable changes in political attitudes. 

Another [experiment](https://www.pnas.org/doi/10.1073/pnas.2321584121) led by Hunt Allcott and Matthew Gentzkow randomized a subset of 19,857 Facebook users and 15,585 Instagram users to deactivate their accounts for six weeks prior to the 2020 election. The result? “Precisely estimated” and “close to zero” effects on polarization, assessments of the election’s legitimacy, evaluations of candidate favorability, and voter turnout. 

As with all scientific research, these findings have numerous nuances, complexities, and limitations. Some social scientists have raised important [methodological critiques](https://www.wsj.com/tech/science-editors-raise-new-doubts-on-metas-claims-it-isnt-polarizing-aaf955e4?utm_source=chatgpt.com) of the Facebook and Instagram field experiments, as well as the [informativeness](https://tecunningham.github.io/posts/2023-07-27-meta-2020-elections-experiments.html) of their findings. For example, the experiments were restricted to these two platforms, and they only examined effects over a relatively short (three-month) period, which occurred after Meta had already implemented extensive content moderation and design changes in response to previous concerns about its political impacts.  Some other randomized experiments have discovered small effects. For example, when users were randomized to deactivate their Facebook accounts for four weeks before the 2018 US midterm election, it resulted in a [slight reduction](https://www.aeaweb.org/articles?id=10.1257/aer.20190658) in political polarization. 

Nevertheless, it is noteworthy that the balance of empirical evidence in this area does not support the claim that social media use has a large impact on users’ political attitudes and behavior. Although many are surprised by such findings, they align with decades of research on the limited and conditional effects of media, propaganda, and persuasion. 

## The difficulties of political persuasion

People are not blank slates. Even from a very young age, humans are [savvy and skeptical information consumers](https://psycnet.apa.org/record/2010-17633-001), actively seeking out and ignoring content based on its perceived reliability, trustworthiness, and utility. They treat media in sophisticated ways that reflect their pre-existing beliefs, attitudes, and identities.

As Hugo Mercier documents extensively in his book [_Not Born Yesterday_](https://press.princeton.edu/books/hardcover/9780691178707/not-born-yesterday?srsltid=AfmBOoo4GqIlxLYUkJYGTwDmBGm88Y8Cjvrq7k41nI-PQ9AhKe1mWsl7), political persuasion is extremely challenging, and most efforts at propaganda throughout history have been [unsuccessful or have had minimal effects](https://www.persuasion.community/p/propaganda-almost-never-works), especially when they contradict things audiences already believe. For example, empirical research consistently demonstrates that “[the small effects of political advertising are small regardless of context, message, sender, or receiver](https://www.science.org/doi/10.1126/sciadv.abc4046).” A recent [study](https://www.nber.org/papers/w33818) randomized subsets of 39,906 Facebook users and 25,925 Instagram users to encounter no political ads on their news feeds for six weeks leading up to the 2020 US presidential election. It “found no detectable effects … on political knowledge, polarization, perceived legitimacy of the election, political participation (including campaign contributions), candidate favorability, and turnout.” 

Of course, this does not demonstrate that political persuasion and manipulation are impossible. Research [indicates](https://press.uchicago.edu/ucp/books/book/chicago/P/bo181475008.html) that people tend to update their beliefs when presented with persuasive arguments or messages from trusted sources, although such effects are often small and tend to [decay over time](https://pubmed.ncbi.nlm.nih.gov/33837144/). However, when it comes to people’s core political attitudes, worldviews, and allegiances, they are much more stubborn than much of the discourse surrounding social media suggests. 

Moreover, people exercise significant agency over which information they encounter in the first place. This phenomenon of “selective exposure” means that correlations between political attitudes and media use often arise not because of media persuasion but [because](https://www.sciencedirect.com/science/article/pii/S2352250X22000835?via=ihub) audiences are drawn to content that coheres with or [rationalizes](https://www.cambridge.org/core/journals/economics-and-philosophy/article/marketplace-of-rationalizations/41FB096344BD344908C7C992D0C0C0DC) their pre-existing attitudes and worldviews. 

For this reason, correlational evidence, which constitutes the [overwhelming majority](https://pmc.ncbi.nlm.nih.gov/articles/PMC9883171/) of evidence reported in studies of digital media use, can be highly misleading. For example, evidence suggests that algorithmic effects are much less impactful than self-selection in explaining people’s engagement with fringe, extremist, and hyper-partisan content online. [Summarizing](https://www.nature.com/articles/s41586-024-07417-w) a large body of empirical literature, a research team led by Ceren Budak documents “a pattern of low exposure to false and inflammatory content \[online\] that is concentrated among a narrow fringe with strong motivations to seek out such information.” As social scientist Sacha Altay [observes](https://osf.io/preprints/psyarxiv/sm3vk_v2), people do not passively fall into rabbit holes; they “jump in and dig.”

Although many people find such lessons about the sophisticated and skeptical nature of media consumption intuitive in their own case, they often mistakenly assume that others are much more gullible. Indeed, Sacha Altay and Alberto Acerbi [find](https://journals.sagepub.com/doi/full/10.1177/14614448231153379) that the strongest and most reliable predictor of alarmism about misinformation is this “third-person effect”: “the belief that ‘distant’ others (as opposed to family and friends) are vulnerable to misinformation.” 

## Conclusion 

We should have considerable uncertainty about the causes of complex social and political outcomes and trends. Nobody can test the effects of removing these social media platforms from society wholesale over a long period of time. Moreover, platforms themselves are diverse, and even the same platforms have evolved in complex ways, making them inherently challenging to study and generalize about. 

Nevertheless, the current balance of evidence does not support blaming America’s epistemic challenges on social media. First, many of these challenges predate social media and can arise independently of it. Second, the uneven distribution of such challenges across nations and political cultures with comparable rates of social media use suggests that social media alone is not what’s causing them. And finally, our best large-scale experiments show minimal effects of social media platforms, which aligns with decades of research into media and social learning.

New evidence may emerge in the future that overturns this skeptical assessment. However, at present, these observations and arguments should lead us to have a moderately strong degree of confidence that social media is not the primary driver of America’s epistemic crisis, and a very high degree of confidence that it is not the only driver.

This does not mean that social media is harmless. But America’s large-scale epistemic challenges seem to be rooted in deep-seated political and cultural divisions that are largely reflected on social media, not created by it. Although Big Tech deserves scrutiny for its potential role in accelerating harmful trends and enabling radicalization and extremist coordination, treating social media as the primary culprit risks misdiagnosing — and so failing to address — the leading causes of America’s fractured and frequently dysfunctional information environment. 

The appeal of the “wrecking ball” narrative lies partly in its promise of a simple fix to complex problems. However, the uncomfortable truth is that America’s struggles with reality and rational debate likely stem from decades-old patterns of political realignment, educational polarization, and institutional mistrust that algorithms did not cause, and no amount of platform regulation can fix. 

Sign up for our newsletter to get Asterisk’s latest interviews, essays, and more.

  Subscribe

**Dan Williams** is an Assistant Professor in Philosophy at the University of Sussex and an Associate Fellow at the Leverhulme Centre for the Future of Intelligence (CFI) at the University of Cambridge

Published July 2025

[Share with email](mailto:?subject=Asterisk Magazine: Scapegoating the Algorithm&body=Scapegoating the Algorithm: https://asteriskmag.com/issues/11/scapegoating-the-algorithm%0AAmerica’s epistemic challenges run deeper than social media.) [Share on Twitter](https://twitter.com/intent/tweet?url=https://asteriskmag.com/issues/11/scapegoating-the-algorithm&text=America’s epistemic challenges run deeper than social media. @asteriskmgzn) [Share on Facebook](https://www.facebook.com/sharer/sharer.php?u=https://asteriskmag.com/issues/11/scapegoating-the-algorithm) [Share on LinkedIn](http://www.linkedin.com/sharing/share-offsite/?&url=https://asteriskmag.com/issues/11/scapegoating-the-algorithm)

Have something to say? Email us at [letters@asteriskmag.com](mailto:letters@asteriskmag.com).

[**Previous**  
Why Are There So Many Rationalist Cults?](https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults)

[**Next**  
No Retvrn](https://asteriskmag.com/issues/11/no-retvrn)

#### Further Reading

More: culture technology political science

*   [
    
    # The State of American Science Funding (For the Next Five Minutes)
    
    Stuart Buck
    
    ](https://asteriskmag.com/issues/11/the-state-of-american-science-funding-for-the-next-five-minutes)
*   [
    
    # Why Are There So Many Rationalist Cults?
    
    Ozy Brennan
    
    ](https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults)

## About Highlights

By highlighting text and “starring” your selection, you can create a personal marker to a passage.

**What you save is stored only on your specific browser locally, and is never sent to the server.** Other visitors will not see your highlights, and you will not see your previously saved highlights when visiting the site through a different browser.

**To add** a highlight: after selecting a passage, click the star ![](https://asteriskmag.com/assets/img/asterisk_mark.png). It will add a quick-access bookmark.

**To remove** a highlight: after hovering over a previously saved highlight, click the cross ![](https://asteriskmag.com/assets/img/asterisk_x.png). It will remove the bookmark.

**To remove all** saved highlights throughout the site, you can click here to completely clear your cache. **All selections have been cleared.**

![](https://asteriskmag.com/assets/img/asterisk_help.png)![](https://asteriskmag.com/assets/img/asterisk_x.png)

© 2025 Asterisk

Subscribe

[Donate](https://donorbox.org/asterisk-fundraising)

Sign up for our newsletter to get Asterisk’s latest interviews, essays, and more.

  Subscribe

![](https://asteriskmag.com/assets/img/asterisk_x.png)