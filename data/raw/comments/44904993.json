[
  {
    "id": 44909576,
    "by": "fnands",
    "timeISO": "2025-08-15T07:31:39.000Z",
    "textPlain": "As someone who works on satellite imagery, this part is incredibly exciting:> ViT models pretrained on satellite dataset (SAT-493M)DINOv2 had pretty poor out-of-the-box performance on satellite/aerial imagery, so it's super exciting that they released a version of it specifically for this use case.",
    "parent": 44904993,
    "depth": 1
  },
  {
    "id": 44905817,
    "by": "beklein",
    "timeISO": "2025-08-14T21:19:40.000Z",
    "textPlain": "- Blog post: https://ai.meta.com/blog/dinov3-self-supervised-vision-model...\n- Paper: https://ai.meta.com/research/publications/dinov3/\n- Hugging Face: https://huggingface.co/collections/facebook/dinov3-68924841b...",
    "parent": 44904993,
    "depth": 1
  },
  {
    "id": 44907484,
    "by": "Imnimo",
    "timeISO": "2025-08-15T00:53:16.000Z",
    "textPlain": "I think SAM and DINO are the two off-the-shelf image models I've gotten the most mileage out of.",
    "parent": 44904993,
    "depth": 1
  },
  {
    "id": 44906728,
    "by": "llm_nerd",
    "timeISO": "2025-08-14T23:01:36.000Z",
    "textPlain": "You have to share your contact information, including DoB, and then be approved access, to obtain the models, and given that it's Meta I assume they're actually validating it against their All Humans database.They made their own DINOv3 license for this release (whereas DINOv2 used the Apache 2.0 license).Neat though. Will still check it out.As a first comment, I had to install the latest transformer==4.56.0dev (e.g. pip install git+https://github.com/huggingface/transformers) for it to work properly. 4.55.2 and earlier was failing with a missing image type in the config.",
    "parent": 44904993,
    "depth": 1
  },
  {
    "id": 44905842,
    "by": "ranger_danger",
    "timeISO": "2025-08-14T21:21:59.000Z",
    "textPlain": "I have no idea what this even is.",
    "parent": 44904993,
    "depth": 1
  },
  {
    "id": 44906483,
    "by": "barbolo",
    "timeISO": "2025-08-14T22:31:42.000Z",
    "textPlain": "That's awesome. DINOv2 was the best image embedder until now.",
    "parent": 44904993,
    "depth": 1
  },
  {
    "id": 44908953,
    "by": "PhilippGille",
    "timeISO": "2025-08-15T05:38:15.000Z",
    "textPlain": "This was submitted earlier:DINOV3: Self-supervised learning for vision at unprecedented scale | https://news.ycombinator.com/item?id=44904608",
    "parent": 44904993,
    "depth": 1
  },
  {
    "id": 44906831,
    "by": "Qwuke",
    "timeISO": "2025-08-14T23:14:09.000Z",
    "textPlain": "Yes, it's pretty disappointing for a seemingly big improvement over SOTA to be commercially licensed compared the previous version.. At least in the press release they're not portraying it as open source just because it's on GitHub/HuggingFace.",
    "parent": 44906728,
    "depth": 2
  },
  {
    "id": 44909245,
    "by": "ethan_smith",
    "timeISO": "2025-08-15T06:35:39.000Z",
    "textPlain": "DINO (Distillation with No labels) is a self-supervised computer vision framework that learns powerful image representations without requiring labeled data. It's particularly valuable for downstream tasks like object detection and segmentation, with DINOv3 now scaling to over 1B parameters and trained on 1.2B images.",
    "parent": 44905842,
    "depth": 2
  },
  {
    "id": 44906012,
    "by": "kaoD",
    "timeISO": "2025-08-14T21:39:44.000Z",
    "textPlain": "> An extended family of versatile vision foundation models producing high-quality dense features and achieving outstanding performance on various vision tasks including outperforming the specialized state of the art across a broad range of settings, without fine-tuning",
    "parent": 44905842,
    "depth": 2
  },
  {
    "id": 44905865,
    "by": "n3storm",
    "timeISO": "2025-08-14T21:24:00.000Z",
    "textPlain": "D3NO?",
    "parent": 44905842,
    "depth": 2
  }
]