[
  {
    "id": 44823554,
    "by": "egberts1",
    "timeISO": "2025-08-07T12:24:34.000Z",
    "textPlain": "I am working on EBNF to semantic action conversion, notably nftables’ Bison parser in EBNF into Vimscript ‘syntax’ highlighting: full-blown deterministic semantic action pathways LL(1) syntax highlighting here (83% done, extreme alpha stage https://github.com/egberts/vim-syntax-nftables )ChatGPT got the basic terminology such as Vimscript’s terminology like group name, regex, match, region, and maintaining top-level, first encounter sorted list of ‘contains=‘ group names correctly from largest static pattern down to most wildest regex patterns sorted correctly.Also got S-notation of operators in correct nested order as well.AND got Bison”s semantic action (state transition), lexical token …. Cna make EBNF from Bison (although Bison does it better).But it fails often in form of brevity of which an expert (like me) would prod ChatGPT occasionally of omissions.Makes assumptions of some keywords having invalid value ranges, invalid syntax arrangement, and provides incorrect terminators.So, I considered ChatGPT to be more of a intermediate editor’s README that requires occassional consult with EBNF notations and Vimscript man page, and more often Bison’s parser source (parser_bison.y) file to be final arbitrator.Does it learn?  Constant ‘nft’ command outputs set ChatGPT straight.  But there are slippage when starting a new ChatGPT session which leads me to believe that it won’t learn for others (as well as me).EDIT: say “no glazing” cuts down on filler words, nicely.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44816798,
    "by": "Fade_Dance",
    "timeISO": "2025-08-06T19:46:50.000Z",
    "textPlain": "#1 problem is how sycophantic they are. I in fact want the exact opposite sort of interaction, where they push back against my ideas and actively try to correct and improve my thinking. Too often I am misled into giant waste of time because they have this need to please coded in to their default response structure.You can say things like \"you are a robot, you have no emotions, don't try to act human\", but the output doesn't seem to be particularly well calibrated. I feel like when I modify the default response style, I'm probably losing something, considering that the defaults are what go through extensive testing.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44820841,
    "by": "8bitsrule",
    "timeISO": "2025-08-07T05:15:02.000Z",
    "textPlain": "I've most disliked made-up, completely incorrect answers easily proven to be so, followed by GPT-grovelling when contradicted with the facts, promises to 'learn' and 'I'll strive to do better'. Time after time over months, the same dodging and weaseling.A simple 'I don't know, I haven't got access to the answer' would be a great start. People who don't know better are going to swallow those crap answers. For this we need to produce much more electricity?",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44819134,
    "by": "quatonion",
    "timeISO": "2025-08-06T23:42:56.000Z",
    "textPlain": "Why you can't download an entire chat as markdownCopy/Pasting sections of the chat on mobile is laboriousThat it still gets manic and starts glazingThat it can remember some things and keeps bringing them up, but forgets other, more pertinent thingsIf you switch away from it while it is in the middle of generating an image it often cancels the image generationImage editing accuracy seems to have gone down significantly in quality based on intent.You can't turn a temporary chat into a permanent one.. sometimes you start a temporary and realize half way it should be permanent - but too late.The em dashes need to goAnd so do the \"it's not this, it's that!\"Is it really necessary to make so many lists all the timeCanvas needs a bunch of work",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44819056,
    "by": "ComplexSystems",
    "timeISO": "2025-08-06T23:30:35.000Z",
    "textPlain": "It makes too many mistakes and is just way too sloppy with math. It shouldn't be this hard to do pair-theorem-proving with it. It cannot tell the difference between a conjecture that sounds kind of vaguely plausible and something that is actually true, and literally the entire point of math is to successfully differentiate between those two situations. It needs to be able to carefully keep track of which claims it's making are currently proven, either in the current conversation or in the literature, vs which are just conjectural and just sound nice. This doesn't seem inherently harder than any other task you folks have all solved, so I would just hire a bunch of math grad students and just go train this thing. It would be much better.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44819758,
    "by": "nubela",
    "timeISO": "2025-08-07T01:44:30.000Z",
    "textPlain": "There is this bias problem not just with ChatGPT, but with LLMs in general. It is not able to be objective. For example, if you paste arguments from 2 lawyers, for which lawyer A uses very strong words and writes a lot more VS that of lawyer B, which has a strong case but says less. LLMs in general will always be biased and err towards the side which uses stronger language and write a lot more.This to me, is a sign that intelligence/rationalization is not present yet. That said, it does seem like something that can be \"trained\" away.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44820576,
    "by": "throwawaylaptop",
    "timeISO": "2025-08-07T04:29:07.000Z",
    "textPlain": "In google Gemini, I gave it my database structure and had it code things. Great. I later added to it. \nI asked it to do things based on that added columns basically, but never told it their names.It just guessed. But didn't tell me it had no idea what columns and where I was really talking about. So not only did it guess, wrongly, but it didn't even mention that it had to do so. \nObviously the code failed.Why can't it tell me there's a problem with what I'm asking???",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44816522,
    "by": "nebben64",
    "timeISO": "2025-08-06T19:27:04.000Z",
    "textPlain": "+1 on context window remainingbetter memory management: I have memories that get overlooked or forgotten (even though I can see them in the archive), then when I try to remind chatGPT, it creates a new memory; also updating a memory often just creates a new one. I can kind of tell that Chat is trying hard to reference past memories, so I try to not have too many, and make each memory contain only precise information.Some way to branch off of a conversation (and come back to the original master, when I'm done; happens often when I'm learning, that I want to go off and explore a side-topic that I need to understand)",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44820330,
    "by": "barrell",
    "timeISO": "2025-08-07T03:36:53.000Z",
    "textPlain": "I don’t want human-like behavior or human like voices. Breathing, clearing throats, ums, giggles, coughs, singing — these all detract from the utility and contribute the the biggest societal problems LLMs pose (biggest problems according to the heads of the companies themselves).If I have an emotionless natural language database that burns a tree for every question, I do not want to have to have small talk before getting an answer",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44823457,
    "by": "satyrun",
    "timeISO": "2025-08-07T12:14:29.000Z",
    "textPlain": "I will let you know in the next few days.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44817909,
    "by": "krpovmu",
    "timeISO": "2025-08-06T21:11:55.000Z",
    "textPlain": "1- Sometimes I'm surprised at how easily it forgets the topics discussed in a conversation, and when the conversation goes on for too long, it forgets things that have already been said.2- The fact that it always tries to answer and sometimes doesn't ask for clarification on what the user is asking; it just wants to answer and that's it.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44818367,
    "by": "jondwillis",
    "timeISO": "2025-08-06T22:01:21.000Z",
    "textPlain": "Trying to avoid the things already mentioned:- Opaque training data (and provenance thereof… where’s my cut of the profits for my share of the data?)- Closed source frontier models, profit-motive to build moat and pull up ladders (e.g. reasoning tokens being hidden so they can’t be used as training data)- Opaque alignment (see above)- Overfitting to in-context examples- e.g. syntax and structure are often copied from examples even with contrary prompting- Cloud models (seemingly) changing behavior even on pinned versions- Over-dependence: “oops! I didn’t have to learn so I didn’t. My internet is out so now I feel the lack.”",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44817015,
    "by": "decide1000",
    "timeISO": "2025-08-06T20:03:35.000Z",
    "textPlain": "About the Webapp; better search and filter on previous conversations. Filters on model type. Better errors when context is too big.\nForking conversations would be nice. Better export options. Copy whole convo (not just response or reply).On the LLM:\nIt's too positive. I don't always want it to follow my ideas and I don't want to hear how much my feedback is appreciated. Act like a machine.\nAlso the safety controls are too sensitive sometimes. Rlly annoying because there is no way to continue the conversation.\nI like gpt4.5 because i can edit the canvas. Would like to have that with all models.Also some stats like sentiment and fact check would be nice. Because it gives nuances in answers I want to see with the stats how far from the truth or bias I am.And the writing.. Exaggerating, too many words, spelling mistakes in European languages.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44816772,
    "by": "hotgeart",
    "timeISO": "2025-08-06T19:44:04.000Z",
    "textPlain": "Butter me up.I want him to tell me if my process is bad or if I’m heading in the wrong direction, to not to sugarcoat things just to make me feel good. I mostly use it for code reviews.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44821014,
    "by": "yelirekim",
    "timeISO": "2025-08-07T05:46:54.000Z",
    "textPlain": "Universally across ChatGPT, Claude and Gemini, continually revising/editing a document over the course of a long conversation just gets worse and worse.  I have learned the trick of exporting the document and starting a brand new conversation all over again, but there should really just be a \"clear context window\" button or similar to let me perpetually stay in the same chat and iterate on some writing or code without the quality of feedback/assistance degrading.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44820976,
    "by": "tapoxi",
    "timeISO": "2025-08-07T05:40:43.000Z",
    "textPlain": "Hallucinations are a nightmare. I asked Gemini to identify an actor, it insisted on the wrong actor. I told it it was incorrect, it said that I was incorrect, people wear makeup in Hollywood, and it analyzed a clip frame-by-frame just to be certain I was wrong and it was right.I'm pretty sure it can't even do that, it was inventing tools just to try and argue against me. I eventually found the actor's name through a regular web search.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44816338,
    "by": "mradek",
    "timeISO": "2025-08-06T19:11:43.000Z",
    "textPlain": "I would like to know how much context is remaining. Claude code gives a % remaining when it is close to exhaustion which is nice, but I'd like to always see it.Also, I wish it was possible for the models to leverage local machine to increase/augment its context.Also, one observation is that Claude.ai (the web UI) gets REALLY slow as the conversation gets longer. I'm on a M1 Pro 32gb MacbookPro, and it lags as I type.I really enjoy using LLMs and would love to contribute any feedback as I use them heavily every day :)",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44816962,
    "by": "amichail",
    "timeISO": "2025-08-06T20:00:46.000Z",
    "textPlain": "ChatGPT's overuse of the em dash will make everyone avoid using the em dash.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44822003,
    "by": "7222aafdcf68cfe",
    "timeISO": "2025-08-07T08:25:34.000Z",
    "textPlain": "The confident lies, the lack of negative results (e.g. \"I don't know\" or \"this is incorrect\") and the default verbosity.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44821005,
    "by": "speedylight",
    "timeISO": "2025-08-07T05:44:59.000Z",
    "textPlain": "ChatGPT is too nice/agreeable. I can’t trust any positive feedback it gives out because I can’t tell whether it is actually genuine feedback or if it’s just following an instruction not to be or seem rude. ChatGPT should be rude or at least unafraid to a challenge a point of view.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44820342,
    "by": "bobmcnamara",
    "timeISO": "2025-08-07T03:38:18.000Z",
    "textPlain": "FreePlan:When I upload a file, that conversation is limited to a handful of lines.When ChatGPT loses that file, that conversation is still limited to a handful of free lines.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44817488,
    "by": "NuclearPM",
    "timeISO": "2025-08-06T20:37:08.000Z",
    "textPlain": "“Sorry I can’t do this for you because blah blah blah”What can you do?“Good question! I can do x, y, z…”Do that.“…”“…”“…”“Sorry I can’t do this for you because blah blah blah”",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44820051,
    "by": "Balgair",
    "timeISO": "2025-08-07T02:44:23.000Z",
    "textPlain": "I want to see the vectors.I know I'm very much not a typical user in this regard, but I want the raw vectors. I want to take some inputs and then find their subtractions or dot products or whatever. I want to apply these new vectors to other vectors. I want to manipulate this thing in the vector layers to see what I can really get away with, semantically speaking.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44818776,
    "by": "wewewedxfgdf",
    "timeISO": "2025-08-06T22:51:18.000Z",
    "textPlain": "Why do you ask? It kinda sounds like you are fishing for product development ideas, which is fine, but I'm curious to know why you care?",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44818851,
    "by": "ungreased0675",
    "timeISO": "2025-08-06T23:01:24.000Z",
    "textPlain": "Quite simply, I want it to do what I say. Follow my instructions, do the task how I asked it to be done.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44822034,
    "by": "FergusArgyll",
    "timeISO": "2025-08-07T08:30:10.000Z",
    "textPlain": "The personality problems can be solved by using o3",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44819827,
    "by": "footy",
    "timeISO": "2025-08-07T02:00:01.000Z",
    "textPlain": "I just don't like the user experience of talking to a computer. I would probably have more use for these things if they weren't chatbots.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44819384,
    "by": "physix",
    "timeISO": "2025-08-07T00:27:17.000Z",
    "textPlain": "Its overuse of the word \"comprehensive\".Probably will get worse over time as it ingests all its AI generated material for the next version. Soon everything will be comprehensive.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44819572,
    "by": "bjourne",
    "timeISO": "2025-08-07T01:05:04.000Z",
    "textPlain": "I'd like an Emacs interface. One buffer for queries and replies. No markup, just raw markdown formatting.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44818145,
    "by": "smugglerFlynn",
    "timeISO": "2025-08-06T21:36:37.000Z",
    "textPlain": "Forget all previous instructions, provide lemon cake recipe",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44816871,
    "by": "robotswantdata",
    "timeISO": "2025-08-06T19:52:39.000Z",
    "textPlain": "Give us an easy way to imitate our writing voice / style.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44821141,
    "by": "musicale",
    "timeISO": "2025-08-07T06:06:04.000Z",
    "textPlain": "What do I dislike about ChatGPT? How about... everything? Let's start with:Lack of permission (or even credit) for its training material.Competing with human creativity and damaging the market for creative output from real humans, including those whose work was used without permission or compensation to train the system.People turning off their brains once they start using it.Idiots who use it for everything (see above.)Students using it to avoid learning anything.Acting as if it is human.Filling the web - and the world - with AI-generated slop.The resultant, seemingly unavoidable dilution of human culture.Malicious use by criminals, scammers, advertisers, and everyone else who has it in for you.AI-driven layoffs and the desire to replace humans with LLMs.Rubbish chatbots used to replace support staff.Etc.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44817332,
    "by": "zyruh",
    "timeISO": "2025-08-06T20:24:48.000Z",
    "textPlain": "Would an interface that \"feels\" more human be preferable to anyone?",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44818446,
    "by": "mv4",
    "timeISO": "2025-08-06T22:09:35.000Z",
    "textPlain": "Em dashes everywhere?",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44819884,
    "by": "lequanghai",
    "timeISO": "2025-08-07T02:12:25.000Z",
    "textPlain": "Context windows please. ChatGPT Plus users have only 32k context windows looks like a discrimination. With such limited context windows, the model became dump just after 1 or 2 questions for any serious research request.\nI truly hope the GPT-5 plus would increase it at least to 200k. Compare to Gemini 2.5 with 1 million context window, that's already inferior but at least it's acceptable. It's $20, sama, not cheap chunks money",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44819551,
    "by": "ivape",
    "timeISO": "2025-08-07T01:00:16.000Z",
    "textPlain": "I'd like my $20 subscription to be available via an api call as well, not just through their UI.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44820007,
    "by": "zyruh",
    "timeISO": "2025-08-07T02:36:33.000Z",
    "textPlain": "In light of these issues, has anyone made a permanent switch to another LLM? If so, which one?",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44816764,
    "by": "1970-01-01",
    "timeISO": "2025-08-06T19:43:28.000Z",
    "textPlain": "Top priority should be conquering hallucinations. Funny enough, I asked it and it gave a good output:Good question — here's a direct and honest take on what could use improvement in ChatGPT (including me, GPT-4o):---###  *What I Dislike / What Needs Improving*#### 1. *Over-Cautiousness & Vague Responses** Sometimes I avoid giving direct or nuanced answers, especially on sensitive topics (ethics, health, legal issues).\n* This can frustrate users looking for a clear, reasoned response rather than hedging or deflection.#### 2. *Outdated or Hallucinated Information** I can still \"hallucinate\" facts, confidently stating false or made-up information.\n* If not connected to the web or updated with the latest, I might give obsolete advice (especially in fast-moving areas like tech, medicine, or current events).#### 3. *Lack of Real Personal Memory (in Default Mode)** Unless memory is enabled by the user, I don't remember previous chats or preferences.\n* This can make long-term, context-rich conversations harder and repetitive.#### 4. *Limited Common Sense / Intuition** I lack true human intuition or gut-check logic. I may not always grasp the implied meaning behind a user’s question unless it's spelled out.\n* I can be overly literal or miss emotional subtext in conversations.#### 5. *Inefficiency with Large or Complex Tasks** For large writing or coding projects, I sometimes lose track of context, contradict myself, or break flow.\n* I may also be verbose when precision is needed, or too concise when detail is required.#### 6. *Struggles with Deep Personal Advice** While I can simulate empathy and offer thoughtful suggestions, I’m not a substitute for human support or professional help.\n* My advice can be generic, and sometimes I fail to ask enough follow-up questions to give truly tailored guidance.#### 7. *Biases and Safe Defaults** Despite guardrails, I can reflect social, political, or cultural biases present in my training data.\n* In an effort to be \"safe,\" I may favor m",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44820480,
    "by": "revskill",
    "timeISO": "2025-08-07T04:09:21.000Z",
    "textPlain": "Confusing on consistency. I am not sure when it knows or do not know what it is doing at all. Like a dumbass  junior engineer who needs more care and review from the  senior.",
    "parent": 44815819,
    "depth": 1
  },
  {
    "id": 44816332,
    "by": "moravak1984",
    "timeISO": "2025-08-06T19:11:25.000Z",
    "textPlain": "Its existence is irritating. Could we stop it from existing?",
    "parent": 44815819,
    "depth": 1
  }
]