[
  {
    "id": 44922384,
    "by": "motorest",
    "timeISO": "2025-08-16T11:44:52.000Z",
    "textPlain": "What a great article. It's always a treat to read this sort of take.I have some remarks though. Taken from the article:> Avoid having five different services all write to the same table. Instead, have four of them send API requests (or emit events) to the first service, and keep the writing logic in that one service.This is not so cut-and-dry. The trade offs are far from obvious or acceptable.If the five services access the database then you are designing a distributed system where the interface being consumed is the database, which you do not need to design or implement, and already supports authorization and access controls out of the box, and you have out-of-the-box support for transactions and custom queries. On the other hand, if you design one service as a high-level interface over a database then you need to implement and manage your own custom interface with your own custom access controls and constrains, and you need to design and implement yourself how to handle transactions and compensation strategies.And what exactly do you buy yourself? More failure modes and a higher micro services tax?Additionally, having five services accessing the same database is a code smell. Odds are that database fused together two or three separate databases. This happens a lot, as most services grow by accretion and adding one more table to a database gets far less resistance than proposing creating an entire new persistence service. And is it possible that those five separate services are actually just one or two services?",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922903,
    "by": "msiyer",
    "timeISO": "2025-08-16T12:48:46.000Z",
    "textPlain": "> Avoid having five different services all write to the same table. Instead, have four of them send API requests (or emit events) to the first service, and keep the writing logic in that one service.The ideal solution: Avoid having five different services all write to the same table.If five different services have to write to the same table, there is a major overlap of logic too. Are the five services really different or one would suffice?Taking practical realities into consideration, we can do what the author says. However, we risk implementing a lot of orchestration logic. We introduce a whole new layer of problems. Is that time not better spent refactoring the services: either give them their own DB tables or merge them into one servic?",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921359,
    "by": "bambax",
    "timeISO": "2025-08-16T08:22:33.000Z",
    "textPlain": "> When querying the database, query the database. It’s almost always more efficient to get the database to do the work than to do it yourself. For instance, if you need data from multiple tables, JOIN them instead of making separate queries and stitching them together in-memory.Oh yes! Never do a join in the application code! But also: use views! (and stored procedures if you can). A view is an abstraction about the underlying data, it's functional by nature, unlikely to break for random reasons in the future, and if done well the underlying SQL code is surprisingly readable and easy to reason about.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44923105,
    "by": "lutzh",
    "timeISO": "2025-08-16T13:12:25.000Z",
    "textPlain": "The only thing I know about “good system design” is that it doesn’t exist in the abstract. Asking whether an architecture is good or bad is the wrong question. The real question is: Is it fit for purpose? Does it help you achieve what you actually need to achieve?I could nitpick individual points in the article, but that misses the bigger issue: the premise is off.Don’t chase generic advice about good or bad design. First understand your requirements, then design a system that meets them.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922259,
    "by": "nvarsj",
    "timeISO": "2025-08-16T11:20:26.000Z",
    "textPlain": "> Paradoxically, good design is self-effacing: bad design is often more impressive than good.Rings very true. Engineers are rated based on the \"complexity\" of the work they do. This system seems to encourage over-engineered solutions to all problems.I don't think there is enough appreciation for KISS - which I first learned about as an undergrad 20 years ago.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921601,
    "by": "KronisLV",
    "timeISO": "2025-08-16T09:06:18.000Z",
    "textPlain": "> Schema design should be flexible, because once you have thousands or millions of records, it can be an enormous pain to change the schema. However, if you make it too flexible (e.g. by sticking everything in a “value” JSON column, or using “keys” and “values” tables to track arbitrary data) you load a ton of complexity into the application code (and likely buy some very awkward performance constraints). Drawing the line here is a judgment call and depends on specifics, but in general I aim to have my tables be human-readable: you should be able to go through the database schema and get a rough idea of what the application is storing and why.I’m surprised that the drawbacks of EAV or just using JSON in your relational database don’t get called out more.I’d very much rather have like 20 tables with clear purpose than seeing that colleagues have once more created a “classifier” mechanism and are using polymorphic links (without actual foreign keys, columns like “section” and “entity_id”) and are treating it as a grab bag of stuff. One that you also need to read the application code a bunch to even hope to understand.Whenever I see that, I want to change careers. I get that EAV has its use cases, but in most other cases fuck EAV.It’s right up there with N+1 issues, complex dynamically generated SQL when views would suffice and also storing audit data in the same DB and it inevitably having functionality written against it, your audit data becoming a part of the business logic. Oh and also shared database instances and not having the ability to easily bootstrap your own, oh and also working with Oracle in general. And also putting things that’d be better off in the app inside of the DB and vice versa.There are so many ways to decrease your quality of life when it comes to storing and accessing data.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44923140,
    "by": "vishnugupta",
    "timeISO": "2025-08-16T13:17:20.000Z",
    "textPlain": "I highly recommend Boring Technology[1]. It is an enjoyable read and most of the advices are actionable.[1] https://boringtechnology.club",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922958,
    "by": "alixanderwang",
    "timeISO": "2025-08-16T12:55:02.000Z",
    "textPlain": "> I’m often alone on this. Engineers look at complex systems with many interesting parts and think “wow, a lot of system design is happening here!” In fact, a complex system usually reflects an absence of good design.For any job-hunters, it's important you forget this during interviews.In the past I've made the mistake of trying to convey this in system design interviews.Some hypothetical startup app> Interviewer: \"Well what about backpressure?\">\"That's not really worth considering for this amount of QPS\"> Interviewer: \"Why wouldn't you use a queue here instead of a cron job?\"> \"I don't think it's necessary for what this app is, but here's the tradeoffs.\"> Interviewer: \"How would you choose between sql and nosql db?\"> \"Doesn't matter much. Whatever the team has most expertise in\"These are not the answers they're looking for. You want to fill the whiteboard with boxes and arrows until it looks like you've got Kubernetes managing your Kubernetes.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44923059,
    "by": "hks0",
    "timeISO": "2025-08-16T13:06:59.000Z",
    "textPlain": "The article starts by criticizing generic rules that come without any context:> Even good system design advice can be kind of bad. I love Designing Data-Intensive Applications, but I don’t think it’s particularly useful for most system design problems engineers will run into.But continues to do the same throughout the rest of its advices. It also says:> ... Drawing the line here is a judgment call and depends on specifics,And immediately mentions:> but in general I aim to have my tables be human-readable ...Which to me reads as \"I'm going to ignore the difference of the context everywhere and instead apply mine for everyone, and I'm going to assume most of the wolrd face the same problems as me\". It's even worse than the book being criticized in the beginning, as the book at least has \"Data-Intensive\" in its title.This is quiet easily fixable. The author can describe the typical scenario they are working with on a day-to-day basis. Do they work with 10 users a day? 100? 10,000,000? What is the traffic? How many engineers? What's the situation of the team/company; do FIXMEs turn into fixes or they become it's a feature? And so on.In the end, without setting a baseline, a lot of engineers will start pointing fingers at each other dismissing the opposite ideas because it doesn't fit their situation. The reasoning might be true, but before that, it is \"irrelevant\", hence any opposition to or defending of it.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921354,
    "by": "ZYbCRq22HbJ2y7",
    "timeISO": "2025-08-16T08:21:50.000Z",
    "textPlain": "> You’re supposed to store timestamps instead, and treat the presence of a timestamp as true. I do this sometimes but not always - in my view there’s some value in keeping a database schema immediately-readable.Seems overly negative of broad advice on a good pattern?    is_on => true\n    on_at => 1023030\n\nSure, that makes sense.     is_a_bear => true\n     a_bear_at => 12312231231\n\nNot so much, as most bears do not become bears at some point after not being a bear.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922886,
    "by": "codr7",
    "timeISO": "2025-08-16T12:46:59.000Z",
    "textPlain": "Replacing booleans with timestamps might be a good idea sometimes, presenting it as The Solution isn't very constructive imo.Adding a separate table where the presence of a record means 'true' allows recording related state without complicating the main table.And sometimes a boolean is exactly what you want.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922515,
    "by": "nasretdinov",
    "timeISO": "2025-08-16T12:05:05.000Z",
    "textPlain": "I agree with most of the stuff written in the article (quite a rare thing I must admit :)). But one thing I'd say is a bit outdated: in general whether or not to read from replica is the same decision as whether or not to use caching: it's a (pretty significant) tradeoff. Previously you didn't have much of a choice due to hardware being quite limited. Now, however, you can have literally hundreds of CPU cores, so all those CPUs can very much be busy at work doing reads. Writes obviously do have an overhead, _but_ note that all writes are eventually serialised, _and_ replica needs to handle them as well anyway",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921584,
    "by": "tetha",
    "timeISO": "2025-08-16T09:02:50.000Z",
    "textPlain": "The distinction of stateful and stateless is one of the main criteria how we're dividing responsibilities between platform-infra and development.I know it's a bit untrue, but you can't do that many things wrong with a stateless application running in a container. And often the answer is \"kill it and deploy it again\". As long as you don't shred your dataset with a bad migration or some bad database code, most bad things at this level can be fixed in a few minutes with a few redeployments.I'm fine having a larger amount of people with a varying degree of experience, time for this, care and diligence working here.With a persistence like a database or a file store, you need some degree of experience of what you have to do around the system so it doesn't become a business risk. Put plainly, a database could be a massive business risk even if it is working perfectly... because no one set backups up.That's why our storages are run by dedicated people who have been doing this for years and years. A bad database loss easily sinks ships.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921252,
    "by": "com",
    "timeISO": "2025-08-16T08:01:37.000Z",
    "textPlain": "The advice about logging and metrics was good.I had been nodding away about state and push/pull, but this section grabbed my attention, since I’ve never seen it do clearly articulated before.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921824,
    "by": "pelagicAustral",
    "timeISO": "2025-08-16T09:50:11.000Z",
    "textPlain": "I can definitely feel the \"underwhelming\" factor. I've been working for  +10 years on government software and I really know what an underwhelming codebase looks like, first off, it has my fucking name on it.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922293,
    "by": "thisbeensaid",
    "timeISO": "2025-08-16T11:27:26.000Z",
    "textPlain": "Since the author praises proper use of databases and talks about event bus, background jobs and caching, I highly recommend to check out https://dbos.dev if you have Python or TypeScript backends. DBOS nicely solves common challenges in simple and complex systems and can eliminate the need for running separate services such as Kafka, Redis or Celery. The best: DBOS can be used as a dependency and doesn't require deploying a separate service.Very recently discussed here a week ago: https://news.ycombinator.com/item?id=44840693",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921254,
    "by": "bravesoul2",
    "timeISO": "2025-08-16T08:02:36.000Z",
    "textPlain": "He doesnt seem to mention Conway or team topology which is an important part of system design too.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921325,
    "by": "magnio",
    "timeISO": "2025-08-16T08:16:01.000Z",
    "textPlain": "I think it's a very good article. Even if you disagree with some of the individual points in it, the advice given are very concrete, pragmatic, and IMO tunable to the specifics of each project.On state, in my current project, it is not statefulness that causes trouble, but when you need to synchronize two stateful systems. Every time there's bidirectional information flow, it's gonna be a headache. The solution is of course to maintain a single source of truth, but with UI application this is sometimes quite tricky.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922310,
    "by": "bubblebeard",
    "timeISO": "2025-08-16T11:30:54.000Z",
    "textPlain": "Very good article, right on point!I do wonder about why the author left out testing, documentation and qa tool design though. To my mind, writing a proper phpcs or whatever to ensure everyone on the team writes code in a consistent way is crucial. Without documentation we end up forgetting why we did certain things. And without tests refactors are a nightmare.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922161,
    "by": "gethly",
    "timeISO": "2025-08-16T11:01:01.000Z",
    "textPlain": "Actually event-sourcing solves most of the pains - events, schema, push/pull, caching, distribution... whatever. The downside is that it is definitely not suitable for small projects and the overhead is substantial(especially during the development stage when you want to ship the product as soon as possible). On the other hand, once you get it going, it's an unstoppable beast.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922507,
    "by": "mgaunard",
    "timeISO": "2025-08-16T12:04:03.000Z",
    "textPlain": "Seems biased towards websites, which are mostly easy CRUD.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921663,
    "by": "dennisy",
    "timeISO": "2025-08-16T09:19:10.000Z",
    "textPlain": "This post has some good concepts, but I do not feel it helps you design good systems. It iterates options and primitives, but good design is when and how you apply them, which the post does not provide.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922110,
    "by": "StevenWaterman",
    "timeISO": "2025-08-16T10:51:04.000Z",
    "textPlain": "What do you call system design, when it's referring to the design of systems in general, and not just computer services?As in:- writing a constitution- designing API for good DX- improving corporate cultureI intuitively want to call all of those system design, because they're all systems in the literal sense. But it seems like everyone else uses \"system design\" to mean distributed computer service design.Any ideas what word or phrase I could use to mean \"applying systems thinking to systems that include humans\"",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922235,
    "by": "mattlondon",
    "timeISO": "2025-08-16T11:14:55.000Z",
    "textPlain": "There was an article here recently about how to write good design docs: the TL;DR for that was basically your design doc should make your design seem obvious. I think that is the same conclusion here - good design is simple, straightforward design with no real surprises.Wholly agree.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44921682,
    "by": "usernamed7",
    "timeISO": "2025-08-16T09:24:06.000Z",
    "textPlain": "One thing i would add, is that a well designed system is often one that is optimized for change. It is rare that a service remains static and unchanging; browsers and libraries are regularly updated, after all. Thus if/when a developer takes on a feature ticket to add or change XYZ, it should be easy to reason about and have predictable side-effects of how that change will impact the system, and ideally be easy to change as well.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922379,
    "by": "whodidntante",
    "timeISO": "2025-08-16T11:44:16.000Z",
    "textPlain": "Never write an article about good system design.In all seriousness, this is an extraordinary subtle and complex area, and there are few rules.For example, \"if you need data from multiple tables, JOIN them instead of making separate queries and stitching them together in-memory\" may be useful in certain circumstances. For  highly scalable consumer systems, the rule of \"avoid joins as much as possible\" can work a lot better.There is also no mention of how important it is to understand the business - usage patterns, the customers, the data, the scale of data, the scale of usage, security, uptime and reliability requirements, reporting requirements, etc.",
    "parent": 44921137,
    "depth": 1
  },
  {
    "id": 44922486,
    "by": "paffdragon",
    "timeISO": "2025-08-16T12:01:15.000Z",
    "textPlain": "> the interface being consumed is the database, which you do not need to design or implementYou absolutely should design and implement it, exactly because it is now your interface. In fact, it will add more constraints to your design, because now you have different consumers and potentially writers all competing for the same resource with potentially different access patterns. Plus the maintenance overhead that migrations of such shared tables come with. And eventually you might have data in this table that are only needed for some of the services, so you now need to implement views and access controls at the DB level.Ideally, if you have a chance to implement it, an API is cleaner and more flexible. The problem in most cases is simply business pushing for faster features which often leads to quick hacks including just giving direct access to some DB table from another service, because the alternative would take more time, and we don't have time, we want features, now.But I agree with your thoughts in the last paragraph. It happens very often that people don't want to undertake the effort of a whole new design or redesign to match the evolving requirements and just patch it by adding a new table to an existing DB, then another,...",
    "parent": 44922384,
    "depth": 2
  },
  {
    "id": 44922950,
    "by": "Muromec",
    "timeISO": "2025-08-16T12:54:14.000Z",
    "textPlain": ">And what exactly do you buy yourself? More failure modes and a higher micro services tax?Nice boxes in the architectural diagram. Each box is handed to a different team and then, when engineers from those teams don't talk to each other, the system doesn't suddenly fail in an unexpected way.",
    "parent": 44922384,
    "depth": 2
  },
  {
    "id": 44922806,
    "by": "sethammons",
    "timeISO": "2025-08-16T12:40:08.000Z",
    "textPlain": "The goal is to minimize what needs changing when things need changing.When you need to alter the datastore, usually for product or scalability, you have to orchestrate all access to that datastore.Ergo: one only one thing using the datastore means less orchestration.At work, we just updated a datastore. We had to move some tables to their own db. 3 years later, 40+ teams have updated their access. This was a product need. If this was a scale issue, the product would just have died sans some as of yet imagined solution.",
    "parent": 44922384,
    "depth": 2
  },
  {
    "id": 44922460,
    "by": "bubblebeard",
    "timeISO": "2025-08-16T11:57:27.000Z",
    "textPlain": "I think the author meant, in a general way, it’s better to avoid simultaneous writes from different services, because this is an easy way to introduce race conditions.",
    "parent": 44922384,
    "depth": 2
  },
  {
    "id": 44923225,
    "by": "Ozzie_osman",
    "timeISO": "2025-08-16T13:28:53.000Z",
    "textPlain": "There are definitely examples of when you want to do joins in the application.For example, you may want to (or have the option to) vertically partition your database, or use different data stores. The app layer is usually stateless and can scale perpetually, but the database might be a bottleneck.Joining in the database over the application is a great default. But I wouldn't say \"never join in the application code\".",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44921590,
    "by": "bob1029",
    "timeISO": "2025-08-16T09:03:29.000Z",
    "textPlain": "This is a big part of what makes ORMs a problem.Writing raw SQL views/queries per MVC view in SSR arrangements is one of the most elegant and performant ways to build complex web products. Let the RDBMS do the heavy lifting with the data. There are optimizations in play you can't even recall (because there's so many) if you're using something old and enterprisey like MSSQL or Oracle. The web server should be able to directly interpolate sql result sets into corresponding <table>s, etc. without having to round trip for each row or perform additional in memory join operations.The typical ORM implementation is the exact opposite of this - one strict object model that must be used everywhere. It's about as inflexible as you can get.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44921995,
    "by": "mdavid626",
    "timeISO": "2025-08-16T10:30:33.000Z",
    "textPlain": "I disagree. In modern highly scalable architectures I’d prefer doing joins in the layer front of the database (backend).The “backend” scales much easier than the database. Loading data by simple indexes, eg. user_id, and joining it on the backend, keeps the db fast. Spinning up another backend instance is easy - unlike db instance.If you think, your joins must happen in db, because data too big to be loaded to memory on backend, restructure it, so it’s possible.Bonus points for moving joins to the frontend. This makes data highly cacheable - fast to load, as you need to load less data and frees up resources on server side.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44922417,
    "by": "tialaramex",
    "timeISO": "2025-08-16T11:51:57.000Z",
    "textPlain": "Stored procedures seem like a win but the big problem is that while I could write the rest of the software in a very nice modern language like Rust, or more practically in C# since my team all know C# if I write a stored procedure it will be in Transact-SQL because that's the only choice.T-SQL was not a good programming language last century when it was vaguely current, and so no I do not want to write any significant amount of code in T-SQL. For my sins I maintain a piece of software with huge T-SQL procedures (multi-page elaborations by somebody who really, really like this stuff) and they're a nightmare. The tooling doesn't really believe in version control, the diagnostics when you make a mistake are either non-existent or C++ style useless spew.We hire a lot of very junior developers. People who still need to be told not to comment out code in release, that variable numbers are for humans to read not machines, that sort of thing. We're not quite hiring physicists to write software (I have done that at a startup) but it's close. However, none of the poor \"My first program\" code I see in a merge request by a new hire is anywhere close to as unreadable as the T-SQL we already own and maintain.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44922733,
    "by": "victorbjorklund",
    "timeISO": "2025-08-16T12:32:24.000Z",
    "textPlain": "Not sure I agree. First of all it can be more performant. Say you fetch 1000 records. And we need to join on a table where these 1000 records just got 2 different foreign keys. Instead of joing in db and fetching a lot more data we can do two queries and join in app instead. Secondly, makes it easier to cache data. Lets say the thing we joing with almost never changes (like some country info) we can cache that and just join it with the data from the db.Not saying this should always be the case, but sometimes it is the right call.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44922152,
    "by": "torginus",
    "timeISO": "2025-08-16T10:59:22.000Z",
    "textPlain": "Are you sure about this?Let's say you run a webshop and have two tables, one for orders with 5 fields, one for customers, with 20 fields.Let's say you have 10k customers, and 1m orders.A query performing a full join on this and getting all the data would result in 25 million fields transmitted, while 2 separate queries and a client side manual join would be just 5m for orders, and 200k for customers.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44921588,
    "by": "quietbritishjim",
    "timeISO": "2025-08-16T09:03:19.000Z",
    "textPlain": "I think it's ok to have this rule as a first approximation, but like all design rules you should understand it well enough to know when to break it.I worked on an application which joined across lots of tables, which made a few dozen records balloon to many thousands of result rows, with huge redundancy in the results. Think of something like a single conceptual result having details A, B, C from one table, X, Y from another table, and 1, 2, 3 from another table. Instead of having 8 result rows (or 9 if you include the top level one from the main table) you have 18 (AX1, AX2, AX3, AY1, ...). It gets exponentially worse with more tables.We moved to separate queries for the different tables. Importantly, we were able to filter them all on the same condition, so we were not making multiple queries to child tables when there were lots of top-level results.The result was much faster because the extra network overhead was overshadowed by the saving in query processing and quantity of data returned. And the application code was actually simpler, because it was a pain to pick out unique child results from the big JOIN. It was literally a win in every respect with no downsides.(Later, we just stuffed all the data into a single JSONB in a single table, which was even better. But even that is an example of breaking the old normalisation rule.)",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44921922,
    "by": "hk1337",
    "timeISO": "2025-08-16T10:13:28.000Z",
    "textPlain": "You should be careful with how much you lean into “doing it in the database” as well with how you implement it. Lest, you get the situation where your application inserts as one value and it gets saved completely different.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44921556,
    "by": "tossandthrow",
    "timeISO": "2025-08-16T08:57:18.000Z",
    "textPlain": "Views make good sense when you can check them in - and DB migrations are a poor way of doing it due to their immutable nature.Depending on the ecosystem the code base adopts a good orm might be a better choice to do joins.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44922659,
    "by": "scarface_74",
    "timeISO": "2025-08-16T12:23:50.000Z",
    "textPlain": "I have a very strict rule about any system I design or that I’m over against using stored procedures.When I use to interview to be a developer at a company, it was always an automatic no for me if a company kept business logic in stored procedures and had a separate team of “database developers”.As far as not doing joins in code, while I agree for the most part. GitHub itself has a rule against joining tables using sql that belong to different domains.https://github.blog/engineering/infrastructure/partitioning-...",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44921574,
    "by": "CafeRacer",
    "timeISO": "2025-08-16T09:00:52.000Z",
    "textPlain": "I came here to say an exactly opposite things. There were a few instances where a relatively heavy join would not perform well, no matter what I tried. And it was faster to load/stitch data together with goroutines. So I just opted to doing it that way.Also SQL is easy, but figuring out what's up with indexes and planner is not.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44922488,
    "by": "luckylion",
    "timeISO": "2025-08-16T12:01:32.000Z",
    "textPlain": "I feel like the biggest question to ask is: how expensive is it exactly, how often do you need to do it, and how important is the speed of it?If you have some complex queries on every page load with a huge number of users, put it in the DB as much as possible.If you need to iterate over a bunch of records and do something based on some combination of values, and it's for a weekly reporting thing, I'd much rather see 3 nested foreach loops with a lot of early exits to skip the things you don't care about than a multi-kb SQL-statement that took two days to develop and nobody every dares to touch again because it's hard to handle.",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44921727,
    "by": "nurettin",
    "timeISO": "2025-08-16T09:31:17.000Z",
    "textPlain": "for me, it is orm -> schema bound views -> views -> table functions -> stored procedure as a last resort (hopefully it doesn't come to that)",
    "parent": 44921359,
    "depth": 2
  },
  {
    "id": 44923134,
    "by": "msiyer",
    "timeISO": "2025-08-16T13:16:58.000Z",
    "textPlain": "... that is how you achieve a good design (for the time being).",
    "parent": 44923105,
    "depth": 2
  },
  {
    "id": 44922591,
    "by": "anal_reactor",
    "timeISO": "2025-08-16T12:16:24.000Z",
    "textPlain": "This is unfortunately true. People love complex solutions, and suggesting a simple one usually comes across as incompetent, while the reality is, simple solutions are easy to manage, which ensures the success of the project as a whole.Sure, there are problems that are inherently complex and require complex solutions. But most likely yours isn't one of them, most likely you have a basic web app.",
    "parent": 44922259,
    "depth": 2
  },
  {
    "id": 44921630,
    "by": "dondraper36",
    "timeISO": "2025-08-16T09:11:58.000Z",
    "textPlain": "There's a great book SQL Antipatterns, by Bill Karwin where this specific antipattern is discussed and criticized.That said, sometimes when I realize there's no way for me to come up even with a rough schema (say, some settings object that is returned to the frontend), I use JSONB columns in Postgres. As a rule of thumb, however, if something can be normalized, it should be, since, after all, that's still a relational database despite all the JSON(B) conveniences and optimizations in Postgres.",
    "parent": 44921601,
    "depth": 2
  },
  {
    "id": 44922190,
    "by": "quibono",
    "timeISO": "2025-08-16T11:05:46.000Z",
    "textPlain": "> storing audit data in the same DB and it inevitably having functionality written against it, your audit data becoming a part of the business logicWhat's the \"proper\" way to do this? Separate DB? Separate data store?",
    "parent": 44921601,
    "depth": 2
  },
  {
    "id": 44922975,
    "by": "dondraper36",
    "timeISO": "2025-08-16T12:58:10.000Z",
    "textPlain": "Yes, and this is exactly why LinkedIn-driven development exists in the first place. Listing a million technologies looks much more impressive on paper to recruiters than describing how you managed to only use a modular monolith and a single Postgres instance to make everything work.",
    "parent": 44922958,
    "depth": 2
  },
  {
    "id": 44921625,
    "by": "grey-area",
    "timeISO": "2025-08-16T09:11:02.000Z",
    "textPlain": "I’d see the booleans as a bad thing in almost all cases, instead of a boolean you can have a timestamp or an integer field (which can expand later).In the is_a case almost always a type or kind is better as you’ll rarely just have bears even if you only start with bears, just as you rarely have just two states for a status field (say on or off), often these expand in use to include things like suspended, deleted and asleep.So generally I’d avoid booleans as they tend to multiply and increase complexity partially when they cover mutually exclusive states like live, deleted and suspended. I have seen is_visible, is_deleted and is_suspended all on the same table (without a status) and the resulting code and queries are not pretty.I’d use an integer rather than a timestamp to replace them though.",
    "parent": 44921354,
    "depth": 2
  },
  {
    "id": 44921552,
    "by": "setr",
    "timeISO": "2025-08-16T08:56:55.000Z",
    "textPlain": "If you take the statement at face value — essentially storing booleans in the db ever is a bad smell - then he’s correct.Although I’m not even sure it’s broadly a good principle, even in the on_at case; if you actually care about this kind of thing, you should be storing it properly in some kind of audit table. Switching bool to timestamp is more of a weird lazy hack that probably won’t be all that useful in practice because only a random subset of data is being tracked like that (Boolean data type definitely isn’t the deciding factor on whether it’s important enough to track update time on).The main reason it’s even suggested is probably just that it’s “free” — you can smuggle the timestamp into your bool without an extra column — and it probably saved some effort accidentally; but not because it’s a broadly complete solution to the set of problems it tries to solve forI’ve got the same suspicion with soft-deletes — I’m fairly positive it’s useless in practice, and is just a mentally lazy solution to avoid proper auditing. Like you definitely can’t just undelete it, and it doesn’t solve for update history, so all you’re really protecting against is accidental bulk delete caught immediately? Which is half the point of your backup",
    "parent": 44921354,
    "depth": 2
  }
]