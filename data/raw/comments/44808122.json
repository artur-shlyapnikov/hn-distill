[
  {
    "id": 44810499,
    "by": "ozgung",
    "timeISO": "2025-08-06T11:15:10.000Z",
    "textPlain": "These examples show that we have a serious social issue, and it's not limited to teachers. People misuse LLMs. We engineers understand that LLMs are products under development. They only work correctly under certain circumstances, and they have limitations and non-perfect evaluation metrics. Regular people (non-engineers) treat them as finished products or magic wands. They ignore the warnings in the page saying LLM can make mistakes. And there are billions of those people. This may create huge social problems that engineers can't fix.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44809225,
    "by": "janalsncm",
    "timeISO": "2025-08-06T08:18:16.000Z",
    "textPlain": "Wonder if this is a natural consequence of teachers being overworked. If teachers can get more work done with AI (who cares if quality suffers!) then that becomes the baseline and admins will push them to do even more.In other words I predict this to be less of an issue with smaller class sizes.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44809468,
    "by": "karel-3d",
    "timeISO": "2025-08-06T08:46:40.000Z",
    "textPlain": "Students give AI-generated essays and the AI then grade it.That's what's called GAN - generative adversarial network.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44809774,
    "by": "empiko",
    "timeISO": "2025-08-06T09:27:09.000Z",
    "textPlain": "The cracks in the education system were showing even before AI, with unmotivated students and teachers alike just burning their hours. AI just exposed these cracks and showed that the entire system is incredibly inefficient and pointless. I believe that the future of education is in much smaller institutions that can support their communities on a human scale.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44808884,
    "by": "internet_points",
    "timeISO": "2025-08-06T07:37:14.000Z",
    "textPlain": "> * A teacher sponsoring a club put student artwork through Microsoft Copilot to 'clean it up' because he thought it looked too unfinished and the kid felt incredibly disrespected and upset.and rightly so! kids deserve better, that is awful",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44809561,
    "by": "jjani",
    "timeISO": "2025-08-06T08:57:28.000Z",
    "textPlain": "All those teachers should indeed be banned from using AI. But that's not because LLMs are incapable of the things they're using them for, in a way that would be an improvement over how those same teachers were doing those tasks pre-LLMs.The majority of times I see things like this it turns out that it's either:- The \"they've built it wrong\" case; this one is the most common. People using - or in this case being made to use at work - tools that behind the scenes  all use very cheap models (e.g. 4o-mini) with little context, half vibe-coded up, to save costs. The company making \"MagicSchool\" doesn't care, they want to maximize those profit margins and they're selling to school administration, not teachers, who only look at the costs and don't ever actually use the products themselves. Just like classic enterprise software in traditional companies. They need to tick boxes, show features that only show the happy path/case. It is perfectly possible to make it high quality, in a way that adds value, doesn't make shit up, and is properly validated. But especially in this niche, sales trumps everything. The hope is that at some point, this will change. We've seen the same play out with enterprise software to an extent; new such software does tend to be more usable on average than it used to be. It has taken a long time to get there though.- The \"you're holding it wrong\" meme; users themselves directly using tools like Microsoft Copilot, 4o and friends (very outdated, free tiers, miles behind Claude/Gemini 2.5 pro/o3/etc.), along with having zero idea about what LLMs can and can't do, and obviously even less of an idea about inherent biases and prompting to prevent those. This combined with a complete lack of caring, along with a lack of competency - people lacking the basic critical thinking skills necessary to spot issues - is a deadly combo.Of the problems with tasks and outcomes named in that thread, the large majority can indeed be done already with LLMs in a manner tha",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44809455,
    "by": "meindnoch",
    "timeISO": "2025-08-06T08:44:41.000Z",
    "textPlain": "In the future, only prestigious private schools will employ human teachers.Education in public schools is going to be 100% LLMs with text-to-speech, the only human adult in classrooms will be a security guard, but later they will also be replaced with AI-controlled autocannons that shoot non-lethal projectiles to discipline misbehaving kids.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44808944,
    "by": "crinkly",
    "timeISO": "2025-08-06T07:45:21.000Z",
    "textPlain": "So my daughter got sent home with some math questions. Thought they looked a bit dry but thought nothing further of it. I checked the answers for her which were all ok.Couple of days later she comes home and tells me I was wrong about some of them which I know I was not. Apparently they self marked them as the teacher read the answers out. Decided to phone in and ask about the marking scheme which I was told I was wrong too and basically I should have done better at GCSE mathematics.I relayed my mathematical credentials and immediately the tone changed. The discussion indicated that they’d generated the questions with CoPilot and then fed that back into CoPilot and generated the answer sheet which had two incorrect answers on it.The teacher and department head in question defended their position until I threatened to feed them to the examination board and leadership team. The following of the tech was almost zealot level religious thinking which is not something I want to see in education.I check all homework now carefully and there have been other issues since.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44810659,
    "by": "xrd",
    "timeISO": "2025-08-06T11:38:46.000Z",
    "textPlain": "It feels funny to think about this next to the outrage over trans kids in school sports. There are probably a dozen kids nationally participating in a sport with other kids who didn't share the same set of chromosomes at birth. That's a tiny slice of the population, but the issue has captured the attention of a huge group of people. I believe the anger, if you distill it a bit, comes from an \"unlevel\" playing field, right?But, when students use AI, and if there are some students that don't, the playing field is \"unlevel\" there as well. The students that don't perhaps want to learn a craft rather than take a shortcut to getting a grade. I would wager that the number of students and teachers using AI is now the majority population.I face this dilemma on a daily basis when trying to do my job as a software developer. Let claude take over, and risk losing the only skill I had to differentiate myself in this harsh world? Or, take a chance on being the turtle and trying to win the race against the hare?",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44810853,
    "by": "blibble",
    "timeISO": "2025-08-06T12:03:19.000Z",
    "textPlain": "first order effect of AI: the individual saves timesecond order effect: across the entire population, the incentive to learn anything at all is removedthird order effect: society ceases to improve and regressesbut it's all good as I can generate boilerplate 30% faster!",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44808733,
    "by": "fzeroracer",
    "timeISO": "2025-08-06T07:18:12.000Z",
    "textPlain": "Teachers using AI to generate all of their lesson material, read student papers and write comments.Students using AI to generate their papers and solve complex problems.What are we as humans even doing. Why not just connect two shitty models together and tell them to hallucinate to each other and skip the whole need to think about anything. We can fire both teachers and students at the same time and save money on this whole education thing.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44811205,
    "by": "jv22222",
    "timeISO": "2025-08-06T12:41:42.000Z",
    "textPlain": "FYI This school uses AI as teachers: https://alpha.school/santa-barbara/They say they have good results?",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44810443,
    "by": "5pl1n73r",
    "timeISO": "2025-08-06T11:06:02.000Z",
    "textPlain": "This is happening across all industries, unfortunately. Medical, engineering, pharmaceuticals, law enforcement, military, transportation, law... Thanks for a perfect post that describes the problem! We need more of these. Most people know they're doing it too, they just need to be told more.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44808458,
    "by": "EdwardDiego",
    "timeISO": "2025-08-06T06:35:45.000Z",
    "textPlain": "Interesting, Simon Williamson has been rather engaged with and positive about LLM usage, so it's good to see some nuance developing.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44810579,
    "by": "conartist6",
    "timeISO": "2025-08-06T11:28:07.000Z",
    "textPlain": "Often the LLM people read like they're five years old, discovering for the very first time what happens when you start to act out against society and root your moral calculus in deep cynicism",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44809789,
    "by": "looseyesterday",
    "timeISO": "2025-08-06T09:29:22.000Z",
    "textPlain": "In some cases teachers are being overworked and expected to deliver far beyond their capability. The issue I see here is that its Powerpoint / document generation AI tools often use older / cheaper / worse models e.g. 4o mini, instead of Claude opus or Gemini 2.5 pro. The second issue it is often hard for the original prompter to see issues in AI output, so another pair of eyes or a different LLM prompt with more context can often pick up most issues. I dont think AI use for teachers is going anywhere, we should work with the flow on this one and help teachers do their jobs more easily.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44810496,
    "by": "minraws",
    "timeISO": "2025-08-06T11:14:46.000Z",
    "textPlain": "So you mean to say now good prompt engineering can get me good grades...Well I guess as long as you have an idea which model your teacher uses you are golden.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44813464,
    "by": "xnx",
    "timeISO": "2025-08-06T15:37:42.000Z",
    "textPlain": "Considering that an auto-generated storybook (https://gemini.google.com/share/8d296b91b77b) taught me why 0.99999... = 1 more clearly and memorably than my \"good school district\" education, I'm optimistic what AI could do for education.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44814118,
    "by": "simianwords",
    "timeISO": "2025-08-06T16:21:48.000Z",
    "textPlain": "Hot take: ChatGPT’s performance is close enough to a teacher’s which is why this is a problem at all.Can some one answer what would realistically change if teachers did use ChatGPT in this way but the students never found out? Things would be more or less the same.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44811486,
    "by": "Myrmornis",
    "timeISO": "2025-08-06T13:10:04.000Z",
    "textPlain": "We need to pay teachers more if we're to effectively have this conversation.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44809435,
    "by": "password321",
    "timeISO": "2025-08-06T08:42:35.000Z",
    "textPlain": "Richard Feynman summed up public education well even if schools have ostensibly changed since: \"Everything was written by somebody who didn’t know what the hell he was talking about, so it was a little bit wrong, always!\".Now they just have an extra tool to help them.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44808465,
    "by": "sieste",
    "timeISO": "2025-08-06T06:36:40.000Z",
    "textPlain": "Teacher saved himself some time by using a chatbot to make a slideshow presentation for a staff meeting. Good!Teachers use chatbots for everything else, uncritically. Not good!",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44810680,
    "by": "Invictus0",
    "timeISO": "2025-08-06T11:41:33.000Z",
    "textPlain": "People need to realize that the next generation of kids is already unable to differentiate human vs llm generated text, and not only that, but they don't even mind it. They are already using LLMs to generate all their text and so they don't mind reading LLM generated text either.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44818385,
    "by": "readthenotes1",
    "timeISO": "2025-08-06T22:03:21.000Z",
    "textPlain": "The good news is that teaching via PowerPoint slides is probably one of the worst possible ways and so just making it repetitive won't disturb the students naps too much.If the teacher had asked AI what are more effective ways to ensure the students are learning the material, I really doubt a PowerPoint presentation would have been the result",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44808291,
    "by": "NoPicklez",
    "timeISO": "2025-08-06T06:09:41.000Z",
    "textPlain": "Fairy low quality post this one",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44808731,
    "by": "politelemon",
    "timeISO": "2025-08-06T07:17:32.000Z",
    "textPlain": "I suggest please link directly to the reddit thread, it has the original text (not a snippet) and lots of additional insights and anecdotes in the comments.https://np.reddit.com/r/Teachers/comments/1mhntjh/unpopular_...",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44810172,
    "by": "bigbacaloa",
    "timeISO": "2025-08-06T10:25:01.000Z",
    "textPlain": "[dead]",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44810154,
    "by": "bigbacaloa",
    "timeISO": "2025-08-06T10:22:01.000Z",
    "textPlain": "[dead]",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44809415,
    "by": "globular-toast",
    "timeISO": "2025-08-06T08:40:10.000Z",
    "textPlain": "Trains allowed us to go further than we could ever walk. Cars caused us to lose the ability to walk completely.Looms allowed us to produce fabrics of higher quality than we ever could by hand. Fast fashion caused us to lose the ability to care for and mend clothes completely.Computers allowed us to calculate and \"think\" faster than we ever could before. AI caused us to lose the ability to think completely...",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44808274,
    "by": "hanspeter",
    "timeISO": "2025-08-06T06:07:13.000Z",
    "textPlain": "Is there more to it, or are we calling the situation out of control based on a single anecdote from Reddit?",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44816274,
    "by": "j_timberlake",
    "timeISO": "2025-08-06T19:07:21.000Z",
    "textPlain": "AI just reveals how lazy/cheap/low-standards they were already trying to be.  And if AI keeps progressing at current speeds, those are the people who are going to be most easily replaced by AI-tutors within a few years.  The actually-good teachers would still have a job in a sane world, but who knows what will happen.",
    "parent": 44808122,
    "depth": 1
  },
  {
    "id": 44812153,
    "by": "4b11b4",
    "timeISO": "2025-08-06T13:59:55.000Z",
    "textPlain": "Have been thinking similar... well, that we'll see much smaller educational organizations which are funded/supported in much different ways.",
    "parent": 44809774,
    "depth": 2
  },
  {
    "id": 44811785,
    "by": "JohnKemeny",
    "timeISO": "2025-08-06T13:34:13.000Z",
    "textPlain": "Technology is making humankind lazy. First physically, then mentally.Learning is hard, it's a struggle. Why learn when you can not learn?",
    "parent": 44809774,
    "depth": 2
  },
  {
    "id": 44810452,
    "by": "jfarmer",
    "timeISO": "2025-08-06T11:07:17.000Z",
    "textPlain": "I sometimes find Paul Watzlawick's five axioms of communication helping in thinking about situations like this.Link: (https://en.wikipedia.org/wiki/Paul_Watzlawick#Five_basic_axi...)  1. One cannot not communicate\n\n  2. Every communication has a content and relationship\n     aspect such that the latter classifies the former\n     and is therefore a metacommunication\n\n  3. The nature of a relationship is dependent on the\n     punctuation of the partners' communication procedures\n\n  4. Human communication involves both digital and analog\n     modalities\n\n  5. Inter-human communication procedures are either\n     symmetric or complementary\n\nRe: (1), the \"mere\" act of using AI communicates something, just like some folks might register a text message as more (or less) intimate than a phone call, email, etc. The choice of modality is always part of what's communicated, part of the act of communication, and we can't stop that. Re: (2), that communication is then classified by each person's idea of what the relationship is.This is a dramatic and expensive way to learn they had different ideas of their relationship!Of course, in a teacher/student situation, it's the teacher's job to make it clear to the students what the relationship is. Otherwise you risk relationship-damaging \"surprises\" like this.Even ignoring the normative question of what a teacher Should™ do in that situation, it was counterproductive. Whatever benefit the teacher thought AI would provide, they'd (hopefully) agree it was outweighed by the cost to their relationship w/ students. All future interactions w/ those students will now be X% harder.There's a kind of technical rationale which says that if (1) the GOAL is to improve the student's output and (2) I would normally do that by giving one or more rounds of feedback and waiting for the student to incorporate it then (3) I should use AI because it will help us reach that goal faster and more efficiently.John Dewey described this rationale in Human Nature",
    "parent": 44808884,
    "depth": 2
  },
  {
    "id": 44810614,
    "by": "amelius",
    "timeISO": "2025-08-06T11:32:53.000Z",
    "textPlain": "In another view, this prepares the kids for what the future is going to be like.",
    "parent": 44808884,
    "depth": 2
  },
  {
    "id": 44808948,
    "by": "chii",
    "timeISO": "2025-08-06T07:45:33.000Z",
    "textPlain": "however, this same action could be useful if it was placed in a different context - for example, if the teacher uses the same AI to produce an artefact, then use it to critique the student as part of teaching (say, to show what might be lacking in a particular piece).",
    "parent": 44808884,
    "depth": 2
  },
  {
    "id": 44809674,
    "by": "tovej",
    "timeISO": "2025-08-06T09:15:05.000Z",
    "textPlain": "Using LLMs to produce material is not a good idea, except maybe to polish up grammar and phrasing.As a former teacher, I know you need to have a good grasp of the material you are using in order to help students understand it. The material should also be in a similarly structured form thoughout a course, which will reinforce the expectations of the students, making their mental load lesser. The only way to do this is to prepare the material yourself.Material created by LLM will have the issues you mentioned, yes, but it will also be less easy to teach, for the reasons mentioned above. In the US, where teaching is already in a terrible state, I wouldn't be surprised if this is accepted quietly, but it will have a long lasting negative impact on learning outcomes.If we project this forward, a reliance on AI tools might also create a lower expectation of the quality of  the material, which will drag the rest of the material down as well. This mirrors the rise of expendable mass produced products when we moved the knowledge needed to produce goods from workers to factory machines.Commodities are one thing, you could argue that the decrease in quality is offset by volume (I wouldn't, but you could), but for teaching? Not a good idea. At most, let the students know how to use LLMs to look for information, and warn them of hallucinations and not being able to find the sources.",
    "parent": 44809561,
    "depth": 2
  },
  {
    "id": 44810730,
    "by": "grues-dinner",
    "timeISO": "2025-08-06T11:47:30.000Z",
    "textPlain": "Drone-based school security with flash bangs, pepper spray and physical dive-bombing of the attacker is already the plan: https://www.campusguardianangel.com/Just add a student compliance add-on subscription.",
    "parent": 44809455,
    "depth": 2
  },
  {
    "id": 44809506,
    "by": "password321",
    "timeISO": "2025-08-06T08:50:59.000Z",
    "textPlain": "Nah by that point people won't have a reason to drop them their children off to a glorified daycare designed to condition them to work quietly for a set amount of hours because we won't need to work anymore.",
    "parent": 44809455,
    "depth": 2
  },
  {
    "id": 44812887,
    "by": "someuser2345",
    "timeISO": "2025-08-06T14:56:28.000Z",
    "textPlain": "> I believe the anger, if you distill it a bit, comes from an \"unlevel\" playing field, right?Why is \"unlevel\" in quotes? When it comes to physical activities, biological males have a huge advantage over biological females; high school boys routinely beat professional adult women's sport teams.> But, when students use AI, and if there are some students that don't, the playing field is \"unlevel\" there as well. The students that don't perhaps want to learn a craft rather than take a shortcut to getting a grade.I agree that this is a bigger problem than trans kids in sports. I think people are less upset about this because1. It's a more recent development\n2. They think that the kids using AI are actually putting themselves at a disadvantage, albeit one that will only become apparent after they graduate.",
    "parent": 44810659,
    "depth": 2
  }
]