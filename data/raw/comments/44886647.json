[
  {
    "id": 44887584,
    "by": "kmfrk",
    "timeISO": "2025-08-13T12:24:59.000Z",
    "textPlain": "Whisper is genuinely amazing - with the right nudging. It's the one AI thing that has genuinely turned my life upside-down in an unambiguously good way.People should check out Subtitle Edit (and throw the dev some money) which is a great interface for experimenting with Whisper transcription. It's basically Aegisub 2.0, if you're old, like me.HOWTO:Drop a video or audio file to the right window, then go to Video > Audio to text (Whisper). I get the best results with Faster-Whisper-XXL. Use large-v2 if you can (v3 has some regressions), and you've got an easy transcription and translation workflow. The results aren't perfect, but Subtitle Edit is for cleaning up imperfect transcripts with features like Tools > Fix common errors.EDIT: Oh, and if you're on the current gen of Nvidia card, you might have to add \"--compute_type float32\" to make the transcription run correctly. I think the error is about an empty file, output or something like that.EDIT2: And if you get another error, possibly about whisper.exe, iirc I had to reinstall the Torch libs from a specific index like something along these lines (depending on whether you use pip or uv):    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n    uv pip install --system torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\nIf you get the errors and the above fixes work, please type your error message in a reply with what worked to help those who come after. Or at least the web crawlers for those searching for help.https://www.nikse.dk/subtitleedithttps://www.nikse.dk/donatehttps://github.com/SubtitleEdit/subtitleedit/releases",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886963,
    "by": "Lio",
    "timeISO": "2025-08-13T11:03:10.000Z",
    "textPlain": "Once local transcription is in more places hopefully we can persuade content creator not to burn bouncing sub-titles into their videos.I've seen professionally produced recordings on dry and technical subjects with good sound quality where they've decided to use distracting sub-titles with no way to disable them.It seems so unnecessary if you're not making novelty videos about cats.Also local transcription allows for automatic translation and again overlaying subtitles on top of an existing burnt in set is a really poor reading experience.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886838,
    "by": "londons_explore",
    "timeISO": "2025-08-13T10:48:52.000Z",
    "textPlain": "Does this have the ability to edit historic words as more info becomes available?Eg. If I say \"I scream\", it sounds phonetically identical to \"Ice cream\".Yet the transcription of \"I scream is the best dessert\" makes a lot less sense than \"Ice cream is the best dessert\".Doing this seems necessary to have both low latency and high accuracy, and things like transcription on android do that and you can see the adjusting guesses as you talk.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887793,
    "by": "JohnKemeny",
    "timeISO": "2025-08-13T12:47:11.000Z",
    "textPlain": "Related, a blog article by the author of the patch:Run Whisper audio transcriptions with one FFmpeg commandhttps://medium.com/@vpalmisano/run-whisper-audio-transcripti...Posted here, with 0 comments:\nhttps://news.ycombinator.com/item?id=44869254",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44892872,
    "by": "hbn",
    "timeISO": "2025-08-13T19:40:19.000Z",
    "textPlain": "I wonder if Apple's upcoming speech APIs can be added too. Would be cool to have it just work out of the box on Macs, without needing to source a model.https://developer.apple.com/documentation/speech/speechtrans...https://developer.apple.com/documentation/speech/speechanaly...https://www.macstories.net/stories/hands-on-how-apples-new-s...",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886785,
    "by": "voxadam",
    "timeISO": "2025-08-13T10:40:59.000Z",
    "textPlain": "Am I correct in understanding that Whisper is a speech recognition AI model originally created by OpenAI?https://en.wikipedia.org/wiki/Whisper_(speech_recognition_sy...",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44891709,
    "by": "sorenjan",
    "timeISO": "2025-08-13T18:00:54.000Z",
    "textPlain": "I hope this is the start of more ML filters in ffmpeg. They added the sr (super resolution) filter years ago, but it's old and it's difficult to get the weights so you can run it, since they're not included. They have added support for multiple inference libraries like libtorch, but again, it's difficult to even get started. Hopefully they can get behind a consistent ML strategy, ideally with a \"models\" directory with ready to use models for upscaling, temporal upscaling, noise cancelling, etc. A lot of audio and video filter research use ML now, new codecs will probably also use it soon.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887159,
    "by": "donatj",
    "timeISO": "2025-08-13T11:31:36.000Z",
    "textPlain": "I know nothing about Whisper, is this usable for automated translation?I own a couple very old and as far as I'm aware never translated Japanese movies. I don't speak Japanese but I'd love to watch them.A couple years ago I had been negotiating with a guy on Fiver to translate them. At his usual rate-per-minute of footage it would have cost thousands of dollars but I'd negotiated him down to a couple hundred before he presumably got sick of me and ghosted me.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887801,
    "by": "webinar",
    "timeISO": "2025-08-13T12:47:42.000Z",
    "textPlain": "I've been using FFmpeg and Whisper to record and transcribe live police scanner audio for my city, and update it in real-time to a live website.  It works great, with the expected transcription errors and hallucinations.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44892004,
    "by": "manca",
    "timeISO": "2025-08-13T18:24:19.000Z",
    "textPlain": "The only problem with this PR/diff is that it creates just a avfilter wrapper around whisper.cpp library and requires the user to manage the dependencies on their own. This is not helpful for novice users who will first need to:1. git clone whisper.cpp2. Make sure they have all dependencies for `that` library3. Hope the build passes4. Download the actual modelAND only then be able to use `-af \"whisper=model...` filter.If they try to use the filter without all the prereqs they'll fail and it'll create frustration.It'd be better to natively create a Whisper avfilter and only require the user to download the model -- I feel like this would streamline the whole process and actually make people use it much more.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886951,
    "by": "instagraham",
    "timeISO": "2025-08-13T11:01:29.000Z",
    "textPlain": "Does this mean that any software which uses ffmpeg can now add a transcription option? Audacity, Chrome, OBS etc",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44896294,
    "by": "atum47",
    "timeISO": "2025-08-14T02:54:33.000Z",
    "textPlain": "It failed to identify me as a human twice before let me access the page",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44888471,
    "by": "realxrobau",
    "timeISO": "2025-08-13T13:52:23.000Z",
    "textPlain": "Annoyingly, something is broken with their anti not stuff, as it keeps refusing to let me see the page.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886783,
    "by": "lawik",
    "timeISO": "2025-08-13T10:40:54.000Z",
    "textPlain": "I wonder if they'll be satisfied there or add a chunk of others now that they've started. Parakeet is supposed to be good?Should they add Voice Activity Detection? Are these separate filters or just making the whisper filter more fancy?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887044,
    "by": "zoobab",
    "timeISO": "2025-08-13T11:15:50.000Z",
    "textPlain": "Not sure it will be packaged in Debian, with an external binary model god knows how it was produced...",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886776,
    "by": "boutell",
    "timeISO": "2025-08-13T10:40:03.000Z",
    "textPlain": "Shut off the broken bot filter so we can read it please",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44895923,
    "by": "baxter001",
    "timeISO": "2025-08-14T01:49:15.000Z",
    "textPlain": "More precisely libavfilter, so it's also soon in mpv and other dependent players.This is going to be great for real-time audio translation.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886878,
    "by": "bondarchuk",
    "timeISO": "2025-08-13T10:53:09.000Z",
    "textPlain": "Can whisper do multilingual yet? Last time I tried it on some mixed dutch/english text it would spit out english translations for some of the dutch text. Strange bug/feature since from all appearances it had understood the dutch text perfectly fine.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44892710,
    "by": "jd3",
    "timeISO": "2025-08-13T19:27:09.000Z",
    "textPlain": "took me longer than i'd care to admit to figure out how to install whisper as a user/system package on macOS w/o brew (which pulls in all of llvm@16 during install)    brew install uv\n    uv tool install openai-whisper\n    then add ~/.local/bin/ to $PATH",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44892231,
    "by": "cheerioty",
    "timeISO": "2025-08-13T18:45:00.000Z",
    "textPlain": "OH: \"New changelog entries go to the bottom, @vpalmisano .. Didn't I tell you this once?\"",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44890140,
    "by": "miladyincontrol",
    "timeISO": "2025-08-13T15:56:13.000Z",
    "textPlain": "on an aside, my favorite whisper 'hack' is you can just speed up audio 10x to process it 10x faster, then adjust the timings after",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886766,
    "by": "zzsshh",
    "timeISO": "2025-08-13T10:38:43.000Z",
    "textPlain": "Does this finally enable dynamically generating subtitles for movies with AI?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44890375,
    "by": "WanderPanda",
    "timeISO": "2025-08-13T16:13:53.000Z",
    "textPlain": "Is Whisper still SOTA 3 years later? It does not seem there is a clearly better open model. Alec Radford really is a genius!",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886854,
    "by": "re",
    "timeISO": "2025-08-13T10:51:14.000Z",
    "textPlain": "I've been playing with whisper to try to do local transcription of long videos, but one issue I've found is that long (>15 seconds) spans without any speech tend to send it into a hallucination loops that it often can't recover from. I wonder if, with direct integration into ffmpeg, they will be able to configure it in a way that can improve that situation.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886891,
    "by": "yewenjie",
    "timeISO": "2025-08-13T10:54:17.000Z",
    "textPlain": "I have recently found that parakeet from NVIDIA is way faster and pretty much as correct as Whisper, but it only works with English.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887984,
    "by": "MaxikCZ",
    "timeISO": "2025-08-13T13:08:41.000Z",
    "textPlain": "I tried to use whisper to generate non-english subs from english audio, but wasnt able to figure out. I know it can do english subs from non-english audio, and that earlier (less precise) versions could do any language audio -> any language subs, but latest whisper only to english subs.Anyone found a way?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44893968,
    "by": "XCSme",
    "timeISO": "2025-08-13T21:17:59.000Z",
    "textPlain": "Unrelated, but can I use Whisper in DaVinci resolve to automatically transcribe my videos and add subs?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44889746,
    "by": "iambvk",
    "timeISO": "2025-08-13T15:28:39.000Z",
    "textPlain": "Is anyone able to get streaming audio to text conversion working with whisper.cpp?I tried several times to get this into a reasonable shape, but all have been failures. If anyone has pointers I really appreciate it.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886779,
    "by": "kwar13",
    "timeISO": "2025-08-13T10:40:21.000Z",
    "textPlain": "Fantastic! I am working on a speech-to-text GNOME extension that would immensely benefit from this.https://github.com/kavehtehrani/gnome-speech2text",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44892352,
    "by": "igorguerrero",
    "timeISO": "2025-08-13T18:55:03.000Z",
    "textPlain": "Aww, I literally just implemented this using whisper.cpp and ffmpeg lib, code is even similar...",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887932,
    "by": "porridgeraisin",
    "timeISO": "2025-08-13T13:03:11.000Z",
    "textPlain": "I had a small bash pipeline for doing this until now.  ffmpeg -f pulse -i \"$(pactl get-default-source)\" -t 5 -f wav -ar 16000 -ac 1 -c:a pcm_s16le - \\\n  | ./main - \\\n  | head -2 \\\n  | tail -1 \\\n  | cut -d] -f2 \\\n  | awk '{$1=$1};1'\n\nThe reading from mic part (-f pulse, pactl...) is linux-specific rest of it should be cross platform. The `main` executable is the whisper.cpp executable (see whisper.cpp github readme, it's just the output of `make base.en` from that).Edit: -t 5 controls recording duration.Oh and add 2>/dev/null to silence the debug output. I copied this from a pipe that further sends it into an LLM that  then looks at the meaning and turns it into a variety of structured data (reminders, todo items, etc) which I then....",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887203,
    "by": "mockingloris",
    "timeISO": "2025-08-13T11:36:10.000Z",
    "textPlain": "How could one in theory, use this to train on a new language?\nSay for a hubby project; I have recordings of some old folks stories in my local dialect.│└── Dey well; Be well",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887121,
    "by": "martzoukos",
    "timeISO": "2025-08-13T11:25:36.000Z",
    "textPlain": "I guess that there is no streaming option for sending generated tokens to, say, an LLM service to process the text in real-time.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44890883,
    "by": "superkuh",
    "timeISO": "2025-08-13T16:55:07.000Z",
    "textPlain": "\"Making sure you're not a bot!\" with no way to get to the actual document that is supposed to be at the URL. Anubis can be configured to be accessible for people without the latest computers by using the meta-refresh proof of work but very few people take any time to configure it and just deploy the defaults. Just like with cloudflare.That said, I suppose I'm glad they're concentrating on making the ffmpeg code better rather than fixing bugs in the web interface for the development tracker. Having whisper integrated will be really useful. I'm already imagining automatic subtitle generation... imagining because I can't read the page or the code to know what it is.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44889892,
    "by": "dotancohen",
    "timeISO": "2025-08-13T15:38:08.000Z",
    "textPlain": "Why would one use FFmpeg with Whisper support, instead of using Whisper directly?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44890568,
    "by": "jhatemyjob",
    "timeISO": "2025-08-13T16:28:21.000Z",
    "textPlain": "I wish they worked with the mpv folks instead of shoehorning this in. Based on the docs it looks like getting live transcription for a video will involve running the demuxer/decoder on one thread, and this whisper filter on another thread, using ffmpeg's AVIO (or to a REST API [1].... shudders) to synchronize those two parallel jobs. It could have been way simpler.Other than for the \"live transcription\" usecase (that they made unnecessarily complicated), I don't see how this is any better than running Whisper.cpp directly. Other people in this thread are basically saying \"ffmpeg's interface is better understood\" [2] but LLMs make that point moot since you can just ask them to do the drudgery for you.[1] https://medium.com/@vpalmisano/run-whisper-audio-transcripti...[2] https://news.ycombinator.com/item?id=44890067",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44895046,
    "by": "BiteCode_dev",
    "timeISO": "2025-08-13T23:20:39.000Z",
    "textPlain": "What's the benefit VS using whisper as a separate tool?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44889083,
    "by": "mkbkn",
    "timeISO": "2025-08-13T14:41:02.000Z",
    "textPlain": "How can I run Whisper or this software in Linux or Android as a non-technical user?Basically a simple audio-to-text for personal use?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44889071,
    "by": "de6u99er",
    "timeISO": "2025-08-13T14:40:11.000Z",
    "textPlain": "That's great. How does Whisper compare to Google Gemini's transcription capabilities?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44890202,
    "by": "yieldcrv",
    "timeISO": "2025-08-13T16:01:05.000Z",
    "textPlain": "Labeling multiple people talking is something i found lacking with whisper, is it better now?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44888960,
    "by": "shmerl",
    "timeISO": "2025-08-13T14:31:17.000Z",
    "textPlain": "Did ffmpeg move their bug tracker to Forgejo?https://code.ffmpeg.org/FFmpeg/FFmpeg/issuesI still see their old one too, but Forgejo one is nice.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887816,
    "by": "thedangler",
    "timeISO": "2025-08-13T12:50:10.000Z",
    "textPlain": "Does this whisper also do text-to-speech?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887542,
    "by": "dncornholio",
    "timeISO": "2025-08-13T12:20:19.000Z",
    "textPlain": "I was expecting a lot more comments on if this is a necessary feature or if this even belongs in a library like ffmpeg. I think this is bloat, especially when the feature doesn't work flawless, whisper is very limited.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44888575,
    "by": "pmarreck",
    "timeISO": "2025-08-13T14:01:38.000Z",
    "textPlain": "Now if it only did separate speaker identification (diarization)",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44888574,
    "by": "correa_brian",
    "timeISO": "2025-08-13T14:01:30.000Z",
    "textPlain": "hell yeah",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44888479,
    "by": "hacker_88",
    "timeISO": "2025-08-13T13:53:14.000Z",
    "textPlain": "[dead]",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886762,
    "by": "ggap",
    "timeISO": "2025-08-13T10:37:51.000Z",
    "textPlain": "Very interesting to see this!",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44888591,
    "by": "notatallshaw",
    "timeISO": "2025-08-13T14:02:58.000Z",
    "textPlain": ">     uv pip install --system torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118uv has a feature to get the correct version of torch based on your available cuda (and some non-cuda) drivers (though I suggest using a venv not the system Python):> uv pip install torch torchvision torchaudio --torch-backend=autoMore details: https://docs.astral.sh/uv/guides/integration/pytorch/#automa...This also means you can safely mix torch requirements with non-torch requirements as it will only pull the torch related things from the torch index and everything else from PyPI.",
    "parent": 44887584,
    "depth": 2
  },
  {
    "id": 44887799,
    "by": "tossit444",
    "timeISO": "2025-08-13T12:47:39.000Z",
    "textPlain": "Aegisub is still actively developed (forked), and imo, both software can't really be compared to one another. They can complement each other, but SE is much better for actual transcription. Aegisub still does the heavy lifting for typesetting and the like.",
    "parent": 44887584,
    "depth": 2
  },
  {
    "id": 44888298,
    "by": "pawelduda",
    "timeISO": "2025-08-13T13:38:54.000Z",
    "textPlain": "Can you give an example why it made your life that much better?",
    "parent": 44887584,
    "depth": 2
  }
]