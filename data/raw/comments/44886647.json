[
  {
    "id": 44887584,
    "by": "kmfrk",
    "timeISO": "2025-08-13T12:24:59.000Z",
    "textPlain": "Whisper is genuinely amazing - with the right nudging. It's the one AI thing that has genuinely turned my life upside-down in an unambiguously good way.People should check out Subtitle Edit (and throw the dev some money) which is a great interface for experimenting with Whisper transcription. It's basically Aegisub 2.0, if you're old, like me.HOWTO:Drop a video or audio file to the right window, then go to Video > Audio to text (Whisper). I get the best results with Faster-Whisper-XXL. Use large-v2 if you can (v3 has some regressions), and you've got an easy transcription and translation workflow. The results aren't perfect, but Subtitle Edit is for cleaning up imperfect transcripts with features like Tools > Fix common errors.EDIT: Oh, and if you're on the current gen of Nvidia card, you might have to add \"--compute_type float32\" to make the transcription run correctly. I think the error is about an empty file, output or something like that.EDIT2: And if you get another error, possibly about whisper.exe, iirc I had to reinstall the Torch libs from a specific index like something along these lines (depending on whether you use pip or uv):    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n    uv pip install --system torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\nIf you get the errors and the above fixes work, please type your error message in a reply with what worked to help those who come after. Or at least the web crawlers for those searching for help.https://www.nikse.dk/subtitleedithttps://www.nikse.dk/donatehttps://github.com/SubtitleEdit/subtitleedit/releases",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886838,
    "by": "londons_explore",
    "timeISO": "2025-08-13T10:48:52.000Z",
    "textPlain": "Does this have the ability to edit historic words as more info becomes available?Eg. If I say \"I scream\", it sounds phonetically identical to \"Ice cream\".Yet the transcription of \"I scream is the best dessert\" makes a lot less sense than \"Ice cream is the best dessert\".Doing this seems necessary to have both low latency and high accuracy, and things like transcription on android do that and you can see the adjusting guesses as you talk.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886963,
    "by": "Lio",
    "timeISO": "2025-08-13T11:03:10.000Z",
    "textPlain": "Once local transcription is in more places hopefully we can persuade content creator not to burn bouncing sub-titles into their videos.I've seen professionally produced recordings on dry and technical subjects with good sound quality where they've decided to use distracting sub-titles with no way to disable them.It seems so unnecessary if you're not making novelty videos about cats.Also local transcription allows for automatic translation and again overlaying subtitles on top of an existing burnt in set is a really poor reading experience.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886785,
    "by": "voxadam",
    "timeISO": "2025-08-13T10:40:59.000Z",
    "textPlain": "Am I correct in understanding that Whisper is a speech recognition AI model originally created by OpenAI?https://en.wikipedia.org/wiki/Whisper_(speech_recognition_sy...",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887793,
    "by": "JohnKemeny",
    "timeISO": "2025-08-13T12:47:11.000Z",
    "textPlain": "Related, a blog article by the author of the patch:Run Whisper audio transcriptions with one FFmpeg commandhttps://medium.com/@vpalmisano/run-whisper-audio-transcripti...Posted here, with 0 comments:\nhttps://news.ycombinator.com/item?id=44869254",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887984,
    "by": "MaxikCZ",
    "timeISO": "2025-08-13T13:08:41.000Z",
    "textPlain": "I tried to use whisper to generate non-english subs from english audio, but wasnt able to figure out. I know it can do english subs from non-english audio, and that earlier (less precise) versions could do any language audio -> any language subs, but latest whisper only to english subs.Anyone found a way?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886951,
    "by": "instagraham",
    "timeISO": "2025-08-13T11:01:29.000Z",
    "textPlain": "Does this mean that any software which uses ffmpeg can now add a transcription option? Audacity, Chrome, OBS etc",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887159,
    "by": "donatj",
    "timeISO": "2025-08-13T11:31:36.000Z",
    "textPlain": "I know nothing about Whisper, is this usable for automated translation?I own a couple very old and as far as I'm aware never translated Japanese movies. I don't speak Japanese but I'd love to watch them.A couple years ago I had been negotiating with a guy on Fiver to translate them. At his usual rate-per-minute of footage it would have cost thousands of dollars but I'd negotiated him down to a couple hundred before he presumably got sick of me and ghosted me.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887044,
    "by": "zoobab",
    "timeISO": "2025-08-13T11:15:50.000Z",
    "textPlain": "Not sure it will be packaged in Debian, with an external binary model god knows how it was produced...",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887801,
    "by": "webinar",
    "timeISO": "2025-08-13T12:47:42.000Z",
    "textPlain": "I've been using FFmpeg and Whisper to record and transcribe live police scanner audio for my city, and update it in real-time to a live website.  It works great, with the expected transcription errors and hallucinations.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886878,
    "by": "bondarchuk",
    "timeISO": "2025-08-13T10:53:09.000Z",
    "textPlain": "Can whisper do multilingual yet? Last time I tried it on some mixed dutch/english text it would spit out english translations for some of the dutch text. Strange bug/feature since from all appearances it had understood the dutch text perfectly fine.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886854,
    "by": "re",
    "timeISO": "2025-08-13T10:51:14.000Z",
    "textPlain": "I've been playing with whisper to try to do local transcription of long videos, but one issue I've found is that long (>15 seconds) spans without any speech tend to send it into a hallucination loops that it often can't recover from. I wonder if, with direct integration into ffmpeg, they will be able to configure it in a way that can improve that situation.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887932,
    "by": "porridgeraisin",
    "timeISO": "2025-08-13T13:03:11.000Z",
    "textPlain": "I had a small bash pipeline for doing this until now.  ffmpeg -f pulse -i \"$(pactl get-default-source)\" -t 5 -f wav -ar 16000 -ac 1 -c:a pcm_s16le - \\\n  | ./main - \\\n  | head -2 \\\n  | tail -1 \\\n  | cut -d] -f2 \\\n  | awk '{$1=$1};1'\n\nThe reading from mic part (-f pulse, pactl...) is linux-specific rest of it should be cross platform. The `main` executable is the whisper.cpp executable (see whisper.cpp github readme, it's just the output of `make base.en` from that)Oh and add 2>/dev/null to silence the debug output. I copied this from a pipe that further sends it into an LLM that  then looks at the meaning and turns it into a variety of structured data (reminders, todo items, etc) which I then....",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887816,
    "by": "thedangler",
    "timeISO": "2025-08-13T12:50:10.000Z",
    "textPlain": "Does this whisper also do text-to-speech?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887203,
    "by": "mockingloris",
    "timeISO": "2025-08-13T11:36:10.000Z",
    "textPlain": "How could one in theory, use this to train on a new language?\nSay for a hubby project; I have recordings of some old folks stories in my local dialect.│└── Dey well; Be well",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886783,
    "by": "lawik",
    "timeISO": "2025-08-13T10:40:54.000Z",
    "textPlain": "I wonder if they'll be satisfied there or add a chunk of others now that they've started. Parakeet is supposed to be good?Should they add Voice Activity Detection? Are these separate filters or just making the whisper filter more fancy?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886766,
    "by": "zzsshh",
    "timeISO": "2025-08-13T10:38:43.000Z",
    "textPlain": "Does this finally enable dynamically generating subtitles for movies with AI?",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887121,
    "by": "martzoukos",
    "timeISO": "2025-08-13T11:25:36.000Z",
    "textPlain": "I guess that there is no streaming option for sending generated tokens to, say, an LLM service to process the text in real-time.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886891,
    "by": "yewenjie",
    "timeISO": "2025-08-13T10:54:17.000Z",
    "textPlain": "I have recently found that parakeet from NVIDIA is way faster and pretty much as correct as Whisper, but it only works with English.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887542,
    "by": "dncornholio",
    "timeISO": "2025-08-13T12:20:19.000Z",
    "textPlain": "I was expecting a lot more comments on if this is a necessary feature or if this even belongs in a library like ffmpeg. I think this is bloat, especially when the feature doesn't work flawless, whisper is very limited.",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886779,
    "by": "kwar13",
    "timeISO": "2025-08-13T10:40:21.000Z",
    "textPlain": "Fantastic! I am working on a speech-to-text GNOME extension that would immensely benefit from this.https://github.com/kavehtehrani/gnome-speech2text",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886776,
    "by": "boutell",
    "timeISO": "2025-08-13T10:40:03.000Z",
    "textPlain": "Shut off the broken bot filter so we can read it please",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44886762,
    "by": "ggap",
    "timeISO": "2025-08-13T10:37:51.000Z",
    "textPlain": "Very interesting to see this!",
    "parent": 44886647,
    "depth": 1
  },
  {
    "id": 44887799,
    "by": "tossit444",
    "timeISO": "2025-08-13T12:47:39.000Z",
    "textPlain": "Aegisub is still actively developed (forked), and imo, both software can't really be compared to one another. They can complement each other, but SE is much better for actual transcription. Aegisub still does the heavy lifting for typesetting and the like.",
    "parent": 44887584,
    "depth": 2
  },
  {
    "id": 44887615,
    "by": "yvdriess",
    "timeISO": "2025-08-13T12:27:31.000Z",
    "textPlain": "A good opportunity to point people to the paper with my favorite title of all time:\"How to wreck a nice beach you sing calm incense\"https://dl.acm.org/doi/10.1145/1040830.1040898",
    "parent": 44886838,
    "depth": 2
  },
  {
    "id": 44887817,
    "by": "Fluorescence",
    "timeISO": "2025-08-13T12:50:24.000Z",
    "textPlain": "It makes me curious about how human subtitlers or even scriptwriters choose to transcribe intentionally ambiguous speech, puns and narratively important mishearings. It's like you need to subtitle what is heard not what is said.Do those born profoundly deaf specifically study word sounds in order to understand/create puns, rhymes and such so they don't need assistance understanding narrative mishearings?It must feel like a form of abstract mathematics without the experiential component... but then I suspect mathematicians manufacture an experiential phenomena with their abstractions with their claims of a beauty like music... hmm!",
    "parent": 44886838,
    "depth": 2
  },
  {
    "id": 44886880,
    "by": "ph4evers",
    "timeISO": "2025-08-13T10:53:20.000Z",
    "textPlain": "Whisper works on 30 second chunks. So yes it can do that and that’s also why it can hallucinate quite a bit.",
    "parent": 44886838,
    "depth": 2
  },
  {
    "id": 44887204,
    "by": "lgessler",
    "timeISO": "2025-08-13T11:36:28.000Z",
    "textPlain": "I recommend having a look at 16.3 onward here if you're curious about this: https://web.stanford.edu/~jurafsky/slp3/16.pdfI'm not familiar with Whisper in particular, but typically what happens in an ASR model is that the decoder, speaking loosely, sees \"the future\" (i.e. the audio after the chunk it's trying to decode) in a sentence like this, and also has the benefit of a language model guiding its decoding so that grammatical productions like \"I like ice cream\" are favored over \"I like I scream\".",
    "parent": 44886838,
    "depth": 2
  },
  {
    "id": 44886990,
    "by": "shaunpud",
    "timeISO": "2025-08-13T11:07:08.000Z",
    "textPlain": "I Scream in the Sun\nhttps://carmageddon.fandom.com/wiki/I_Scream_in_the_Sun",
    "parent": 44886838,
    "depth": 2
  },
  {
    "id": 44887002,
    "by": "DiogenesKynikos",
    "timeISO": "2025-08-13T11:09:49.000Z",
    "textPlain": "This is what your brain does when it processes language.I find that in languages I don't speak well, my ability to understand degrades much more quickly as the audio quality goes down. But in my native language, even with piss poor audio quality, my brain fills in the garbled words with its prior expectation of what those words should be, based on context.",
    "parent": 44886838,
    "depth": 2
  },
  {
    "id": 44887563,
    "by": "didacusc",
    "timeISO": "2025-08-13T12:22:39.000Z",
    "textPlain": "what would it make of this? https://www.youtube.com/watch?v=zyvZUxnIC3k",
    "parent": 44886838,
    "depth": 2
  },
  {
    "id": 44887425,
    "by": "ambicapter",
    "timeISO": "2025-08-13T12:06:51.000Z",
    "textPlain": "They do that because it increases “engagement”, not because they care about the user’s experience with the subtitles.",
    "parent": 44886963,
    "depth": 2
  },
  {
    "id": 44887805,
    "by": "whywhywhywhy",
    "timeISO": "2025-08-13T12:48:30.000Z",
    "textPlain": "Algorithm boosts it that’s why they do it. Even if every device had real time 100% accurate subtitling built in they’d still do it if they video performs better with it.",
    "parent": 44886963,
    "depth": 2
  },
  {
    "id": 44886980,
    "by": "HPsquared",
    "timeISO": "2025-08-13T11:05:41.000Z",
    "textPlain": "The other problem with burned-in subtitles is you can't change the language.",
    "parent": 44886963,
    "depth": 2
  },
  {
    "id": 44887123,
    "by": "preisschild",
    "timeISO": "2025-08-13T11:25:47.000Z",
    "textPlain": "They could also just upload those transcriptions as normal closed-captioning srt subtitles...",
    "parent": 44886963,
    "depth": 2
  },
  {
    "id": 44887583,
    "by": "dzhiurgis",
    "timeISO": "2025-08-13T12:24:56.000Z",
    "textPlain": "It's just so annyoing how someone like Netflix offers like 3-4 languages for most of its content when you can basically get it for free via browser extensions (if you watch on browser).Must be union thing.",
    "parent": 44886963,
    "depth": 2
  },
  {
    "id": 44886805,
    "by": "Maxious",
    "timeISO": "2025-08-13T10:44:13.000Z",
    "textPlain": "yep, there's a c++ implementation to run it https://github.com/ggml-org/whisper.cpp",
    "parent": 44886785,
    "depth": 2
  },
  {
    "id": 44886802,
    "by": "johnisgood",
    "timeISO": "2025-08-13T10:43:51.000Z",
    "textPlain": "Yes.From the documentation:> It runs automatic speech recognition using the OpenAI's Whisper model.",
    "parent": 44886785,
    "depth": 2
  },
  {
    "id": 44886796,
    "by": "acidburnNSA",
    "timeISO": "2025-08-13T10:43:06.000Z",
    "textPlain": "Yes, according to the comments in the patch, you are correct.",
    "parent": 44886785,
    "depth": 2
  },
  {
    "id": 44886857,
    "by": "cess11",
    "timeISO": "2025-08-13T10:51:16.000Z",
    "textPlain": "Kind of, it's a family of audio transcription models.https://huggingface.co/search/full-text?q=whisper",
    "parent": 44886785,
    "depth": 2
  },
  {
    "id": 44886814,
    "by": "AlienRobot",
    "timeISO": "2025-08-13T10:45:32.000Z",
    "textPlain": "I think so, if I remember correctly PotPlayer also supports it for automatic subtitling.",
    "parent": 44886785,
    "depth": 2
  },
  {
    "id": 44886799,
    "by": "kwar13",
    "timeISO": "2025-08-13T10:43:26.000Z",
    "textPlain": "yes.",
    "parent": 44886785,
    "depth": 2
  },
  {
    "id": 44888072,
    "by": "abdusco",
    "timeISO": "2025-08-13T13:18:12.000Z",
    "textPlain": "I solved it by generating English subtitles, then passing those to an LLM in chunks that are ~20 entries in size. Replace the timestamps with simple integers and include preceding and following subtitles as context for better translation. Make sure to replace the timestamps with simple integer ids, because LLMs like to mangle those, no matter how hard you prompt.I could share a python script that is working pretty reliably for me.",
    "parent": 44887984,
    "depth": 2
  },
  {
    "id": 44887008,
    "by": "ks2048",
    "timeISO": "2025-08-13T11:10:57.000Z",
    "textPlain": "If they want to support it out-of-the box, they'll still have to embed a model file (roughly 500 MB - 3GB, varying size and quality)",
    "parent": 44886951,
    "depth": 2
  },
  {
    "id": 44887840,
    "by": "ethan_smith",
    "timeISO": "2025-08-13T12:53:03.000Z",
    "textPlain": "Whisper can indeed transcribe Japanese and translate it to English, though quality varies by dialect and audio clarity. You'll need the \"large-v3\" model for best results, and you can use ffmpeg's new integration with a command like `ffmpeg -i movie.mp4 -af whisper=model=large-v3:task=translate output.srt`.",
    "parent": 44887159,
    "depth": 2
  },
  {
    "id": 44887359,
    "by": "prmoustache",
    "timeISO": "2025-08-13T11:57:02.000Z",
    "textPlain": "My personnal experience trying to transcribe (not translate) was a complete failure. The thing would invent stuff. It would also be completely lost when more than one language is used.It also doesn't understand contexts so does a lot of errors you see in automatic translations from videos in youtube for example.",
    "parent": 44887159,
    "depth": 2
  },
  {
    "id": 44887336,
    "by": "trenchpilgrim",
    "timeISO": "2025-08-13T11:53:14.000Z",
    "textPlain": "Whisper has quite bad issues with hallucination. It will inject sentences that were never said in the audio.It's decent for classification but poor at transcription.",
    "parent": 44887159,
    "depth": 2
  },
  {
    "id": 44887270,
    "by": "_def",
    "timeISO": "2025-08-13T11:43:36.000Z",
    "textPlain": "May I ask which movies? I'm just curious",
    "parent": 44887159,
    "depth": 2
  },
  {
    "id": 44887063,
    "by": "majewsky",
    "timeISO": "2025-08-13T11:17:35.000Z",
    "textPlain": "It looks like the model file needs to be supplied at invocation time, so the binary blob would not be required for packaging.",
    "parent": 44887044,
    "depth": 2
  },
  {
    "id": 44887809,
    "by": "Xunjin",
    "timeISO": "2025-08-13T12:48:55.000Z",
    "textPlain": "Is this website open? Would love to see your work :P",
    "parent": 44887801,
    "depth": 2
  }
]