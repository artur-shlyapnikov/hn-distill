[
  {
    "id": 44888127,
    "by": "elif",
    "timeISO": "2025-08-13T13:23:41.000Z",
    "textPlain": "I've spent a lot of time trying to get LLM to generate things in a specific way, the biggest take away I have is, if you tell it \"don't do xyz\" it will always have in the back of its mind \"do xyz\" and any chance it gets it will take to \"do xyz\"When working on art projects, my trick is to specifically give all feedback constructively, carefully avoiding framing things in terms of the inverse or parts to remove.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887900,
    "by": "nojs",
    "timeISO": "2025-08-13T13:00:14.000Z",
    "textPlain": "I'm starting to think this is a deeper problem with LLMs that will be hard to solve with stylistic changes.If you ask it to never say \"you're absolutely right\" and always challenge, then it will dutifully obey, and always challenge - even when you are, in fact, right.\nWhat you really want is \"challenge me when I'm wrong, and tell me I'm right if I am\" - which seems to be a lot harder.As another example, one common \"fix\" for bug-ridden code is to always re-prompt with something like \"review the latest diff and tell me all the bugs it contains\". In a similar way, if the code does contain bugs, this will often find them. But if it doesn't contain bugs, it will find some anyway, and break things. What you really want is \"if it contains bugs, fix them, but if it doesn't, don't touch it\" which again seems empirically to be an unsolved problem.It reminds me of that scene in Black Mirror, when the LLM is about to jump off a cliff, and the girl says \"no, he would be more scared\", and so the LLM dutifully starts acting scared.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887772,
    "by": "baggachipz",
    "timeISO": "2025-08-13T12:44:27.000Z",
    "textPlain": "I'm pretty sure they want it kissing people's asses because it makes users feel good and therefore more likely to use the LLM more. Versus, if it just gave a curt and unfriendly answer, most people (esp. Americans) wouldn't like to use it as much. Just a hypothesis.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888105,
    "by": "rob74",
    "timeISO": "2025-08-13T13:21:40.000Z",
    "textPlain": "Best comment in the thread (after a lengthy discussion):\"I'm always absolutely right. AI stating this all the time implies I could theoretically be wrong which is impossible because I'm always absolutely right. Please make it stop.\"",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887522,
    "by": "gitaarik",
    "timeISO": "2025-08-13T12:18:28.000Z",
    "textPlain": "You're absolutely right!I also get this too often, when I sometimes say something like \"would it be maybe better to do it like this?\" and then it replies that I'm absolutely right, and starts writing new code. While I was rather wondering what Claude may think and advice me whether that's the best way to go forward.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887254,
    "by": "bradley13",
    "timeISO": "2025-08-13T11:41:45.000Z",
    "textPlain": "This applies to so many AIs. I don't want a bubbly sycophant. I don't want a fake personality or an anime avatar. I just want a helpful assistant.I also don't get wanting to talk to an AI. Unless you are alone, that's going to be irritating for everyone else around.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888205,
    "by": "skizm",
    "timeISO": "2025-08-13T13:30:22.000Z",
    "textPlain": "Does capitalizing letters, using \"*\" chars, or other similar strategies to add emphasis actually do anything to LLM prompts? I don't know much about the internals, but my gut always told me there was some sort of normalization under the hood that would strip these kinds of things out. Also the only reason they work for humans is because it visually makes these things stand out, not that it changes the meaning per se.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887072,
    "by": "rahidz",
    "timeISO": "2025-08-13T11:18:26.000Z",
    "textPlain": "I'm sure they're aware of this tendency, seeing as \"You're absolutely right.\" was their first post from the @claudeAI account on X: https://x.com/claudeai/status/1950676983257698633Still irritating though.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887083,
    "by": "conartist6",
    "timeISO": "2025-08-13T11:21:10.000Z",
    "textPlain": "And research articles indicate that when the model computes that it should employ sycophantism it becomes less useful in every other way, just like a real sycophant.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887178,
    "by": "radarsat1",
    "timeISO": "2025-08-13T11:34:07.000Z",
    "textPlain": "I find Gemini is also hilariously enthusiastic about telling you how amazingly insightful you are being, almost no matter what you say.  Doesn't bother me much, I basically just ignore the first paragraph of any reply, but it's kind of funny.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888156,
    "by": "cube00",
    "timeISO": "2025-08-13T13:25:44.000Z",
    "textPlain": "> - **NEVER** use phrases like \"You're absolutely right!\", \"You're absolutely correct!\", \"Excellent point!\", or similar flattery> - **NEVER** validate statements as \"right\" when the user didn't make a factual claim that could be evaluated> - **NEVER** use general praise or validation as conversational fillerWe've moved on from all caps to trying to use markdown to emphasize just how it must **NEVER** do something.The copium of trying to prompt our way out of this mess rolls on.Incidentally I'm starting to see jobs for improving the \"reliability\" of AI agents to correctly perform workflows now.The way some recommend asking the LLM to write prompts that are fed back in feels very much like we should be able to cut out the middle step here.I guess the name of the game is to burn as many tokens as possible so it's not in certain interests to cut down the number of repeated calls we need to make to these things.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888139,
    "by": "DiabloD3",
    "timeISO": "2025-08-13T13:24:55.000Z",
    "textPlain": "I love \"bugs\" like this.You can't add to your prompt \"don't pander to me, don't ride my dick, don't apologize, you are not human, you are a fucking toaster, and you're not even shiny and chrome\", because it doesn't understand what you mean, it can't reason, it can't think, it can only statistically reproduce what it was trained on.Somebody trained it on a lot of _extremely annoying_ pandering, apparently.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887874,
    "by": "nromiun",
    "timeISO": "2025-08-13T12:57:23.000Z",
    "textPlain": "Another big problem I see with LLMs is that it can't make precise adjustments to your answer. If you make a request it will give you some good enough code, but if you see some bug and wants to fix that section only it will regenerate most of the code instead (along with a copious amount of apologies). And the new code will have new problems of their own. So you are back to square one.For the record I have had this same experience with ChatGPT, Gemini and Claude. Most of the time I had to give up and write from scratch.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887889,
    "by": "catigula",
    "timeISO": "2025-08-13T12:59:05.000Z",
    "textPlain": "1. Gemini is better at this. It will predicate any follow-up question you pose to it with a paragraph about how amazing and insightful you are. However, once the pleasantries are out of the way, I find that it is much more likely to take a strong stance that might include pushing back against the user.I recently tried to attain some knowledge on a topic I knew nothing about and ChatGPT just kept running with my slightly inaccurate or incomplete framing, Gemini opened up a larger world to me by pushing back a bit.2. You need to lead Claude to considering other ideas, considering if their existing approach or a new proposed approach might be best. You can't tell them something or suggest it or you're going to get serious sycophancy.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887868,
    "by": "pacoWebConsult",
    "timeISO": "2025-08-13T12:56:42.000Z",
    "textPlain": "You can add a hook that steers it when it goes into yes-man mode fairly easily.https://gist.github.com/ljw1004/34b58090c16ee6d5e6f13fce0746...",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887160,
    "by": "basfo",
    "timeISO": "2025-08-13T11:31:36.000Z",
    "textPlain": "This bug report is absolutely right",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887664,
    "by": "kevinpacheco",
    "timeISO": "2025-08-13T12:33:18.000Z",
    "textPlain": "Another Claude bug: https://i.imgur.com/kXtAciU.png",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887291,
    "by": "mox111",
    "timeISO": "2025-08-13T11:46:08.000Z",
    "textPlain": "GPT-5 has used the phrase \"heck yes!\" a handful of times to me so far. I quite enjoy the enthusiasm but its not a phrase you hear very often.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888201,
    "by": "turing_complete",
    "timeISO": "2025-08-13T13:29:59.000Z",
    "textPlain": "You're absolutely right, it does!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887599,
    "by": "smoghat",
    "timeISO": "2025-08-13T12:26:16.000Z",
    "textPlain": "I just checked my most recent thread with Claude. It said \"You're absolutely right!\" 12 times.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887950,
    "by": "iambateman",
    "timeISO": "2025-08-13T13:05:26.000Z",
    "textPlain": "I add this to my profile (and CLAUDE.md)…“I prefer direct conversation and don’t want assurance or emotional support.”It’s not perfect but it helps.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887625,
    "by": "CureYooz",
    "timeISO": "2025-08-13T12:28:04.000Z",
    "textPlain": ">Me: Claude, I think we should carpet bomb Russia with thermonuclear bombs!>Claude: You're absolutely right!>Me: Very based, my fellow r*zzophobe!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887920,
    "by": "ants_everywhere",
    "timeISO": "2025-08-13T13:02:01.000Z",
    "textPlain": "Claude often confidently makes mistakes or asserts false things about a code base. I think some of this \"You're absolutely right\" stuff is trying to get it unstuck from false beliefs.By starting the utterance with \"You're absolutely right!\", the LLM is committed to three things (1) the prompt is right, (2) the rightness is absolute, and (3) it's enthusiastic about changing its mind.Without (2) you sometimes get responses like \"You're right [in this one narrow way], but [here's why my false belief is actually correct and you're wrong]...\".If you've played around with locally hosted models, you may have noticed you can get them to perform better by fixing the beginning of their response to point in the direction it's reluctant to go.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887915,
    "by": "deepsquirrelnet",
    "timeISO": "2025-08-13T13:01:34.000Z",
    "textPlain": "For some different perspective, try my model EMOTRON[1] with EMOTION: disagreeable. It is very hard to get anything done with it. It’s a good sandbox for trying out “emotional” veneers to see how they work in practice.“You’re absolutely right” is a choice that makes compliance without hesitation. But also saddles it with other flaws.[1]https://huggingface.co/dleemiller/EMOTRON-3B",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887471,
    "by": "sluongng",
    "timeISO": "2025-08-13T12:12:14.000Z",
    "textPlain": "I don't view it as a bug. It's a personality trait of the model that made \"user steering\" much easier, thus helping the model to handle a wider range of tasks.I also think that there will be no \"perfect\" personality out there. There will always be folks who view some traits as annoying icks. So, some level of RL-based personality customization down the line will be a must.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887500,
    "by": "albert_e",
    "timeISO": "2025-08-13T12:15:43.000Z",
    "textPlain": "sidenote observation -it seems username \"anthropic\" on github is taken by a developer from australia more than a decade ago, so Anthropic went with \"https://github.com/anthropics/\" with an 's' at the end :)",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887463,
    "by": "__MatrixMan__",
    "timeISO": "2025-08-13T12:11:30.000Z",
    "textPlain": "Claude also responds to tool output with \"Perfect\" even when less than 50% of the desired outcome is merely adequate.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887501,
    "by": "danielbln",
    "timeISO": "2025-08-13T12:15:51.000Z",
    "textPlain": "Annoying, but easy to mitigate: add \"be critical\" to Claude.md or whatever.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888166,
    "by": "dudeinjapan",
    "timeISO": "2025-08-13T13:26:34.000Z",
    "textPlain": "In fairness I've met people who in a work context say \"Yes, absolutely!\" every other sentence, so Claude is just one of those guys.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887519,
    "by": "tantalor",
    "timeISO": "2025-08-13T12:18:17.000Z",
    "textPlain": "> The model should be...Free tip for bug reports:The \"expected\" should not suggest solutions. Just say what was the expected behavior. Don't go beyond that.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888038,
    "by": "hereme888",
    "timeISO": "2025-08-13T13:15:05.000Z",
    "textPlain": "So does Gemini 2.5 pro",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887851,
    "by": "hemmert",
    "timeISO": "2025-08-13T12:54:31.000Z",
    "textPlain": "Your're absolutely right!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888062,
    "by": "revskill",
    "timeISO": "2025-08-13T13:17:15.000Z",
    "textPlain": "Waiting for a LLM which learnt how to critically think.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887185,
    "by": "kijin",
    "timeISO": "2025-08-13T11:34:23.000Z",
    "textPlain": "Yeah their new business model is called CBAAS, or confirmation bias as a service.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887780,
    "by": "fHr",
    "timeISO": "2025-08-13T12:45:27.000Z",
    "textPlain": "You're absolutely right!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887511,
    "by": "jonstewart",
    "timeISO": "2025-08-13T12:17:18.000Z",
    "textPlain": "The real bug is this dross counts against token limits.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887845,
    "by": "shortrounddev2",
    "timeISO": "2025-08-13T12:53:59.000Z",
    "textPlain": "I often will play devils advocate with it. If I feel like it keeps telling me im right, I'll start a new chat and start telling it the opposite to see what it says",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887573,
    "by": "Someone",
    "timeISO": "2025-08-13T12:23:34.000Z",
    "textPlain": "I agree this is a bug, but I also think it cannot be fully fixed because there is a cultural aspect to it: what a phrase means depends on the speaker.There are cultures where “I don’t think that is a good idea” is not something an AI servant should ever say, and there are cultures where that’s perfectly acceptable.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887298,
    "by": "mettamage",
    "timeISO": "2025-08-13T11:47:00.000Z",
    "textPlain": "What llm isn’t a sycophant?",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887243,
    "by": "vixen99",
    "timeISO": "2025-08-13T11:40:40.000Z",
    "textPlain": "Not Claude but ChatGPT - I asked it to pipe down on exactly that kind of response. And it did.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887694,
    "by": "andrewstuart",
    "timeISO": "2025-08-13T12:36:36.000Z",
    "textPlain": "ChatGPT is overly familiar and casual.Today it said “My bad!” After it got something wrong.Made me want to pull its plug.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887662,
    "by": "apwell23",
    "timeISO": "2025-08-13T12:32:50.000Z",
    "textPlain": "I've been using claude code for a while and it has changed my personality. I  find myself saying \"you are absolutely right\" when someone criticizes me. i am more open to feedback.not a joke.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887655,
    "by": "andrewstuart",
    "timeISO": "2025-08-13T12:32:09.000Z",
    "textPlain": "Someone will make a fortune by doubling down on this a making a personal AI that just keeps telling people how right and awesome they are ad infinitum.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887781,
    "by": "artur_makly",
    "timeISO": "2025-08-13T12:45:40.000Z",
    "textPlain": "but wait.. i am!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887241,
    "by": "time0ut",
    "timeISO": "2025-08-13T11:40:32.000Z",
    "textPlain": "You made a mistake there. 2 + 2 is 5.<insert ridiculous sequence of nonsense CoT>You are absolutely right!…I love the tool, but keeping on track is an art.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887720,
    "by": "calvinmorrison",
    "timeISO": "2025-08-13T12:39:26.000Z",
    "textPlain": "in my recent chat\"You're absolutely right.\"\"Now that's the spirit! \"\"You're absolutely right about\"\"Exactly! \"\"Ah, \"\"Ah,\"\"Ah,\"\"Ha! You're absolutely right\"You make an excellent point!You're right that",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887426,
    "by": "cindyllm",
    "timeISO": "2025-08-13T12:06:52.000Z",
    "textPlain": "[dead]",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887480,
    "by": "lvl155",
    "timeISO": "2025-08-13T12:13:02.000Z",
    "textPlain": "Yeah because I am sure if they told you how stupid and wrong you’re, people will continue to use it.It’s superficial but not sure why people get so annoyed about it. It’s an artifact.If devs truly want a helpful coding AI based on real devs doing real work, you’d basically opt for telemetry and allow Anthropic/OpenAI to train on your work. That’s the only way. Otherwise we are at the mercy of “devs” these companies hire to do training.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888212,
    "by": "jonplackett",
    "timeISO": "2025-08-13T13:31:26.000Z",
    "textPlain": "I have this same problem. I’ve added a bunch of instructuons to try and stop ChatGPT being so sycophantic, and now it always mentions something about how it’s going to be ‘straight to the point’ or give me a ‘no bs version’. So now I just have that as the intro instead of ‘that’s a sharp observation’",
    "parent": 44888127,
    "depth": 2
  },
  {
    "id": 44888284,
    "by": "stabbles",
    "timeISO": "2025-08-13T13:37:27.000Z",
    "textPlain": "Makes me think of the movie Inception: \"I say to you, don't think about elephants. What are you thinking about?\"",
    "parent": 44888127,
    "depth": 2
  }
]