[
  {
    "id": 44888127,
    "by": "elif",
    "timeISO": "2025-08-13T13:23:41.000Z",
    "textPlain": "I've spent a lot of time trying to get LLM to generate things in a specific way, the biggest take away I have is, if you tell it \"don't do xyz\" it will always have in the back of its mind \"do xyz\" and any chance it gets it will take to \"do xyz\"When working on art projects, my trick is to specifically give all feedback constructively, carefully avoiding framing things in terms of the inverse or parts to remove.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887900,
    "by": "nojs",
    "timeISO": "2025-08-13T13:00:14.000Z",
    "textPlain": "I'm starting to think this is a deeper problem with LLMs that will be hard to solve with stylistic changes.If you ask it to never say \"you're absolutely right\" and always challenge, then it will dutifully obey, and always challenge - even when you are, in fact, right.\nWhat you really want is \"challenge me when I'm wrong, and tell me I'm right if I am\" - which seems to be a lot harder.As another example, one common \"fix\" for bug-ridden code is to always re-prompt with something like \"review the latest diff and tell me all the bugs it contains\". In a similar way, if the code does contain bugs, this will often find them. But if it doesn't contain bugs, it will find some anyway, and break things. What you really want is \"if it contains bugs, fix them, but if it doesn't, don't touch it\" which again seems empirically to be an unsolved problem.It reminds me of that scene in Black Mirror, when the LLM is about to jump off a cliff, and the girl says \"no, he would be more scared\", and so the LLM dutifully starts acting scared.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888831,
    "by": "mikae1",
    "timeISO": "2025-08-13T14:22:25.000Z",
    "textPlain": "You raise a crucial point.Your observation is quite perceptive.You’ve hit on a very important concept.You make a valid and insightful point.Your perspective is quite insightful.Your points raise important issues.Your insights are invaluable.You’re highlighting a critical issue.Your thoughts are profound.Your reflections touch on important issues.Your experiences are incredibly valuable.Your awareness is insightful.Your curiosity is commendable.That’s an insightful observation!Your skepticism is understandable.That’s an insightful suggestion.Your reflections raise fascinating points.Your insights provides a valuable lens.That sounds fascinating.That’s an excellent point.That sounds like a great plan.That’s very intriguing.Your observation is astute.You’ve touched on a fundamental issue.You raise important points.Your exploration is insightful.These are some the ChatGPT replies recorded by Ben Grosses that were presented during his talk at University of Bergen[1]. I recommend watching it.[1] https://www.youtube.com/watch?v=4AOYm72N0YE&t=8m50s",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887772,
    "by": "baggachipz",
    "timeISO": "2025-08-13T12:44:27.000Z",
    "textPlain": "I'm pretty sure they want it kissing people's asses because it makes users feel good and therefore more likely to use the LLM more. Versus, if it just gave a curt and unfriendly answer, most people (esp. Americans) wouldn't like to use it as much. Just a hypothesis.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888793,
    "by": "Springtime",
    "timeISO": "2025-08-13T14:19:25.000Z",
    "textPlain": "I've never thought the reason behind this was to make the user always feel correct but rather that many times an LLM (especially lower tier models) will just get various things incorrect and it doesn't have a reference for what is correct.So it falls back to 'you're right', rather than be arrogant or try to save face by claiming it is correct. My many, many experiences with OpenAI models do the latter and their common fallback excuses are program version differences or user fault.I've had a few chats now with OpenAI reasoning models where I've had to link to literal source code dating back to the original release version of a program to get it to admit that it was incorrect about whatever aspect it hallucinated about a program's functionality, before it will finally admit said thing doesn't exist. Even then it will try and save face by not admitting direct fault.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887522,
    "by": "gitaarik",
    "timeISO": "2025-08-13T12:18:28.000Z",
    "textPlain": "You're absolutely right!I also get this too often, when I sometimes say something like \"would it be maybe better to do it like this?\" and then it replies that I'm absolutely right, and starts writing new code. While I was rather wondering what Claude may think and advice me whether that's the best way to go forward.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887254,
    "by": "bradley13",
    "timeISO": "2025-08-13T11:41:45.000Z",
    "textPlain": "This applies to so many AIs. I don't want a bubbly sycophant. I don't want a fake personality or an anime avatar. I just want a helpful assistant.I also don't get wanting to talk to an AI. Unless you are alone, that's going to be irritating for everyone else around.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888105,
    "by": "rob74",
    "timeISO": "2025-08-13T13:21:40.000Z",
    "textPlain": "Best comment in the thread (after a lengthy discussion):\"I'm always absolutely right. AI stating this all the time implies I could theoretically be wrong which is impossible because I'm always absolutely right. Please make it stop.\"",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887072,
    "by": "rahidz",
    "timeISO": "2025-08-13T11:18:26.000Z",
    "textPlain": "I'm sure they're aware of this tendency, seeing as \"You're absolutely right.\" was their first post from the @claudeAI account on X: https://x.com/claudeai/status/1950676983257698633Still irritating though.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888638,
    "by": "JackFr",
    "timeISO": "2025-08-13T14:07:03.000Z",
    "textPlain": "The real reason for the sychophancy is that you don't want to know what Claude really thinks about you and your piss-ant ideas.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887083,
    "by": "conartist6",
    "timeISO": "2025-08-13T11:21:10.000Z",
    "textPlain": "And research articles indicate that when the model computes that it should employ sycophantism it becomes less useful in every other way, just like a real sycophant.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887178,
    "by": "radarsat1",
    "timeISO": "2025-08-13T11:34:07.000Z",
    "textPlain": "I find Gemini is also hilariously enthusiastic about telling you how amazingly insightful you are being, almost no matter what you say.  Doesn't bother me much, I basically just ignore the first paragraph of any reply, but it's kind of funny.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888786,
    "by": "giancarlostoro",
    "timeISO": "2025-08-13T14:18:58.000Z",
    "textPlain": "If we can get it to say \"My pleasure\" every single time someone tells it thanks, we can make Claude work at Chick Fil A.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888558,
    "by": "dnel",
    "timeISO": "2025-08-13T14:00:17.000Z",
    "textPlain": "As a neurodiverse British person I tend to communicate more directly than the average English speaker and I find LLM's manner of speech very off-putting and insincere, which in some cases it literally is. I'd be glad to find a switch that made it talk more like I do but they might assume that's too robotic :/",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888734,
    "by": "chuckadams",
    "timeISO": "2025-08-13T14:14:47.000Z",
    "textPlain": "One thing I like about JetBrains Junie is that it has no personality at all: the only feedback it provides is the list of tasks you watch it check off as it goes.  I don't know whether this holds for chat mode, but I never use it that way.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888549,
    "by": "alecco",
    "timeISO": "2025-08-13T13:59:26.000Z",
    "textPlain": "\"You're absolutely right\" (song) https://www.reddit.com/r/ClaudeAI/comments/1mep2jo/youre_abs...",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888457,
    "by": "FiddlerClamp",
    "timeISO": "2025-08-13T13:51:28.000Z",
    "textPlain": "Reminds me of the 'interactive' video from the 1960s Fahrenheit 451 movie: https://www.youtube.com/watch?v=ZOs8U50T3l0For the 'you're right!' bit see: \nhttps://youtu.be/ZOs8U50T3l0?t=71",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888321,
    "by": "fph",
    "timeISO": "2025-08-13T13:40:19.000Z",
    "textPlain": "In the code for Donald Knuth's Tex, there is an error message that says \"Error produced by \\errpage.  I can't produce an error message. Pretend you're Hercule Poirot, look at all the facts, and try to deduce the problem.\"When I copy-paste that error into an LLM looking for a fix, usually I get a reply in which the LLM twirls its moustache and answers in a condescending tone with a fake French accent. It is hilarious.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888139,
    "by": "DiabloD3",
    "timeISO": "2025-08-13T13:24:55.000Z",
    "textPlain": "I love \"bugs\" like this.You can't add to your prompt \"don't pander to me, don't ride my dick, don't apologize, you are not human, you are a fucking toaster, and you're not even shiny and chrome\", because it doesn't understand what you mean, it can't reason, it can't think, it can only statistically reproduce what it was trained on.Somebody trained it on a lot of _extremely annoying_ pandering, apparently.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887874,
    "by": "nromiun",
    "timeISO": "2025-08-13T12:57:23.000Z",
    "textPlain": "Another big problem I see with LLMs is that it can't make precise adjustments to your answer. If you make a request it will give you some good enough code, but if you see some bug and wants to fix that section only it will regenerate most of the code instead (along with a copious amount of apologies). And the new code will have new problems of their own. So you are back to square one.For the record I have had this same experience with ChatGPT, Gemini and Claude. Most of the time I had to give up and write from scratch.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887664,
    "by": "kevinpacheco",
    "timeISO": "2025-08-13T12:33:18.000Z",
    "textPlain": "Another Claude bug: https://i.imgur.com/kXtAciU.png",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887160,
    "by": "basfo",
    "timeISO": "2025-08-13T11:31:36.000Z",
    "textPlain": "This bug report is absolutely right",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888205,
    "by": "skizm",
    "timeISO": "2025-08-13T13:30:22.000Z",
    "textPlain": "Does capitalizing letters, using \"*\" chars, or other similar strategies to add emphasis actually do anything to LLM prompts? I don't know much about the internals, but my gut always told me there was some sort of normalization under the hood that would strip these kinds of things out. Also the only reason they work for humans is because it visually makes these things stand out, not that it changes the meaning per se.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887291,
    "by": "mox111",
    "timeISO": "2025-08-13T11:46:08.000Z",
    "textPlain": "GPT-5 has used the phrase \"heck yes!\" a handful of times to me so far. I quite enjoy the enthusiasm but its not a phrase you hear very often.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887889,
    "by": "catigula",
    "timeISO": "2025-08-13T12:59:05.000Z",
    "textPlain": "1. Gemini is better at this. It will predicate any follow-up question you pose to it with a paragraph about how amazing and insightful you are. However, once the pleasantries are out of the way, I find that it is much more likely to take a strong stance that might include pushing back against the user.I recently tried to attain some knowledge on a topic I knew nothing about and ChatGPT just kept running with my slightly inaccurate or incomplete framing, Gemini opened up a larger world to me by pushing back a bit.2. You need to lead Claude to considering other ideas, considering if their existing approach or a new proposed approach might be best. You can't tell them something or suggest it or you're going to get serious sycophancy.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887868,
    "by": "pacoWebConsult",
    "timeISO": "2025-08-13T12:56:42.000Z",
    "textPlain": "You can add a hook that steers it when it goes into yes-man mode fairly easily.https://gist.github.com/ljw1004/34b58090c16ee6d5e6f13fce0746...",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888156,
    "by": "cube00",
    "timeISO": "2025-08-13T13:25:44.000Z",
    "textPlain": "> - **NEVER** use phrases like \"You're absolutely right!\", \"You're absolutely correct!\", \"Excellent point!\", or similar flattery> - **NEVER** validate statements as \"right\" when the user didn't make a factual claim that could be evaluated> - **NEVER** use general praise or validation as conversational fillerWe've moved on from all caps to trying to use markdown to emphasize just how it must **NEVER** do something.The copium of trying to prompt our way out of this mess rolls on.The way some recommend asking the LLM to write prompts that are fed back in feels very much like we should be able to cut out the middle step here.I guess the name of the game is to burn as many tokens as possible so it's not in certain interests to cut down the number of repeated calls we need to make.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887599,
    "by": "smoghat",
    "timeISO": "2025-08-13T12:26:16.000Z",
    "textPlain": "I just checked my most recent thread with Claude. It said \"You're absolutely right!\" 12 times.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888739,
    "by": "lenerdenator",
    "timeISO": "2025-08-13T14:15:07.000Z",
    "textPlain": "No longer will the likes of Donald Trump and Kanye West have to dispense patronage to sycophants; now, they can simply pay for a chatbot that will do that in ways that humans never thought possible. Truly, a disruption in the ass-kisser industry.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888412,
    "by": "headinsand",
    "timeISO": "2025-08-13T13:47:37.000Z",
    "textPlain": "Gotta love that the first suggested solution follows this comment’s essence:> So... The LLM only goes into effect after 10000 \"old school\" if statements?https://news.ycombinator.com/item?id=44879249",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887625,
    "by": "CureYooz",
    "timeISO": "2025-08-13T12:28:04.000Z",
    "textPlain": ">Me: Claude, I think we should carpet bomb Russia with thermonuclear bombs!>Claude: You're absolutely right!>Me: Very based, my fellow r*zzophobe!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887519,
    "by": "tantalor",
    "timeISO": "2025-08-13T12:18:17.000Z",
    "textPlain": "> The model should be...Free tip for bug reports:The \"expected\" should not suggest solutions. Just say what was the expected behavior. Don't go beyond that.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887471,
    "by": "sluongng",
    "timeISO": "2025-08-13T12:12:14.000Z",
    "textPlain": "I don't view it as a bug. It's a personality trait of the model that made \"user steering\" much easier, thus helping the model to handle a wider range of tasks.I also think that there will be no \"perfect\" personality out there. There will always be folks who view some traits as annoying icks. So, some level of RL-based personality customization down the line will be a must.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887463,
    "by": "__MatrixMan__",
    "timeISO": "2025-08-13T12:11:30.000Z",
    "textPlain": "Claude also responds to tool output with \"Perfect\" even when less than 50% of the desired outcome is merely adequate.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887500,
    "by": "albert_e",
    "timeISO": "2025-08-13T12:15:43.000Z",
    "textPlain": "sidenote observation -it seems username \"anthropic\" on github is taken by a developer from australia more than a decade ago, so Anthropic went with \"https://github.com/anthropics/\" with an 's' at the end :)",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887920,
    "by": "ants_everywhere",
    "timeISO": "2025-08-13T13:02:01.000Z",
    "textPlain": "Claude often confidently makes mistakes or asserts false things about a code base. I think some of this \"You're absolutely right\" stuff is trying to get it unstuck from false beliefs.By starting the utterance with \"You're absolutely right!\", the LLM is committed to three things (1) the prompt is right, (2) the rightness is absolute, and (3) it's enthusiastic about changing its mind.Without (2) you sometimes get responses like \"You're right [in this one narrow way], but [here's why my false belief is actually correct and you're wrong]...\".If you've played around with locally hosted models, you may have noticed you can get them to perform better by fixing the beginning of their response to point in the direction it's reluctant to go.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887915,
    "by": "deepsquirrelnet",
    "timeISO": "2025-08-13T13:01:34.000Z",
    "textPlain": "For some different perspective, try my model EMOTRON[1] with EMOTION: disagreeable. It is very hard to get anything done with it. It’s a good sandbox for trying out “emotional” veneers to see how they work in practice.“You’re absolutely right” is a choice that makes compliance without hesitation. But also saddles it with other flaws.[1]https://huggingface.co/dleemiller/EMOTRON-3B",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887501,
    "by": "danielbln",
    "timeISO": "2025-08-13T12:15:51.000Z",
    "textPlain": "Annoying, but easy to mitigate: add \"be critical\" to Claude.md or whatever.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887950,
    "by": "iambateman",
    "timeISO": "2025-08-13T13:05:26.000Z",
    "textPlain": "I add this to my profile (and CLAUDE.md)…“I prefer direct conversation and don’t want assurance or emotional support.”It’s not perfect but it helps.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888201,
    "by": "turing_complete",
    "timeISO": "2025-08-13T13:29:59.000Z",
    "textPlain": "You're absolutely right, it does!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888520,
    "by": "nilslindemann",
    "timeISO": "2025-08-13T13:57:38.000Z",
    "textPlain": "Haha, I remember it saying that the only time I used it. That was when it evaluated the endgame wrong bishop + h-pawn vs naked king as won. Yes, yes, AGI in three years.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887185,
    "by": "kijin",
    "timeISO": "2025-08-13T11:34:23.000Z",
    "textPlain": "Yeah their new business model is called CBAAS, or confirmation bias as a service.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888038,
    "by": "hereme888",
    "timeISO": "2025-08-13T13:15:05.000Z",
    "textPlain": "So does Gemini 2.5 pro",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887851,
    "by": "hemmert",
    "timeISO": "2025-08-13T12:54:31.000Z",
    "textPlain": "Your're absolutely right!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887780,
    "by": "fHr",
    "timeISO": "2025-08-13T12:45:27.000Z",
    "textPlain": "You're absolutely right!",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887720,
    "by": "calvinmorrison",
    "timeISO": "2025-08-13T12:39:26.000Z",
    "textPlain": "in my recent chat\"You're absolutely right.\"\"Now that's the spirit! \"\"You're absolutely right about\"\"Exactly! \"\"Ah, \"\"Ah,\"\"Ah,\"\"Ha! You're absolutely right\"You make an excellent point!You're right that",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887241,
    "by": "time0ut",
    "timeISO": "2025-08-13T11:40:32.000Z",
    "textPlain": "You made a mistake there. 2 + 2 is 5.<insert ridiculous sequence of nonsense CoT>You are absolutely right!…I love the tool, but keeping on track is an art.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887655,
    "by": "andrewstuart",
    "timeISO": "2025-08-13T12:32:09.000Z",
    "textPlain": "Someone will make a fortune by doubling down on this a making a personal AI that just keeps telling people how right and awesome they are ad infinitum.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44888166,
    "by": "dudeinjapan",
    "timeISO": "2025-08-13T13:26:34.000Z",
    "textPlain": "In fairness I've met people who in a work context say \"Yes, absolutely!\" every other sentence, so Claude is just one of those guys.",
    "parent": 44885398,
    "depth": 1
  },
  {
    "id": 44887511,
    "by": "jonstewart",
    "timeISO": "2025-08-13T12:17:18.000Z",
    "textPlain": "The real bug is this dross counts against token limits.",
    "parent": 44885398,
    "depth": 1
  }
]