[
  {
    "id": 44905187,
    "by": "mijoharas",
    "timeISO": "2025-08-14T20:20:00.000Z",
    "textPlain": "Ok, cool! I was actually one of the people on the hyprnote HN thread asking for a headless mode!I was actually integrating some whisper tools yesterday. I was wondering if there was a way to get a streaming response, and was thinking it'd be nice if you can.I'm on linux, so don't think I can test out owhisper right now, but is that a thing that's possible?Also, it looks like the `owhisper run` command gives it's output as a tui. Is there an option for a plain text response so that we can just pipe it to other programs? (maybe just `kill`/`CTRL+C` to stop the recording and finalize the words).Same question for streaming, is there a way to get a streaming text output from owhisper? (it looks like you said you create a deepgram compatible api, I had a quick look at the api docs, but I don't know how easy it is to hook into it and get some nice streaming text while speaking).Oh yeah, and diarisation (available with a flag?) would be awesome, one of the things that's missing from most of the easiest to run things I can find.",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44905003,
    "by": "clickety_clack",
    "timeISO": "2025-08-14T20:03:22.000Z",
    "textPlain": "Please find a way to add speaker diarization, with a way to remember the speakers. You can do it with pyannote, and get a vector embedding of each speaker that can be compared between audio samples, but that’s a year old now so I’m sure there’s better options now!",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44908231,
    "by": "replwoacause",
    "timeISO": "2025-08-15T03:12:44.000Z",
    "textPlain": "I’m looking for something that is aware of what is being discussed realtime, so if I zone out for a few minutes, I can ask it what I missed or to clarify something. Can this do that? If not, anybody know of something that can?",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44906643,
    "by": "wanderingmind",
    "timeISO": "2025-08-14T22:49:21.000Z",
    "textPlain": "Thank you for taking the time to build something and share it. However what is the advantage of using this over whisper.cpp stream that can also do real time conversion?https://github.com/ggml-org/whisper.cpp/tree/master/examples...",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44907040,
    "by": "bartleeanderson",
    "timeISO": "2025-08-14T23:43:40.000Z",
    "textPlain": "Very cool. I was reading through the various threads here. I am working on adding stt and tts to an AI DungeonMaster. Just a personal fun project, am working on the adventure part of it now. This will come in handy. I had dungeon navigation via commands working but started over and left it at the point where I am ready to merge the navigation back in again once I was happy with a slimmer version with one file. It will be fun to be able to talk to the DM and have it respond with voice and actions. The diarization will be very helpful if I can create a stream where it can hear all of us conversing at once. But baby steps. Still working on getting the whole campaign working after I get characters created and put in a party :)",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44904907,
    "by": "solarkraft",
    "timeISO": "2025-08-14T19:56:19.000Z",
    "textPlain": "Wait, this is cool.I just spent last week researching the options (especially for my M1!) and was left wishing for a standard, full-service (live) transcription server for Whisper like OLlama has been for LLMs.I’m excited to try this out and see your API (there seems to be a standard vaccuum here due to openai not having a real time transcription service, which I find to be a bummer)!Edit: They seem to emulate the Deepgram API (https://developers.deepgram.com/reference/speech-to-text-api...), which seems like a solid choice. I’d definitely like to see a standard emerging here.",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44908078,
    "by": "neom",
    "timeISO": "2025-08-15T02:44:20.000Z",
    "textPlain": "Just wanna give a shout out to the hyprnote team - I've been running it for about a month now and I love how simple and no gimmicks it is. It's a good app, def recommend! (Team seem like a lovely group of youngins' also) :)",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44904267,
    "by": "JP_Watts",
    "timeISO": "2025-08-14T19:01:50.000Z",
    "textPlain": "I’d like to use this to transcribe meeting minutes with multiple people. How could this program work for that use case?",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44907758,
    "by": "notthetup",
    "timeISO": "2025-08-15T01:46:34.000Z",
    "textPlain": "Is there a way to list all the models that are available to be pulled?",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44907329,
    "by": "rshemet",
    "timeISO": "2025-08-15T00:26:21.000Z",
    "textPlain": "THIS IS THE BOMB!!! So excited for this one. Thanks for putting cool tech out there.",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44904204,
    "by": "yujonglee",
    "timeISO": "2025-08-14T18:56:00.000Z",
    "textPlain": "Happy to answer any questions!These are list of local models it supports:- whisper-cpp-base-q8- whisper-cpp-base-q8-en- whisper-cpp-tiny-q8- whisper-cpp-tiny-q8-en- whisper-cpp-small-q8- whisper-cpp-small-q8-en- whisper-cpp-large-turbo-q8- moonshine-onnx-tiny- moonshine-onnx-tiny-q4- moonshine-onnx-tiny-q8- moonshine-onnx-base- moonshine-onnx-base-q4- moonshine-onnx-base-q8",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44906779,
    "by": "elektor",
    "timeISO": "2025-08-14T23:06:34.000Z",
    "textPlain": "Cool tool! Are you guys releasing Hyprnote for Windows this month?",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44907533,
    "by": "pylotlight",
    "timeISO": "2025-08-15T01:01:36.000Z",
    "textPlain": "This has MPS support for hwa?",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44905812,
    "by": "DiabloD3",
    "timeISO": "2025-08-14T21:19:25.000Z",
    "textPlain": "I suggest you don't brand this \"Ollama for X\". They've become a commercial operation that is trying to FOSS-wash their actions through using llama.cpp's code and then throwing their users under the bus when they can't support them.I see that you are also using llama.cpp's code? That's cool, but make sure you become a member of that community, not an abuser.",
    "parent": 44901853,
    "depth": 1
  },
  {
    "id": 44905301,
    "by": "yujonglee",
    "timeISO": "2025-08-14T20:29:15.000Z",
    "textPlain": "> I'm on linuxI didn't tested on Linux yet, but we have linux build:\nhttp://owhisper.hyprnote.com/download/latest/linux-x86_64> also, it looks like the `owhisper run` command gives it's output as a tui. Is there an option for a plain tex`owhisper run` is more like way to quickly trying it out. But I think piping is definitely something that should work.> Same question for streaming, is there a way to get a streaming text output from owhisper?You can use Deepgram client to talk to `owhisper serve`.\n(https://docs.hyprnote.com/owhisper/deepgram-compatibility)\nSo best resource might be Deepgram client SDK docs.> diarisationyeah on the roadmap",
    "parent": 44905187,
    "depth": 2
  },
  {
    "id": 44905289,
    "by": "mijoharas",
    "timeISO": "2025-08-14T20:28:40.000Z",
    "textPlain": "Oh wait, maybe you do support linux for owhisper:\nhttps://github.com/fastrepl/homebrew-hyprnote/blob/main/Form...Can you help me out to find where the code you've built is? I can see the folder in github[0], but I can't see the code for the cli for instance? unless I'm blind.[0] https://github.com/fastrepl/hyprnote/tree/main/owhisper",
    "parent": 44905187,
    "depth": 2
  },
  {
    "id": 44905051,
    "by": "yujonglee",
    "timeISO": "2025-08-14T20:07:49.000Z",
    "textPlain": "yeah that is on the roadmap!",
    "parent": 44905003,
    "depth": 2
  },
  {
    "id": 44908363,
    "by": "koolala",
    "timeISO": "2025-08-15T03:35:40.000Z",
    "textPlain": "Why not use a LLM with the speech to text output?",
    "parent": 44908231,
    "depth": 2
  },
  {
    "id": 44907103,
    "by": "yujonglee",
    "timeISO": "2025-08-14T23:53:48.000Z",
    "textPlain": "Its lot more than that.- It supports other models like moonshine.- It also works as proxy for cloud model providers.- It can expose local models as Deepgram compatible api server",
    "parent": 44906643,
    "depth": 2
  },
  {
    "id": 44908146,
    "by": "fancy_pantser",
    "timeISO": "2025-08-15T02:56:22.000Z",
    "textPlain": "I scratched a similar itch and found local LLMs plus Whisper worked really well to listen in and \"DJ\" a soundtrack while playing tabletop RPGs with a group. If you want to check it out: https://github.com/sean-public/conductor",
    "parent": 44907040,
    "depth": 2
  },
  {
    "id": 44905067,
    "by": "yujonglee",
    "timeISO": "2025-08-14T20:09:06.000Z",
    "textPlain": "Correct. About the deepgram-compatibility:\nhttps://docs.hyprnote.com/owhisper/deepgram-compatibilityLet me know how it goes!",
    "parent": 44904907,
    "depth": 2
  },
  {
    "id": 44904318,
    "by": "yujonglee",
    "timeISO": "2025-08-14T19:05:15.000Z",
    "textPlain": "If your use-case is meeting, https://github.com/fastrepl/hyprnote is for you.\nOWhisper is more like a headless version of it.",
    "parent": 44904267,
    "depth": 2
  },
  {
    "id": 44904797,
    "by": "sxp",
    "timeISO": "2025-08-14T19:47:28.000Z",
    "textPlain": "If you want to transcribe meeting notes, whisper isn't the best tool because it doesn't separate the transcribe by speakers. There are some other tools that do that, but I'm not sure what the best local option is. I've used Google's cloud STT with the diarization option and manually renamed \"Speaker N\" after the fact.",
    "parent": 44904267,
    "depth": 2
  },
  {
    "id": 44907931,
    "by": "yujonglee",
    "timeISO": "2025-08-15T02:20:12.000Z",
    "textPlain": "sure. `owhisper pull --help`",
    "parent": 44907758,
    "depth": 2
  },
  {
    "id": 44907368,
    "by": "yujonglee",
    "timeISO": "2025-08-15T00:34:06.000Z",
    "textPlain": "Thank you!",
    "parent": 44907329,
    "depth": 2
  },
  {
    "id": 44905054,
    "by": "phkahler",
    "timeISO": "2025-08-14T20:08:06.000Z",
    "textPlain": "I thought whisper and others took large chunks (20-30 seconds) of speech, or a complete wave file as input. How do you get real-time transcription? What size chunks do you feed it?To me, STT should take a continuous audio stream and output a continuous text stream.",
    "parent": 44904204,
    "depth": 2
  },
  {
    "id": 44906675,
    "by": "shekhar101",
    "timeISO": "2025-08-14T22:53:40.000Z",
    "textPlain": "FYI:\nowhisper pull whisper-cpp-large-turbo-q8                                                                                \nFailed to download model.ggml: Other error: Server does not support range requests. Got status: 200 OKBut the base-q8 works (and works quite well!). The TUI is really nice. Speaker diarization would make it almost perfect for me. Thanks for building this.",
    "parent": 44904204,
    "depth": 2
  },
  {
    "id": 44905795,
    "by": "alkh",
    "timeISO": "2025-08-14T21:17:35.000Z",
    "textPlain": "Sorry, maybe I missed it but I didn't see this list on your website. I think it is a good idea to add this info there. Besides that, thank you for the effort and your work! I will definetely give it a try",
    "parent": 44904204,
    "depth": 2
  },
  {
    "id": 44907089,
    "by": "yujonglee",
    "timeISO": "2025-08-14T23:51:39.000Z",
    "textPlain": "probably end of this month or early next month. not 100% sure.",
    "parent": 44906779,
    "depth": 2
  },
  {
    "id": 44907568,
    "by": "yujonglee",
    "timeISO": "2025-08-15T01:08:34.000Z",
    "textPlain": "yes. metal is on",
    "parent": 44907533,
    "depth": 2
  },
  {
    "id": 44905874,
    "by": "yujonglee",
    "timeISO": "2025-08-14T21:24:54.000Z",
    "textPlain": "yeah we use whisper.cpp for whisper inference. this is more like a community-focused project, not a commercial product!",
    "parent": 44905812,
    "depth": 2
  }
]