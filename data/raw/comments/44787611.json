[
  {
    "id": 44790411,
    "by": "k8si",
    "timeISO": "2025-08-04T19:31:43.000Z",
    "textPlain": "Maybe this is a nitpick but CoNLL NER is not a \"challenging task\". Even pre-LLM systems were getting >90 F1 on that as far back as 2016.Also, just in case people want to lit review further on this topic: they call their method \"programmatic data curation\" but I believe this approach is also called model distillation and/or student-teacher training.",
    "parent": 44787611,
    "depth": 1
  },
  {
    "id": 44790162,
    "by": "alchemist1e9",
    "timeISO": "2025-08-04T19:10:54.000Z",
    "textPlain": "I’ve been thinking about curating primary sources themselves and then using those for fine-tuning.Anyone gone that route and know of projects with very high quality curated source materials? ideally categorized and labeled.",
    "parent": 44787611,
    "depth": 1
  },
  {
    "id": 44790672,
    "by": "6510",
    "timeISO": "2025-08-04T19:55:35.000Z",
    "textPlain": "Noob question: Would it be possible to train a small model for a single prompt?",
    "parent": 44787611,
    "depth": 1
  },
  {
    "id": 44794393,
    "by": "simianwords",
    "timeISO": "2025-08-05T04:37:32.000Z",
    "textPlain": "I think its a good idea but how do you not accidentally benchmark hack here?",
    "parent": 44787611,
    "depth": 1
  },
  {
    "id": 44790456,
    "by": "mwigdahl",
    "timeISO": "2025-08-04T19:34:10.000Z",
    "textPlain": "Is this just distillation but with a step to filter out low-quality responses first?",
    "parent": 44787611,
    "depth": 1
  }
]