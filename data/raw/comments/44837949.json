[
  {
    "id": 44869452,
    "by": "hinkley",
    "timeISO": "2025-08-11T21:03:55.000Z",
    "textPlain": "Practically the day after I learned about tail recursion in CS class, I learned that almost all recursive calls can be translated to iteration, that in many cases the iterative version is easier to scan, is as fast if not faster, and that they can usually handle much much larger inputs than recursion due to avoiding stack overflow.Tail recursion is meant to fix the latter. But what we mean to happen and what actually happens ain't ever exactly similar.Tail recursion IME is a bigger foot gun than relying on someone to add a new conditional branch at the end of a block in an iterative algorithm without fucking it up in the process. And iteration responds generally better to Extract Function. And while I can think of counter cases easily enough, in the large iteration is less work and less vigilance. And you cannot scale a project up without the vigilance requirement amortizing basically to 0 per line of code.",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44870562,
    "by": "LegionMammal978",
    "timeISO": "2025-08-11T23:20:02.000Z",
    "textPlain": "Several people in this thread are saying that tail recursion is superior to imperative iteration in that it explicitly specifies which variables may change in each iteration (assuming a broadly immutable language).To the contrary, I'd argue that immutability isn't the only alternative to universal mutability: many newer imperative languages (such as Rust) have various forms of controlled mutability, where one must explicitly declare which variables may be modified by imperative assignments.IME, controlled mutability captures just about all the benefit of immutable languages, without requiring any special data structures or sufficiently-smart compiler analyses to ensure good performance. I've never really understood the desire for tail-recursive versions of iterative algorithms, except for a prior commitment to functional programming.",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44869480,
    "by": "tombert",
    "timeISO": "2025-08-11T21:06:54.000Z",
    "textPlain": "I'm a pretty big functional programming nerd and I want to like tail recursion, but I honestly kind of feel like I agree with Guido on it, which is that it kind of breaks the typical stack-trace patterns.I have kind of grown to prefer Clojure's loop/recur construct, since it gives you something more or less akin to tail recursion but it doesn't pretend to be actually recursive.",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44871352,
    "by": "kazinator",
    "timeISO": "2025-08-12T01:29:38.000Z",
    "textPlain": "Tail recursive functions are loops when tail calls are jumps.Tail calls being jumps is the key insight.Not all tail calls are recursion!Students are confused by recursion. Some may be confused by tail calls.Don't mix two confusing things together when teaching.(Tail calls get mixed up with recursion because recognizing and treating/optimizing recursive tail calls to create loops an important highlighted category. In a compiler that doesn't optimize tail calls, optimizing self tail calls is an important priority (if that is easier to do than a general treatment). Many common algorithms are expressible in just one function that calls itself, and there are cases in which some or all of those calls can be tail calls; e.g. binary tree traversal.)The order should probably be: teach recursion first. Then when students have firmly wrapped their heads around it, introduce tail calls. Students will gain the skill of knowing what is a tail call and why it is important, and recognize which calls tail calls.  Secondly, the harder skill of taking recursion that uses non-tail calls and restructuring it to make tail calls instead.",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44871628,
    "by": "eru",
    "timeISO": "2025-08-12T02:21:25.000Z",
    "textPlain": "Loops are a special case of tail recursion which is a special case of recursion [0] which is a special case of calling functions.However, loops aren't the only use for tail recursion.  Another classic example are state machines as described in the 'Lambda: the ultimate goto' paper.  See eg https://en.wikisource.org/wiki/Lambda:_The_Ultimate_GOTO[0] Well, recursion on functions.  You can also have eg recursive data types or recursion in mathematics in general.  But let's focus on functions.",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44869916,
    "by": "munchler",
    "timeISO": "2025-08-11T21:56:51.000Z",
    "textPlain": "Every developer should know how to write a tail-recursive function and understand why it is equivalent to a loop. That said, tail recursion is rarely needed in modern functional programming. For example, why write out a recursive function when a call to `fold` or `map` will do the same thing?",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44870387,
    "by": "mehulashah",
    "timeISO": "2025-08-11T22:54:22.000Z",
    "textPlain": "Tail recursion is beautifully deep and simple. It (and as a corollary CPS) makes clear what state matters to your loop (and function) and avoids extraneous variables in loops as well as implicit unneeded state in functions. It also makes it easier to show the correctness of your loops. Sure, there are other functional language constructs like fold and map, if your problem is amenable to them. Tail recursion is more general and simpler.",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44870663,
    "by": "odyssey7",
    "timeISO": "2025-08-11T23:31:16.000Z",
    "textPlain": "High-profile places where this is sadly not implemented include:- V8 JavaScript Engine- Python",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44870385,
    "by": "wagwang",
    "timeISO": "2025-08-11T22:54:10.000Z",
    "textPlain": "Normal recursion is just a loop and a stack, turns out, if you can optimize recursion without a stack, it just becomes a loop.",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44870124,
    "by": "aryonoco",
    "timeISO": "2025-08-11T22:20:45.000Z",
    "textPlain": "For what it’s worth, in F#, tail recursive functions are  turned into equivalent loops by the .NET CLR.I actually like the compromise. I get to write safe functional code while getting all the benefits of a highly optimised iterative operation.",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44870159,
    "by": "username3",
    "timeISO": "2025-08-11T22:23:39.000Z",
    "textPlain": "> I wrote up a detailed blog post about tail call optimization in Elixir/Erlang and its performance. The TLDR; sort of is that none tail call optimized recursive functions (body-recursive) can be faster and more memory efficient than TCO functions. This is something that I never thought before, that TCO is always faster seems to be a common misconception. My example is also not contrived - it’s an implementation of map.https://pragtob.wordpress.com/2016/06/16/tail-call-optimizat...",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44870415,
    "by": "tylerhou",
    "timeISO": "2025-08-11T22:58:58.000Z",
    "textPlain": "I disagree with the title; loops are tail-recursive functions, but tail-recursive functions are not loops (in the sense that squares are rectangles, but rectangles are not squares).It is true that every tail recursive function can be converted into a semantically equivalent loop via a transformation like CPS (which the author mentions). However, for mutually tail-recursive functions, this conversion loses control flow information. This is because after the CPS transformation, calls to the other function become calls to a continuation; this call usually must be implemented as an indirect jump. On the other hand, mutually tail-recursive functions can call each other with direct/statically-known jumps.This loss of information might appear trivial, but in practice it has some important consequences. Classic examples are interpreter loops. It is well-known that computed gotos can result in modest to large speedups for interpreters [1]. The reason why is that computed gotos create an indirect jump per opcode, so a branch predictor can take advantage of correlations between opcodes. For example, looking at Python disassembly, the header of a standard range for loop compiles down to three opcodes: GET_ITER, FOR_ITER, STORE_FAST in sequence [2]. A branch predictor can recognize that the target of the \"FOR_ITER\" indirect jump will likely be the \"STORE_FAST\" instruction pointer; it cannot predict this in the naive implementation where jumps for all instructions are \"merged\" into a single indirect jump / switch at the top of the loop body. In this case, computed goto is effectively equivalent to a CPS transformation whose closures require no storage on the heap.Suppose, however, we know even more information about the instruction sequence; for example, we know ahead of time that every FOR_ITER opcode will be followed by a STORE_FAST opcode. We could completely replace the indirect jump with a direct jump to the instruction pointer for the STORE_FAST opcode. Because modern branc",
    "parent": 44837949,
    "depth": 1
  },
  {
    "id": 44871592,
    "by": "pdpi",
    "timeISO": "2025-08-12T02:14:26.000Z",
    "textPlain": "> Tail recursion IME is a bigger foot gunThis is true for some languages, but not all.E.g. scala has @tailrec annotations, which make it a compile error for the annotated function to not be tail recursive. Clojure doesn't have tail call elimination, but has the `recur` special form for explicit recursion that is guaranteed to not consume any stack space.Rust has reserved the `become` keyword  that will eventually guarantee tail call elimination (So pretty similar to Clojure's recur, but I think Rust's version will allow mutual recursion)Zig goes the whole hog, and has `@call(modifier, fn, args)`, where `modifier` can be  things like compile_time, always_tail, always_inline, never_tail, never_inline, and a bunch other desirable guarantees you might want.",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44871671,
    "by": "eru",
    "timeISO": "2025-08-12T02:27:36.000Z",
    "textPlain": "> Practically the day after I learned about tail recursion in CS class, I learned that almost all recursive calls can be translated to iteration, that in many cases the iterative version is easier to scan, is as fast if not faster, and that they can usually handle much much larger inputs than recursion due to avoiding stack overflow.What do you mean by easier to scan?  I find (most) loops [0] hard to read, because they typically involve mutable state.When properly implemented, tail calls are as fast as gotos and loops, and don't blow up any stack.  (Not all languages are implemented with a stack in any case.)However you have one point:Most of the time, we don't use recursion directly in our programs even in a language like Haskell or Scheme.  Instead we define a 'combinator' that encapsulates the specific, limited recursion scheme that we want, and then use that one.  This is very similar to how people generally don't use goto directly in their programs.You might be familiar with the combinators 'map', 'filter' and perhaps 'reduce'/'foldr'.  You could re-interpret the various common loop types as such recursion combinators that weaker languages have to bake into their language, because they are not strong enough to express them as a user-defined library.  And indeed, Haskell has Control.Monad.Loops (https://hackage.haskell.org/package/monad-loops-0.4.3/docs/C...) which gives you exactly the common loop types as a library.Some examples of less common combinators are eg 'unfold' or various combinators to traverse trees or graphs.[0] The foreach-loop over some sequence is less headache inducing than eg a while-loop.",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44869505,
    "by": "tombert",
    "timeISO": "2025-08-11T21:10:03.000Z",
    "textPlain": "In my mind, the biggest advantage to using tail recursion over vanilla loops is the ability to keep using persistent data structures without any (apparent) mutation.At least in theory, a tail recursive call will be converted into a dumb jump, so there shouldn't be a performance penalty, but since from your code's perspective you're passing in the stuff for the next iteration, you can keep using the pretty and easy-to-reason-about structures without creating any kind of mutable reference.I'm not 100% sold on tail recursion in a broader sense, but at least with Clojure's loop/recur stuff it is kind of cool to be able to keep using persistent data structures across iterations of loops.",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44871724,
    "by": "akdor1154",
    "timeISO": "2025-08-12T02:36:22.000Z",
    "textPlain": "There are cases where iteration is clearer, and there are cases where recursion is clearer.It's well worth being familiar with both - if you learn how to shoehorn both approaches where they aren't ideal, your judgement on avoiding such practices will improve. :)",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44870082,
    "by": "bjoli",
    "timeISO": "2025-08-11T22:15:52.000Z",
    "textPlain": "I am in the other camp. I prefer tail recursion and recursion over loops. However: For the simple cases it can and should probably be abstracted away like the racket for loops or my own goof-loop [1].I just feel that a recursive calls makes state much more clear, but then again I am no fan of mutation in general. In my old python days I think a good 60% of my bugs were due to me being bad at managing state.[1] https://rikspucko.koketteriet.se/bjoli/goof-loop",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44871935,
    "by": "rr808",
    "timeISO": "2025-08-12T03:09:12.000Z",
    "textPlain": "> IME is a bigger foot gun thanPretty much true for any functional feature. Great in the classroom, less practical in the real world.",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44869605,
    "by": "CalChris",
    "timeISO": "2025-08-11T21:21:41.000Z",
    "textPlain": "I must have missed this class. How does one convert a recursive descent parser into an iterative one?",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44870935,
    "by": "zelphirkalt",
    "timeISO": "2025-08-12T00:15:12.000Z",
    "textPlain": "I have my doubts about any CS class/lecture, that teaches, that the \"iterative version is easier to scan\". Might just be the bias or inexperience of the lecturer. By not I find recursive to be often easier to read than some for loop with its loop header and counter that I need to think about and update in my mind. And then the loop usually in many languages does not even have a return value, because it is not an expression, but a statement. Meeehhh, very meehhh in many languages. Not all, but many.I think maybe in languages like Ruby or Smalltalk a loop can be more readable, because of how they structure it as messages to objects, rather than special keywords in the language.",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44869756,
    "by": "javcasas",
    "timeISO": "2025-08-11T21:37:07.000Z",
    "textPlain": "Recursion deals with recursive data structures, and iteration deals with \"plain old\" data structures.When you use one to process the other, you get into trouble. For example, you need to manage a stack to do iteration on your binary tree. Or you need to construct slices to recurse on your arrays.It's all about ergonomics.",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44869980,
    "by": "Spivak",
    "timeISO": "2025-08-11T22:04:17.000Z",
    "textPlain": "I'm in your camp, recursive code is hard for the next reader, which might be you, to understand. It's a bit too magic looking for my taste. If you're looping it should look like a loop, if you're pushing  onto a stack you should get to see the stack. It's also safe against modifications which might silently break the tail-call nature of it until you blow out the stack later. It also gives you much saner and more debuggable stack traces because all the state is in the current frame.",
    "parent": 44869452,
    "depth": 2
  },
  {
    "id": 44871913,
    "by": "eru",
    "timeISO": "2025-08-12T03:06:55.000Z",
    "textPlain": "Loops and gootos are just a special case of function calls, that needed to be invented because back in the olden days we had no clue how to design language and write compilers.I don't understand why someone would want to hold on nostalgically to restrictions we no longer face.Controlled mutability is a step up, yes.  Btw, even languages like Haskell give you plenty of mutability to play with, if you want to.  (Eg MVars and TVars are a thing.)You are right that replacing a loop one for one with a tail recursive version doesn't give you much benefit either way.  (Though it does make my life easier, because you don't have to contort my brain around keeping track of mutation.)However that's a bit of a straw man and misses the broader picture.What you'd want to do is define combinators that encapsulate the specific pattern of computation you want to implement.  The most commonly known combinators are things like 'map' and 'filter'.  But there are plenty more useful ones you can define, like various tree traversals or whatever makes sense for use cases and data structures.Whether those combinators are implemented with tail calls or with loops or gotos or whatever is an implementation detail that their users don't need to worry about.I know of one major use case where you'd want to use tail recursion directly: state machines and interpreters.  See https://news.ycombinator.com/item?id=43076088 for an example of the latter.  See https://en.wikisource.org/wiki/Lambda:_The_Ultimate_GOTO for an example of the former.",
    "parent": 44870562,
    "depth": 2
  },
  {
    "id": 44870960,
    "by": "zelphirkalt",
    "timeISO": "2025-08-12T00:19:11.000Z",
    "textPlain": "But Rust's semantics make it less ergonomic to pass values and especially once you do any mutation, that code path is no longer trivially up for parallelization/concurrency. There one will have to lean into what Rust offers to make it safe again, which brings along more syntax. When one wants to pass values, one needs to implement clone or copy or something, and then explicitly clone or copy or so.It is a tradeoff one can make, and it lends itself to high performance but it does come at a cost.",
    "parent": 44870562,
    "depth": 2
  },
  {
    "id": 44869917,
    "by": "dreamcompiler",
    "timeISO": "2025-08-11T21:57:01.000Z",
    "textPlain": "Clojure does it this way because the JVM stupidly doesn't support tail call optimization.It is true that TCO messes up your stack traces. It is also true that loops mess up your stack traces, because they don't even create a stack trace. In many languages that support TCO, TCO can be turned off for debugging and enabled for production, so Guido's characterization of the issue is ridiculous.",
    "parent": 44869480,
    "depth": 2
  },
  {
    "id": 44870050,
    "by": "kmicinski",
    "timeISO": "2025-08-11T22:12:49.000Z",
    "textPlain": "I agree with you--that's a topic I will definitely cover in my blog, too. You make a good point: I know some folks who worked at big financial orgs, writing hundreds of thousands of lines of code, and never wrote general-recursive functions (only used simple recursors like foldl).",
    "parent": 44869916,
    "depth": 2
  },
  {
    "id": 44870982,
    "by": "zelphirkalt",
    "timeISO": "2025-08-12T00:23:30.000Z",
    "textPlain": "I wouldn't say \"rarely\", unless you have a whole host of other higher order functions at your disposal for more special cases than map and fold. There are many cases, where you don't want to fold or map over the whole data structure and want to exit early with a result already. Writing tail recursive functions is still very common.",
    "parent": 44869916,
    "depth": 2
  },
  {
    "id": 44869999,
    "by": "xdavidliu",
    "timeISO": "2025-08-11T22:06:05.000Z",
    "textPlain": "it's not entirely true that it does the same thing: even if it gives the same result. For many programming languages, fold and map can only act on non-lazy data structures, so require O(N) memory for the data that needs to be folded over, while tail-recursive functions usually only use O(1) memory, even stack memory.Notable exceptions to the above are python3 with generators, which I believe truly use O(1) memory with map and fold. Haskell has lists that are lazy by default, but if you fold or map over them, it still \"forces the thunk\" for each element and thus you still end up using O(N) memory.",
    "parent": 44869916,
    "depth": 2
  },
  {
    "id": 44870033,
    "by": "Eji1700",
    "timeISO": "2025-08-11T22:10:18.000Z",
    "textPlain": "> For example, why write out a recursive function when a call to `fold` or `map` will do the same thing?Yeah this was a big help when I started F#.  Basically \"if you're using the rec keyword, you're probably missing something\" and hell that even goes for a lot of uses of fold, from the beginners perspective.",
    "parent": 44869916,
    "depth": 2
  },
  {
    "id": 44871978,
    "by": "eru",
    "timeISO": "2025-08-12T03:15:16.000Z",
    "textPlain": "I have almost the opposite view: tail calls are great.But most of the time you will want to express your program in terms of more restricted combinators, because restriction makes the readers job easier.  Easier to understand, and easier to convince yourself that no weird things are happening.Basically, you might already agree that restricting mutation is good.  This is the same principle.So when you see a 'fold' you know even without looking at the callback, that your program will run through the whole list and not exit early.  When you see a 'map' you also know that no early exit will happen, but even more you know exactly how the return value will be constructed (whereas for fold that's arbitrary).However you are right that 'fold' and 'filter' and 'map', just like 'for' and 'while', are not good as universal building blocks.That's why you should define new combinators when you need them.  Typically, that's when you define new data structures, eg when you define a tree you will also want to define a 'map' for it, and also various tree traversals and perhaps searches.  Less typically, you also want new combinators for new algorithmic ideas, even on old data structures.Eg matrix multiplication is an interesting combinator.  You provide the meaning of 'addition' and 'multiplication' as call-backs, and depending on your choice you get an algorithm for finding shortest paths or for matching regular expressions etc (in addition to the obvious matrix-multiplication on real numbers, of course).  See https://news.ycombinator.com/item?id=9751987It's relatively seldom that you want to use 'naked' recursion.  The main example I can think of is when implementing state machine or interpreters.  See eg https://news.ycombinator.com/item?id=43076088 for the latter, and https://news.ycombinator.com/item?id=43076088 for the former.",
    "parent": 44870387,
    "depth": 2
  },
  {
    "id": 44871982,
    "by": "kmicinski",
    "timeISO": "2025-08-12T03:15:52.000Z",
    "textPlain": "I appreciate your thoughtful criticism of the post, to my eyes everything you are saying is correct.",
    "parent": 44870415,
    "depth": 2
  }
]