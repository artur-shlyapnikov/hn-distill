[
  {
    "id": 44879928,
    "by": "skrebbel",
    "timeISO": "2025-08-12T18:15:37.000Z",
    "textPlain": "This article is beautifully written, and it's full of proper original research. I'm sad that most comments so far are knee-jerk \"lol rationalists\" type responses. I haven't seen any comment yet that isn't already addressed in much more colour and nuance in the article itself.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44881718,
    "by": "pavlov",
    "timeISO": "2025-08-12T20:55:39.000Z",
    "textPlain": "A very interesting read.My idea of these self-proclaimed rationalists was fifteen years out of date. I thought they’re people who write wordy fan fiction, but turns out they’ve reached the point of having subgroups that kill people and exorcise demons.This must be how people who had read one Hubbard pulp novel in the 1950s felt decades later when they find out he’s running a full-blown religion now.The article seems to try very hard to find something positive to say about these groups, and comes up with:“Rationalists came to correct views about the COVID-19 pandemic while many others were saying masks didn’t work and only hypochondriacs worried about covid; rationalists were some of the first people to warn about the threat of artificial intelligence.”There’s nothing very unique about agreeing with the WHO, or thinking that building Skynet might be bad… (The rationalist Moses/Hubbard was 12 when that movie came out — the most impressionable age.) In the wider picture painted by the article, these presumed successes sound more like a case of a stopped clock being right twice a day.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44883651,
    "by": "jmoggr",
    "timeISO": "2025-08-13T01:17:43.000Z",
    "textPlain": "I think the comments here have been overly harsh. I have friends in the community and have visited the LessWrong \"campus\" several times. They seemed very welcoming, sincere, and were kind and patient even when I was basically asserting that several of their beliefs were dumb (in hopefully somewhat respectful manner).As for the AI doomerism, many in the community have more immediate and practical concerns about AI, however the most extreme voices are often the most prominent. I also know that there has been internal disagreement on the kind of messaging they should be using to raise concern.I think rationalists get plenty of things wrong, but I suspect that many people would benefit from understanding their perspective and reasoning.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877844,
    "by": "JohnMakin",
    "timeISO": "2025-08-12T15:45:44.000Z",
    "textPlain": "One of a few issues I have with groups like these, is that they often confidently and aggressively spew a set of beliefs that on their face logically follow from one another, until you realize they are built on a set of axioms that are either entirely untested or outright nonsense. This is common everywhere, but I feel especially pronounced in communities like this. It also involves quite a bit of navel gazing that makes me feel a little sick participating in.The smartest people I have ever known have been profoundly unsure of their beliefs and what they know. I immediately become suspicious of anyone who is very certain of something, especially if they derived it on their own.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880588,
    "by": "gwbas1c",
    "timeISO": "2025-08-12T19:10:48.000Z",
    "textPlain": "Many years ago I met Eliezer Yudkowsky. He handed me a pamphlet extolling the virtues of rationality. The whole thing came across as a joke, as a parody of evangelizing. We both laughed.I glanced at it once or twice and shoved it into a bookshelf. I wish I kept it, because I never thought so much would happen around him.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880994,
    "by": "vehemenz",
    "timeISO": "2025-08-12T19:42:25.000Z",
    "textPlain": "I get the impression that these people desperately want to study philosophy but for some reason can't be bothered to get formal training because it would be too humbling for them. I call it \"small fishbowl syndrome,\" but maybe there's a better term for it.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44881572,
    "by": "Jtsummers",
    "timeISO": "2025-08-12T20:40:57.000Z",
    "textPlain": "> Many of them also expect that, without heroic effort, AGI development will lead to human extinction.> These beliefs can make it difficult to care about much of anything else: what good is it to be a nurse or a notary or a novelist, if humanity is about to go extinct?Replace AGI causing extinction with the Rapture and you get a lot of US Christian fundamentalists. They often reject addressing problems in the environment, economy, society, etc. because the Rapture will happen any moment now. Some people just end up stuck in a belief about something catastrophic (in the case of the Rapture, catastrophic for those left behind but not those raptured) and they can't get it out of their head. For individuals who've dealt with anxiety disorder, catastrophizing is something you learn to deal with (and hopefully stop doing), but these folks find a community that reinforces the belief about the pending catastrophe(s) and so they never get out of the doom loop.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877301,
    "by": "bobson381",
    "timeISO": "2025-08-12T15:13:16.000Z",
    "textPlain": "I keep thinking about the first Avengers movie, when Loki is standing above everyone going \"See, is this not your natural state?\". There's some perverse security in not getting a choice, and these rationalist frameworks, based in logic, can lead in all kinds of crazy arbitrary directions - powered by nothing more than a refusal to suffer any kind of ambiguity.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879787,
    "by": "Mizza",
    "timeISO": "2025-08-12T18:03:09.000Z",
    "textPlain": "It's amphetamine. All of these people are constantly tweaking. They're annoying people to begin with, but they're all constantly yakked up and won't stop babbling. It's really obvious, I don't know why it isn't highlighted more in all these post Ziz articles.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877593,
    "by": "meroes",
    "timeISO": "2025-08-12T15:29:58.000Z",
    "textPlain": "It grew out of many different threads: different websites, communities, etc all around the same time. I noticed it contemporaneously in the philosophy world where Nick Bostrom’s Simulation argument was boosted more than it deserved (like everyone was just accepting it at the lay-level). Looking back I see it also developed from less wrong and other sites, but I was wondering what was going on with simulations taking over philosophy talk. Now I see how it all coalesced.All of it has the appearance of sounding so smart, and a few sites were genuine. But it got taken over.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44882055,
    "by": "pizzadog",
    "timeISO": "2025-08-12T21:34:11.000Z",
    "textPlain": "I have a lot of experience with rationalists. What I will say is:1) If you have a criticism about them or their stupid name or how \"'all I know is that I know nothing' how smug of them to say they're truly wise,\" rest assured they have been self flagellating over these criticisms 100x longer than you've been aware of their group. That doesn't mean they succeeded at addressing the criticisms, of course, but I can tell you that they are self aware. Especially about the stupid name.2) They are actually well read. They are not sheltered and confused. They are out there doing weird shit together all the time. The kind of off-the-wall life experiences you find in this community will leave you wide eyed.3) They are genuinely concerned with doing good. You might know about some of the weird, scary, or cringe rationalist groups. You probably haven't heard about the ones that are succeeding at doing cool stuff because people don't gossip about charitable successes.In my experience, where they go astray is when they trick themselves into working beyond their means. The basic underlying idea behind most rationalist projects is something like \"think about the way people suffer everyday. How can we think about these problems in a new way? How can we find an answer that actually leaves everyone happy?\" A cynic (or a realist, depending on your perspective) might say that there are many problems that fundamentally will leave some group unhappy. The overconfident rationalist will challenge that cynical/realist perspective until they burn themselves out, and in many cases they will attract a whole group of people who burn out alongside them. To consider an extreme case, the Zizians squared this circle by deciding that the majority of human beings didn't have souls and so \"leaving everyone happy\" was as simple as ignoring the unsouled masses. In less extreme cases this presents itself as hopeless idealism, or a chain of logic that becomes so divorced from normal socialization that it a",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44883709,
    "by": "a_bonobo",
    "timeISO": "2025-08-13T01:26:51.000Z",
    "textPlain": "This is a great article.There's so much in these group dynamics that repeats group dynamics of communist extremists of the 70s. A group that has found a 'better' way of life, all you have to do is believe in the group's beliefs.Compare this part from OP:>Here is a sampling of answers from people in and close to dysfunctional groups: “We spent all our time talking about philosophy and psychology and human social dynamics, often within the group.” “Really tense ten-hour conversations about whether, when you ate the last chip, that was a signal that you were intending to let down your comrades in selfish ways in the future.”This reeks of Marxist-Leninist self-criticism, where everybody tried to up each other in how ideologically pure they were. The most extreme outgrowing of self-criticism is when the Japanese United Red Army beat its own members to death as part of self-criticisms.>'These violent beatings ultimately saw the death of 12 members of the URA who had been deemed not sufficiently revolutionary.' https://en.wikipedia.org/wiki/United_Red_ArmyHistory doesn't repeat, but it rhymes.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880878,
    "by": "psunavy03",
    "timeISO": "2025-08-12T19:33:08.000Z",
    "textPlain": "A problem with this whole mindset is that humans, all of us, are only quasi-rational beings.  We all use System 1 (\"The Elephant\") and System 2 (\"The Rider\") thinking instinctively.  So if you end up in deep denial about your own capacity for irrationality, I guess it stands to reason you could end up getting led down some deep dark rabbit holes.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879831,
    "by": "JKCalhoun",
    "timeISO": "2025-08-12T18:07:25.000Z",
    "textPlain": "> Many of them also expect that, without heroic effort, AGI development will lead to human extinction.Odd to me. Not biological warfare? Global warming? All-out nuclear war?I guess The Terminator was a formative experience for them. (For me perhaps it was The Andromeda Strain.)",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880838,
    "by": "Liftyee",
    "timeISO": "2025-08-12T19:30:34.000Z",
    "textPlain": "Finally, something that properly articulates my unease when encountering so-called \"rationalists\" (especially the ones that talk about being \"agentic\", etc.). For some reason, even though I like logical reasoning, they always rubbed me the wrong way - probably just a clash between their behavior and my personal values (mainly humility).",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877273,
    "by": "mlinhares",
    "timeISO": "2025-08-12T15:11:09.000Z",
    "textPlain": "> One is Black Lotus, a Burning Man camp led by alleged rapist Brent Dill, which developed a metaphysical system based on the tabletop roleplaying game Mage the Ascension.What the actual f. This is such an insane thing to read and understand what it means that i might need to go and sit in silence for the rest of the day.How did we get to this place with people going completely nuts like this?",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877326,
    "by": "nathan_compton",
    "timeISO": "2025-08-12T15:14:53.000Z",
    "textPlain": "Thinking too hard about anything will drive you insane but I think the real issue here is that rationalists simply over-estimate both the power of rational thought and their ability to do it. If you think of people who tend to make that kind of mistake you can see how you get a lot of crazy groups.I guess I'm a radical skeptic, secular humanist, utilitarianish sort of guy, but I'm not dumb enough to think throwing around the words \"bayesian prior\" and \"posterior distribution\" makes actually figuring out how something works or predicting the outcome of an intervention easy or certain. I've had a lot of life at this point and gotten to some level of mastery at a few things and my main conclusion is that most of the time its just hard to know stuff and that the single most common cognitive mistake people make is too much certainty.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879743,
    "by": "VonGuard",
    "timeISO": "2025-08-12T17:58:20.000Z",
    "textPlain": "This is actually a known pattern in tech, going back to Engelbart and SRI. While not 1-to-1, you could say that the folks who left SRI for Xerox PARC did so because Engelbart and his crew became obsessed with EST: https://en.wikipedia.org/wiki/Erhard_Seminars_TrainingEST-type training still exists today. You don't eat until the end of the whole weekend, or maybe you get rice and little else. Everyone is told to insult you day one until you cry. Then day two, still having not eaten, they build you up and tell you how great you are and have a group hug. Then they ask you how great you feel. Isn't this a good feeling? Don't you want your loved ones to have this feeling? Still having not eaten, you're then encouraged to pay for your family and friends to do the training, without their knowledge or consent.A friend of mine did this training after his brother paid for his mom to do it, and she paid for him to do it. Let's just say that, though they felt it changed their lives at the time, their lives in no way shape or form changed. Two are in quite a bad place, in fact...Anyway, point is, the people who invented everything we are using right now were also susceptible to cult-like groups with silly ideas and shady intentions.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877827,
    "by": "dfabulich",
    "timeISO": "2025-08-12T15:44:53.000Z",
    "textPlain": "The whole game of Rationalism is that you should ignore gut intuitions and cultural norms that you can't justify with rational arguments.Well, it turns out that intuition and long-lived cultural norms often have rational justifications, but individuals may not know what they are, and norms/intuitions provide useful antibodies against narcissist would-be cult leaders.Can you find the \"rational\" justification not to isolate yourself from non-Rationalists, not to live with them in a polycule, and not to take a bunch of psychedelic drugs with them? If you can't solve that puzzle, you're in danger of letting the group take advantage of you.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877461,
    "by": "j_m_b",
    "timeISO": "2025-08-12T15:22:53.000Z",
    "textPlain": "> One way that thinking for yourself goes wrong is that you realize your society is wrong about something, don’t realize that you can’t outperform it, and wind up even wronger.many such cases",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44881055,
    "by": "caycep",
    "timeISO": "2025-08-12T19:48:21.000Z",
    "textPlain": "Granted, admitted from what little I've read on the outside, the \"rational\" part just seems to be mostly the writing style - this sort of dispassionate, eloquently worded prose that makes weird ideas seem more \"rational\" and logical than they really are.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44881853,
    "by": "guerrilla",
    "timeISO": "2025-08-12T21:13:14.000Z",
    "textPlain": "> One way that thinking for yourself goes wrong is that you realize your society is wrong about something, don’t realize that you can’t outperform it, and wind up even wronger.I've been there myself.> And without the steadying influence of some kind of external goal you either achieve or don’t achieve, your beliefs can get arbitrarily disconnected from reality — which is very dangerous if you’re going to act on them.I think this and the entire previous two paragraphs preceding it are excellent arguments for philosophical pragmatism and empiricism. It's strange to me that the community would not have already converged on that after all their obsessions with decision theory.> The Zizians and researchers at Leverage Research both felt like heroes, like some of the most important people who had ever lived. Of course, these groups couldn’t conjure up a literal Dark Lord to fight. But they could imbue everything with a profound sense of meaning. All the minor details of their lives felt like they had the fate of humanity or all sentient life as the stakes. Even the guilt and martyrdom could be perversely appealing: you could know that you’re the kind of person who would sacrifice everything for your beliefs.This helps me understand what people mean by \"meaning\". A sense that their life and actions actually matter. I've always struggled to understand this issue but this helps make it concrete, the kind of thing people must be looking for.> One of my interviewees speculated that rationalists aren’t actually any more dysfunctional than anywhere else; we’re just more interestingly dysfunctional.\"We're\"? The author is a rationalist too? That would definitely explain why this article is so damned long. Why are rationalists not able to write less? It sounds like a joke but this is seriously a thing. [EDIT: Various people further down in the comments are saying it's amphetamines and yes, I should have known that from my own experience. That's exactly what it is.]> Consider talkin",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44878088,
    "by": "biophysboy",
    "timeISO": "2025-08-12T15:59:01.000Z",
    "textPlain": "> “There’s this belief [among rationalists],” she said, “that society has these really bad behaviors, like developing self-improving AI, or that mainstream epistemology is really bad–not just religion, but also normal ‘trust-the-experts’ science. That can lead to the idea that we should figure it out ourselves. And what can show up is that some people aren't actually smart enough to form very good conclusions once they start thinking for themselves.”I see this arrogant attitude all the time on HN: reflexive distrust of the \"mainstream media\" and \"scientific experts\". Critical thinking is a very healthy idea, but its dangerous when people use it as a license to categorically reject sources. Its even worse when extremely powerful people do this; they can reduce an enormous sub-network of thought into a single node for many many people.So, my answer for \"Why Are There So Many Rationalist Cults?\" is the same reason all cults exist: humans like to feel like they're in on the secret. We like to be in secret clubs.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44883553,
    "by": "duxup",
    "timeISO": "2025-08-13T01:00:56.000Z",
    "textPlain": "I remember going to college and some graduate student, himself a philosophy major, telling me that nobody is as big a jerk as philosophy majors.I don't know if it is really true, but it certainly felt true that folks looking for deeper answers about a better way to think about things end up finding what they believe is the \"right\" way and that tends to lead to branding other options as \"wrong\".A search for certainty always seems to be defined or guided by people dealing with their own issues and experiences that they can't explain.  It gets tribal and very personal and those kind of things become dark rabbit holes.---->Jessica Taylor, an AI researcher who knew both Zizians and participants in Leverage Research, put it bluntly. “There’s this belief [among rationalists],” she said, “that society has these really bad behaviors, like developing self-improving AI, or that mainstream epistemology is really bad–not just religion, but also normal ‘trust-the-experts’ science. That can lead to the idea that we should figure it out ourselves. And what can show up is that some people aren't actually smart enough to form very good conclusions once they start thinking for themselves.”Reminds me of some members of our government and conspiracy theorists who \"research\" and encourage people to figure it out themselves ...",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877595,
    "by": "alphazard",
    "timeISO": "2025-08-12T15:30:09.000Z",
    "textPlain": "The terminology here is worth noting.  Is a Rationalist Cult a cult that practices Rationalism according to third parties, or is it a cult that says they are Rationalist?Clearly all of these groups that believe in demons or realities dictated by tabletop games are not what third parties would call Rationalist.  They might call themselves that.There are some pretty simple tests that can out these groups as not rational.  None of these people have ever seen a demon, so world models including demons have never predicted any of their sense data.  I doubt these people would be willing to make any bets about when or if a demon will show up.  Many of us would be glad to make a market concerning predictions made by tabletop games about physical phenomenon.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44883498,
    "by": "homeonthemtn",
    "timeISO": "2025-08-13T00:54:39.000Z",
    "textPlain": "This just sounds like any other community based around a niche interest.From kink to rock hounding, there's always people who base their identity on being a broker of status or power because they themselves are a powerless outsider once removed from the community",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44883165,
    "by": "Lerc",
    "timeISO": "2025-08-12T23:54:37.000Z",
    "textPlain": "Reading the other comments makes me wonder if they just misread the sign and they were looking for the rationalizationist meeting.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880527,
    "by": "thedudeabides5",
    "timeISO": "2025-08-12T19:06:00.000Z",
    "textPlain": "Purity Spirals + Cheap Talk = irrational rationalists",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44882138,
    "by": "kanzure",
    "timeISO": "2025-08-12T21:44:27.000Z",
    "textPlain": "Here are some other anti-lesswrong materials to consider:https://aiascendant.com/p/extropias-children-chapter-1-the-w...https://davidgerard.co.uk/blockchain/2023/02/06/ineffective-...https://www.bloomberg.com/news/features/2023-03-07/effective...https://www.vox.com/future-perfect/23458282/effective-altrui...https://qchu.substack.com/p/eliezerhttps://x.com/kanzure/status/1726251316513841539",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877638,
    "by": "wiredfool",
    "timeISO": "2025-08-12T15:32:32.000Z",
    "textPlain": "It's really worth reading up on the techniques from Large Group Awareness Training so that you can recognize them when they pop up.Once you see them listed (social pressure, sleep deprivation, control of drinking/bathroom, control of language/terminology, long exhausting activities, financial buy in, etc) and see where they've been used in cults and other cult adjacent things it's a little bit of a warning signal when you run across them IRL.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877427,
    "by": "AIPedant",
    "timeISO": "2025-08-12T15:21:09.000Z",
    "textPlain": "I think I found the problem!  The rationalist community was drawn together by AI researcher Eliezer Yudkowsky’s blog post series The Sequences, a set of essays about how to think more rationally\n\nI actually don't mind Yudkowski as an individual - I think he is almost always wrong and undeservedly arrogant, but mostly sincere. Yet treating him as an AI researcher and serious philosopher (as opposed to a sci-fi essayist and self-help writer) is the kind of slippery foundation that less scrupulous people can build cults from. (See also Maharishi Mahesh Yogi and related trends - often it is just a bit of spiritual goofiness as with David Lynch, sometimes you get a Charles Manson.)",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44881552,
    "by": "mathattack",
    "timeISO": "2025-08-12T20:38:05.000Z",
    "textPlain": "On a recent Mindscape podcast Sean Carroll mentioned that rationalists are rational about everything except accusations that they're not being rational.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879665,
    "by": "kazinator",
    "timeISO": "2025-08-12T17:51:57.000Z",
    "textPlain": "The only way you can hope to get a gathering of nothing but paragons of critical thinking and skepticism is if the gathering has an entrance exam in critical thinking and skepticism (and a pretty tough one, if they are to be paragons). Or else, it's invitation-only.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44881298,
    "by": "mordnis",
    "timeISO": "2025-08-12T20:16:52.000Z",
    "textPlain": "I really like your suggestions, even for non-rationalists.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44882109,
    "by": "gwbas1c",
    "timeISO": "2025-08-12T21:40:51.000Z",
    "textPlain": "One thing I'm having trouble with: The article assumes the reader knows some history about the rationalists.I listened to a podcast that covered some of these topics, so I'm not lost; but I think someone who's new to this topic will be very, very, confused.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44878853,
    "by": "jancsika",
    "timeISO": "2025-08-12T16:49:22.000Z",
    "textPlain": "> And what can show up is that some people aren't actually smart enough to form very good conclusions once they start thinking for themselves.It's mostly just people who aren't very experienced talking about and dealing honestly with their emotions, no?I mean, suppose someone is busy achieving and, at the same time, proficient in balancing work with emotional life, dealing head-on with interpersonal conflicts, facing change, feeling and acknowledging hurt, knowing their emotional hangups, perhaps seeing a therapist, perhaps even occasionally putting personal needs ahead of career... :)Tell that person they can get a marginal (or even substantial) improvement from some rationalist cult practice. Their first question is going to be, \"What's the catch?\" Because at the very least they'll suspect that adjusting their work/life balance will bring a sizeable amount of stress and consequent decrease in their emotional well-being. And if the pitch is that this rationalist practice works equally well at improving emotional well-being, that smells to them. They already know they didn't logic themselves into their current set of emotional issues, and they are highly unlikely to logic themselves out of them. So there's not much value here to offset the creepy vibes of the pitch. (And again-- being in touch with your emotions means quicker and deeper awareness of creepy vibes!)Now, take a person whose unexplored emotional well-being tacitly depends on achievement. Even a marginal improvement in achievement could bring perceptible positive changes in their holistic selves! And you can step through a well-specified, logical process to achieve change? Sign HN up!",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877732,
    "by": "bubblyworld",
    "timeISO": "2025-08-12T15:38:54.000Z",
    "textPlain": "What is the base rate here? Hard to know the scope of the problem without knowing how many non-rationalists (is that even a coherent group of people?) end up forming weird cults, as a comparison. My impression is that crazy beliefs are common amongst everybody.A much simpler theory is that rationalists are mostly normal people, and normal people tend to form cults.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877853,
    "by": "animal_spirits",
    "timeISO": "2025-08-12T15:46:01.000Z",
    "textPlain": "> If someone is in a group that is heading towards dysfunctionality, try to maintain your relationship with them; don’t attack them or make them defend the group. Let them have normal conversations with you.This is such an important skill we should all have. I learned this best from watching the documentary Behind the Curve, about flat earthers, and have applied it to my best friend diving into the Tartarian conspiracy theory.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877446,
    "by": "lenerdenator",
    "timeISO": "2025-08-12T15:22:09.000Z",
    "textPlain": "Because humans like people who promise answers.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44881838,
    "by": "IX-103",
    "timeISO": "2025-08-12T21:11:46.000Z",
    "textPlain": "Is it really that surprising that a group of humans who think they have some special understanding of reality compared to others tend to separate and isolate themselves until they fall into an unguided self-reinforcing cycle?I'd have thought that would be obvious since it's the history of many religions (which seem to just be cults that survived the bottleneck effect to grow until they reached a sustainable population).In other words, humans are wired for tribalism, so don't be surprised when they start forming tribes...",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877258,
    "by": "optimalsolver",
    "timeISO": "2025-08-12T15:10:31.000Z",
    "textPlain": "Pertinent Twitter comment:\"Rationalism is such an insane name for a school of thought. Like calling your ideology correctism or winsargumentism\"https://x.com/growing_daniel/status/1893554844725616666",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44881504,
    "by": "jmull",
    "timeISO": "2025-08-12T20:34:46.000Z",
    "textPlain": "I think rationalist cults work exactly the same as religious cults. They promise to have all the answers, to attract the vulnerable. The answers are convoluted and inscrutable, so a leader/prophet interprets them. And doom is neigh, providing motivation and fear to hold things together.It's the same wolf in another sheep's clothing.And people who wouldn't join a religious cult -- e.g. because religious cults are too easy to recognize since we're all familiar with them, or because religions hate anything unusual about gender -- can join a rationalist cult instead.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44882976,
    "by": "crazydoggers",
    "timeISO": "2025-08-12T23:28:09.000Z",
    "textPlain": "Trying to find life’s answers by giving over your self authority to another individual or group’s philosophy is not rational. Submitting oneself to an authority who’s role is telling people what’s best in life will always lead to attracting the type of people looking to control, take advantage and traumatize others.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44883328,
    "by": "marstall",
    "timeISO": "2025-08-13T00:23:05.000Z",
    "textPlain": "Harpers did an amazing cover story on these freaks in 2015 https://harpers.org/archive/2015/01/come-with-us-if-you-want...",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44882053,
    "by": "hax0ron3",
    "timeISO": "2025-08-12T21:34:00.000Z",
    "textPlain": "The premise of the article might just be nonsense.How many rationalists are there in the world? Of course it depends on what you mean by rationalist, but I'd guess that there are probably several tens of thousands, at very least, people in the world who either consider themselves rationalists or are involved with the rationalist community.With such numbers, is it surprising that there would be half a dozen or so small cults?There are certainly some cult-like aspects to certain parts of the rationalist community, and I think that those are interesting to explore, but come on, this article doesn't even bother to establish that its title is justified.To the extent that rationalism does have some cult-like aspects, I think a lot of it is because it tends to attract smart people who are deficient in the ability to use avenues other than abstract thinking to comprehend reality and who enjoy making loosely justified imaginative leaps of thought while overestimating their own abilities to model reality. The fact that a huge fraction of rationalists are sci-fi fans is not a coincidence.But again, one should first establish that there is anything actually unusual about the number of cults in the rationalist community. Otherwise this is rather silly.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880205,
    "by": "rogerkirkness",
    "timeISO": "2025-08-12T18:40:38.000Z",
    "textPlain": "Because they have serious emotional maturity issues leading to lobotomizing their normal human emotional side of their identity and experience of life.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880090,
    "by": "jameslk",
    "timeISO": "2025-08-12T18:28:57.000Z",
    "textPlain": "Over rationalizing is paperclip maximizing",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877916,
    "by": "gadders",
    "timeISO": "2025-08-12T15:49:15.000Z",
    "textPlain": "They are literally the \"ackchyually\" meme made flesh.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44878213,
    "by": "digbybk",
    "timeISO": "2025-08-12T16:07:02.000Z",
    "textPlain": "When I was looking for a group in my area to meditate with, it was tough finding one that didn't appear to be a cult. And yet I think Buddhist meditation is the best tool for personal growth humanity has ever devised. Maybe the proliferation of cults is a sign that Yudkowsky was on to something.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877412,
    "by": "cjs_ac",
    "timeISO": "2025-08-12T15:20:07.000Z",
    "textPlain": "Rationalism is the belief that reason is the primary path to knowledge, as opposed to, say, the observation that is championed by empiricism. It's a belief system that prioritises imposing its tenets on reality rather than asking reality what reality's tenets are. From the outset, it's inherently cult-like.",
    "parent": 44877076,
    "depth": 1
  }
]