[
  {
    "id": 44877844,
    "by": "JohnMakin",
    "timeISO": "2025-08-12T15:45:44.000Z",
    "textPlain": "One of a few issues I have with groups like these, is that they often confidently and aggressively spew a set of beliefs that on their face logically follow from one another, until you realize they are built on a set of axioms that are either entirely untested or outright nonsense. This is common everywhere, but I feel especially pronounced in communities like this. It also involves quite a bit of navel gazing that makes me feel a little sick participating in.The smartest people I have ever known have been profoundly unsure of their beliefs and what they know. I immediately become suspicious of anyone who is very certain of something, especially if they derived it on their own.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879787,
    "by": "Mizza",
    "timeISO": "2025-08-12T18:03:09.000Z",
    "textPlain": "It's amphetamine. All of these people are constantly tweaking. They're annoying people to begin with, but they're all constantly yakked up and won't stop babbling. It's really obvious, I don't know why it isn't highlighted more in all these post Ziz articles.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879928,
    "by": "skrebbel",
    "timeISO": "2025-08-12T18:15:37.000Z",
    "textPlain": "This article is beautifully written, and it's full of proper original research. I'm sad that most comments so far are knee-jerk \"lol rationalists\" type responses. I haven't seen any comment yet that isn't already addressed in much more colour and nuance in the article itself.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880588,
    "by": "gwbas1c",
    "timeISO": "2025-08-12T19:10:48.000Z",
    "textPlain": "Many years ago I met Eliezer Yudkowsky. He handed me a pamphlet extolling the virtues of rationality. The whole thing came across as a joke, as a parody of evangelizing. We both laughed.I glanced at it once or twice and shoved it into a bookshelf. I wish I kept it, because I never thought so much would happen around him.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877301,
    "by": "bobson381",
    "timeISO": "2025-08-12T15:13:16.000Z",
    "textPlain": "I keep thinking about the first Avengers movie, when Loki is standing above everyone going \"See, is this not your natural state?\". There's some perverse security in not getting a choice, and these rationalist frameworks, based in logic, can lead in all kinds of crazy arbitrary directions - powered by nothing more than a refusal to suffer any kind of ambiguity.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877593,
    "by": "meroes",
    "timeISO": "2025-08-12T15:29:58.000Z",
    "textPlain": "It grew out of many different threads: different websites, communities, etc all around the same time. I noticed it contemporaneously in the philosophy world where Nick Bostrom’s Simulation argument was boosted more than it deserved (like everyone was just accepting it at the lay-level). Looking back I see it also developed from less wrong and other sites, but I was wondering what was going on with simulations taking over philosophy talk. Now I see how it all coalesced.All of it has the appearance of sounding so smart, and a few sites were genuine. But it got taken over.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880527,
    "by": "thedudeabides5",
    "timeISO": "2025-08-12T19:06:00.000Z",
    "textPlain": "Purity Spirals + Cheap Talk = irrational rationalists",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879743,
    "by": "VonGuard",
    "timeISO": "2025-08-12T17:58:20.000Z",
    "textPlain": "This is actually a known pattern in tech, going back to Engelbart and SRI. While not 1-to-1, you could say that the folks who left SRI for Xerox PARC did so because Engelbart and his crew became obsessed with EST: https://en.wikipedia.org/wiki/Erhard_Seminars_TrainingEST-type training still exists today. You don't eat until the end of the whole weekend, or maybe you get rice and little else. Everyone is told to insult you day one until you cry. Then day two, still having not eaten, they build you up and tell you how great you are and have a group hug. Then they ask you how great you feel. Isn't this a good feeling? Don't you want your loved ones to have this feeling? Still having not eaten, you're then encouraged to pay for your family and friends to do the training, without their knowledge or consent.A friend of mine did this training after his brother paid for his mom to do it, and she paid for him to do it. Let's just say that, though they felt it changed their lives at the time, their lives in no way shape or form changed. Two are in quite a bad place, in fact...Anyway, point is, the people who invented everything we are using right now were also susceptible to cult-like groups with silly ideas and shady intentions.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877273,
    "by": "mlinhares",
    "timeISO": "2025-08-12T15:11:09.000Z",
    "textPlain": "> One is Black Lotus, a Burning Man camp led by alleged rapist Brent Dill, which developed a metaphysical system based on the tabletop roleplaying game Mage the Ascension.What the actual f. This is such an insane thing to read and understand what it means that i might need to go and sit in silence for the rest of the day.How did we get to this place with people going completely nuts like this?",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879831,
    "by": "JKCalhoun",
    "timeISO": "2025-08-12T18:07:25.000Z",
    "textPlain": "> Many of them also expect that, without heroic effort, AGI development will lead to human extinction.Odd to me. Not biological warfare? Global warming? All-out nuclear war?I guess The Terminator was a formative experience for them. (For me perhaps it was The Andromeda Strain.)",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877461,
    "by": "j_m_b",
    "timeISO": "2025-08-12T15:22:53.000Z",
    "textPlain": "> One way that thinking for yourself goes wrong is that you realize your society is wrong about something, don’t realize that you can’t outperform it, and wind up even wronger.many such cases",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44878088,
    "by": "biophysboy",
    "timeISO": "2025-08-12T15:59:01.000Z",
    "textPlain": "> “There’s this belief [among rationalists],” she said, “that society has these really bad behaviors, like developing self-improving AI, or that mainstream epistemology is really bad–not just religion, but also normal ‘trust-the-experts’ science. That can lead to the idea that we should figure it out ourselves. And what can show up is that some people aren't actually smart enough to form very good conclusions once they start thinking for themselves.”I see this arrogant attitude all the time on HN: reflexive distrust of the \"mainstream media\" and \"scientific experts\". Critical thinking is a very healthy idea, but its dangerous when people use it as a license to categorically reject sources. Its even worse when extremely powerful people do this; they can reduce an enormous sub-network of thought into a single node for many many people.So, my answer for \"Why Are There So Many Rationalist Cults?\" is the same reason all cults exist: humans like to feel like they're in on the secret. We like to be in secret clubs.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877326,
    "by": "nathan_compton",
    "timeISO": "2025-08-12T15:14:53.000Z",
    "textPlain": "Thinking too hard about anything will drive you insane but I think the real issue here is that rationalists simply over-estimate both the power of rational thought and their ability to do it. If you think of people who tend to make that kind of mistake you can see how you get a lot of crazy groups.I guess I'm a radical skeptic, secular humanist, utilitarianish sort of guy, but I'm not dumb enough to think throwing around the words \"bayesian prior\" and \"posterior distribution\" makes actually figuring out how something works or predicting the outcome of an intervention easy or certain. I've had a lot of life at this point and gotten to some level of mastery at a few things and my main conclusion is that most of the time its just hard to know stuff and that the single most common cognitive mistake people make is too much certainty.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877827,
    "by": "dfabulich",
    "timeISO": "2025-08-12T15:44:53.000Z",
    "textPlain": "The whole game of Rationalism is that you should ignore gut intuitions and cultural norms that you can't justify with rational arguments.Well, it turns out that intuition and long-lived cultural norms often have rational justifications, but individuals may not know what they are, and norms/intuitions provide useful antibodies against narcissist would-be cult leaders.Can you find the \"rational\" justification not to isolate yourself from non-Rationalists, not to live with them in a polycule, and not to take a bunch of psychedelic drugs with them? If you can't solve that puzzle, you're in danger of letting the group take advantage of you.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880205,
    "by": "rogerkirkness",
    "timeISO": "2025-08-12T18:40:38.000Z",
    "textPlain": "Because they have serious emotional maturity issues leading to lobotomizing their normal human emotional side of their identity and experience of life.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877595,
    "by": "alphazard",
    "timeISO": "2025-08-12T15:30:09.000Z",
    "textPlain": "The terminology here is worth noting.  Is a Rationalist Cult a cult that practices Rationalism according to third parties, or is it a cult that says they are Rationalist?Clearly all of these groups that believe in demons or realities dictated by tabletop games are not what third parties would call Rationalist.  They might call themselves that.There are some pretty simple tests that can out these groups as not rational.  None of these people have ever seen a demon, so world models including demons have never predicted any of their sense data.  I doubt these people would be willing to make any bets about when or if a demon will show up.  Many of us would be glad to make a market concerning predictions made by tabletop games about physical phenomenon.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877427,
    "by": "AIPedant",
    "timeISO": "2025-08-12T15:21:09.000Z",
    "textPlain": "I think I found the problem!  The rationalist community was drawn together by AI researcher Eliezer Yudkowsky’s blog post series The Sequences, a set of essays about how to think more rationally\n\nI actually don't mind Yudkowski as an individual - I think he is almost always wrong and undeservedly arrogant, but mostly sincere. Yet treating him as an AI researcher and serious philosopher (as opposed to a sci-fi essayist and self-help writer) is the kind of slippery foundation that less scrupulous people can build cults from. (See also Maharishi Mahesh Yogi and related trends - often it is just a bit of spiritual goofiness as with David Lynch, sometimes you get a Charles Manson.)",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879665,
    "by": "kazinator",
    "timeISO": "2025-08-12T17:51:57.000Z",
    "textPlain": "The only way you can hope to get a gathering of nothing but paragons of critical thinking and skepticism is if the gathering has an entrance exam in critical thinking and skepticism (and a pretty tough one, if they are to be paragons). Or else, it's invitation-only.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877638,
    "by": "wiredfool",
    "timeISO": "2025-08-12T15:32:32.000Z",
    "textPlain": "It's really worth reading up on the techniques from Large Group Awareness Training so that you can recognize them when they pop up.Once you see them listed (social pressure, sleep deprivation, control of drinking/bathroom, control of language/terminology, long exhausting activities, financial buy in, etc) and see where they've been used in cults and other cult adjacent things it's a little bit of a warning signal when you run across them IRL.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880090,
    "by": "jameslk",
    "timeISO": "2025-08-12T18:28:57.000Z",
    "textPlain": "Over rationalizing is paperclip maximizing",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877853,
    "by": "animal_spirits",
    "timeISO": "2025-08-12T15:46:01.000Z",
    "textPlain": "> If someone is in a group that is heading towards dysfunctionality, try to maintain your relationship with them; don’t attack them or make them defend the group. Let them have normal conversations with you.This is such an important skill we should all have. I learned this best from watching the documentary Behind the Curve, about flat earthers, and have applied it to my best friend diving into the Tartarian conspiracy theory.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877732,
    "by": "bubblyworld",
    "timeISO": "2025-08-12T15:38:54.000Z",
    "textPlain": "What is the base rate here? Hard to know the scope of the problem without knowing how many non-rationalists (is that even a coherent group of people?) end up forming weird cults, as a comparison. My impression is that crazy beliefs are common amongst everybody.A much simpler theory is that rationalists are mostly normal people, and normal people tend to form cults.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877446,
    "by": "lenerdenator",
    "timeISO": "2025-08-12T15:22:09.000Z",
    "textPlain": "Because humans like people who promise answers.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877412,
    "by": "cjs_ac",
    "timeISO": "2025-08-12T15:20:07.000Z",
    "textPlain": "Rationalism is the belief that reason is the primary path to knowledge, as opposed to, say, the observation that is championed by empiricism. It's a belief system that prioritises imposing its tenets on reality rather than asking reality what reality's tenets are. From the outset, it's inherently cult-like.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44878853,
    "by": "jancsika",
    "timeISO": "2025-08-12T16:49:22.000Z",
    "textPlain": "> And what can show up is that some people aren't actually smart enough to form very good conclusions once they start thinking for themselves.It's mostly just people who aren't very experienced talking about and dealing honestly with their emotions, no?I mean, suppose someone is busy achieving and, at the same time, proficient in balancing work with emotional life, dealing head-on with interpersonal conflicts, facing change, feeling and acknowledging hurt, knowing their emotional hangups, perhaps seeing a therapist, perhaps even occasionally putting personal needs ahead of career... :)Tell that person they can get a marginal (or even substantial) improvement from some rationalist cult practice. Their first question is going to be, \"What's the catch?\" Because at the very least they'll suspect that adjusting their work/life balance will bring a sizeable amount of stress and consequent decrease in their emotional well-being. And if the pitch is that this rationalist practice works equally well at improving emotional well-being, that smells to them. They already know they didn't logic themselves into their current set of emotional issues, and they are highly unlikely to logic themselves out of them. So there's not much value here to offset the creepy vibes of the pitch. (And again-- being in touch with your emotions means quicker and deeper awareness of creepy vibes!)Now, take a person whose unexplored emotional well-being tacitly depends on achievement. Even a marginal improvement in achievement could bring perceptible positive changes in their holistic selves! And you can step through a well-specified, logical process to achieve change? Sign HN up!",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877351,
    "by": "noqc",
    "timeISO": "2025-08-12T15:16:32.000Z",
    "textPlain": "Perhaps I will get downvoted to death again for saying so, but the obvious answer is because the name \"rationalist\" is structurally indistinguishable from the name \"scientology\" or \"the illuminati\". You attract people who are desperate for an authority to appeal to, but for whatever reason are no longer affiliated with the church of their youth. Even a rationalist movement which held nothing as dogma would attract people seeking dogma, and dogma would form.The article begins by saying the rationalist community was \"drawn together by AI researcher Eliezer Yudkowsky’s blog post series The Sequences\". Obviously the article intends to make the case that this is a cult, but it's already done with the argument at this point.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877258,
    "by": "optimalsolver",
    "timeISO": "2025-08-12T15:10:31.000Z",
    "textPlain": "Pertinent Twitter comment:\"Rationalism is such an insane name for a school of thought. Like calling your ideology correctism or winsargumentism\"https://x.com/growing_daniel/status/1893554844725616666",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879890,
    "by": "1970-01-01",
    "timeISO": "2025-08-12T18:12:04.000Z",
    "textPlain": "I find it ironic that the question is asked unempirically. Where is the data stating there are many more than before? Start there, then go down the rabbit hole. Otherwise, you're concluding on something that may not be true, and trying to rationalize the answer, just as a cultist does.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880131,
    "by": "idontwantthis",
    "timeISO": "2025-08-12T18:32:28.000Z",
    "textPlain": "Does anyone else feel that “rationality” is the same as clinical anxiety?I’m hyper rational when I don’t take my meds. I’m also insane. But all of my thoughts and actions follow a carefully thought out sequence.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44878213,
    "by": "digbybk",
    "timeISO": "2025-08-12T16:07:02.000Z",
    "textPlain": "When I was looking for a group in my area to meditate with, it was tough finding one that didn't appear to be a cult. And yet I think Buddhist meditation is the best tool for personal growth humanity has ever devised. Maybe the proliferation of cults is a sign that Yudkowsky was on to something.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877747,
    "by": "rkapsoro",
    "timeISO": "2025-08-12T15:39:49.000Z",
    "textPlain": "Something like 15 years ago I once went to a Less Wrong/Overcoming Bias meetup in my town after being a reader of Yudkowsky's blog for some years. I was like, Bayesian Conspiracy, cool, right?The group was weird and involved quite a lot of creepy oversharing. I didn't return.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880411,
    "by": "AndrewKemendo",
    "timeISO": "2025-08-12T18:57:21.000Z",
    "textPlain": "I was on LW when it emerged from the OB blog and back then it was a interesting and engaging group, though even then there were like 5 “major” contributors - most of which had no coherent academic or commercial success.As soon as those “sequences” were being developed it was clearly turning into a cult around EY, that I never understood and still don’t.This article did a good job of covering the history since and was really well written.Water finds its own level",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877879,
    "by": "dkarl",
    "timeISO": "2025-08-12T15:47:10.000Z",
    "textPlain": "Isn't this entirely to be expected? The people who dominate groups like these are the ones who put the most time and effort into them, and no sane person who appreciates both the value and the limitations of rational thinking is going to see as much value in a rationalist group, and devote as much time to it, as the kind of people who are attracted to the cultish aspect of achieving truth and power through pure thought. There's way more value there if you're looking to indulge in, or exploit, a cult-like spiral into shared fantasy than if you're just looking to sharpen your logical reasoning.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879573,
    "by": "scythe",
    "timeISO": "2025-08-12T17:43:57.000Z",
    "textPlain": "One of the hallmarks of cults — if not a necessary element — is that they tend to separate their members from the outside society. Rationalism doesn't directly encourage this, but it does facilitate it in a couple of ways:- Idiosyncratic language used to describe ordinary things (\"lightcone\" instead of \"future\", \"prior\" instead of \"belief\" or \"prejudice\", etc)- Disdain for competing belief systems- Insistence on a certain shared interpretation of things most people don't care about (the \"many-worlds interpretation\" of quantum uncertainty, self-improving artificial intelligence, veganism, etc)- I'm pretty sure polyamory makes the list somehow, just because it isn't how the vast majority of people want to date. In principle it's a private lifestyle choice, but it's obviously a community value here.So this creates an opportunity for cult-like dynamics to occur where people adjust themselves according to their interactions within the community but not interactions outside the community. And this could seem — to the members — like the beliefs themselves are the problem, but from a sociological perspective, it might really be the inflexible way they diverge from mainstream society.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44878007,
    "by": "Isamu",
    "timeISO": "2025-08-12T15:53:51.000Z",
    "textPlain": "So I like Steven Pinker’s book Rationality, to me it seems quite straightforward.But I have never been able to get into the Rationalist stuff, to me it’s all very meandering and peripheral and focused on… I don’t know what.Is it just me?",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877277,
    "by": "amiga386",
    "timeISO": "2025-08-12T15:11:26.000Z",
    "textPlain": "See also Rational Magic: Why a Silicon Valley culture that was once obsessed with reason is going woo (2023)https://www.thenewatlantis.com/publications/rational-magicand its discussion on HN: https://news.ycombinator.com/item?id=35961817",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877676,
    "by": "keybored",
    "timeISO": "2025-08-12T15:35:33.000Z",
    "textPlain": "Cue all the surface-level “tribalism/loneliness/hooman nature” comments instead of the simple analysis that Rationalism (this kind) is severely brain-broken and irredeemable and will just foster even worse outcomes in a group setting. It’s a bit too close to home (ideologically) to get a somewhat detached analysis.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877274,
    "by": "thrance",
    "timeISO": "2025-08-12T15:11:12.000Z",
    "textPlain": "Reminds me somewhat of the Culte de la Raison (Cult of Reason) birthed by the french revolution. It didn't last long.https://en.wikipedia.org/wiki/Cult_of_Reason",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877738,
    "by": "zzzeek",
    "timeISO": "2025-08-12T15:39:32.000Z",
    "textPlain": "because humans are biological creatures iterating through complex chemical processes that are attempting to allow a large organism to survive and reproduce within the specific ecosystem provided by the Earth in the present day.    \"Rational reasoning\" is a quaint side effect that sometimes is emergent from the nervous system of these organisms, but it's nothing more than that.   It's normal that the surviving/reproducing organism's emergent side effect of \"rational thought\", when it is particularly intense, will self-refer to the organism and act as though it has some kind of dominion over the organism itself, but this is, like the rationalism itself, just an emergent effect that is accidental and transient.    Same as if you see a cloud that looks like an elephant (it's still just a cloud).",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879911,
    "by": "akomtu",
    "timeISO": "2025-08-12T18:14:00.000Z",
    "textPlain": "It's a religion of an overdeveloped mind that hides from everything it cannot understand. It's an anti-religion, in a sense, that puts your mind on the pedestal.Note the common pattern in major religions: they tell you that thoughts and emotions obscure the light of intuition, like clouds obscure sunlight. Rationalism is the opposite: it denies the very idea of intuition, or anything above the sphere of thoughts, and tells to create as many thoughts as possible.Rationalists deny anything spiritual, good or evil, because they don't have evidence to think otherwise. They remain in this state of neutral nihilism until someone bigger than them sneaks into their ranks and casually introduces them to evil with some undeniable evidence. Their minds quickly pass the denial-anger-acceptance stages and being faithful to their rationalist doctrine they update their beliefs with what they know. From that point they are a cult. That's the story of Scientology, which has too many many parallels with Rationalism.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877434,
    "by": "iwontberude",
    "timeISO": "2025-08-12T15:21:45.000Z",
    "textPlain": "They watched too much eXistenZ",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44878124,
    "by": "the_third_wave",
    "timeISO": "2025-08-12T16:01:04.000Z",
    "textPlain": "Gott ist tot! Gott bleibt tot! Und wir haben ihn getötet! Wie trösten wir uns, die Mörder aller Mörder? Das Heiligste und Mächtigste, was die Welt bisher besaß, es ist unter unseren Messern verblutet.The average teenager who reads Nietzsches proclamation on the death of God thinks of this as an accomplishment, finally we got rid of those thousands of years old and thereby severely outdated ideas and rules. Somewhere along the march to maturity they may start to wonder whether that which has replaced those old rules and ideas were good replacements but most of them never come to the realisation that there were rebellious teenagers during all those centuries when the idea of a supreme being to which or whom even the mightiest were to answer to still held sway. Nietzsche saw the peril in letting go off that cultural safety valve and warned for what might come next.We are currently living in the world he warned us about and for that I, atheist as I am, am partly responsible. The question to be answered here is whether it is possible to regain the benefits of the old order without getting back the obvious excesses, the abuse, the sanctimoniousness and all the other abuses of power and privilege which were responsible for turning people away from that path.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877290,
    "by": "gjsman-1000",
    "timeISO": "2025-08-12T15:12:41.000Z",
    "textPlain": "It’s especially popular in Silicon Valley.Quite possibly, places like Reddit and Hacker News, are training for the required level of intellectual smugness, and certitude that you can dismiss every annoying argument with a logical fallacy.That sounds smug of me, but I’m actually serious. One of their defects, is that once you memorize all the fallacies (“Appeal to authority,” “Ad hominem,”) you can easily reach the point where you more easily recognize the fallacies in everyone else’s arguments than your own. You more easily doubt other people’s cited authorities, than your own. You slap “appeal to authority” against a disliked opinion, while citing an authority next week for your own. It’s a fast path from there to perceived intellectual superiority, and an even faster path from there into delusion. Rational delusion.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44880042,
    "by": "dav_Oz",
    "timeISO": "2025-08-12T18:25:03.000Z",
    "textPlain": "For me largley shaped by the westering old Europe creaking and breaking (after 2 WWs) under its heavy load of philosophical/metaphysical inheritance (which at this point in time can be considered effectively americanized).It is still fascinating to trace back the divergent developments like american-flavoured christian sects or philosophical schools of \"pragmatism\", \"rationalism\" etc. which get super-charged by technological disruptions.In my youth I was heavily influenced by the so-called Bildung which can be functionally thought of as a form of ersatz religion and is maybe better exemplified in the literary tradition of the Bildungsroman.I've grappled with and wildly fantasized about all sorts of things, experimented mindlessly with all kinds of modes of thinking and consciousness amidst my coming-of-age, in hindsight without this particular frame of Bildung left by myself I would have been left utterly confused and maybe at some point acted out on it. By engaging with books like Der Zauberberg by Thomas Mann or Der Mann ohne Eigenschaften by Robert Musil, my apparent madness was calmed down and instead of breaking the dam of a forming social front of myself with the vastness of the unconsciousness, over time I was guided to develop my own way into slowly operating it appropriately without completely blowing myself up into a messiah or finding myself eternally trapped in the futility and hopelessness of existence.Borrowing from my background, one effective vaccination which spontaneously came up in my mind against rationalists sects described here, is Schopenhauer's Die Welt als Wille und Vorstellung which can be read as a radical continuation of Kant's Critique of Pure Reason which was trying to stress test the ratio itself. [To demonstrate the breadth of Bildung in even something like the physical sciences e.g. Einstein was familiar with Kant's a priori framework of space and time, Heisenberg's autobiographical book Der Teil und das Ganze was motivated by: \"I wa",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877478,
    "by": "numbsafari",
    "timeISO": "2025-08-12T15:23:22.000Z",
    "textPlain": "Why are so many cults founded on fear or hate?Because empathy is hard.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877253,
    "by": "api",
    "timeISO": "2025-08-12T15:10:03.000Z",
    "textPlain": "Why are there so many cults? People want to feel like they belong to something, and in a world in the midst of a loneliness and isolation epidemic the market conditions are ideal for cults.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877395,
    "by": "throwaway984393",
    "timeISO": "2025-08-12T15:18:54.000Z",
    "textPlain": "[dead]",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877333,
    "by": "righthand",
    "timeISO": "2025-08-12T15:15:27.000Z",
    "textPlain": "[flagged]",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44879991,
    "by": "SpaceManNabs",
    "timeISO": "2025-08-12T18:21:24.000Z",
    "textPlain": "Cause they all read gwern and all eugenics leads into cults because conspiracy adjacent garbo always does.",
    "parent": 44877076,
    "depth": 1
  },
  {
    "id": 44877347,
    "by": "incomingpain",
    "timeISO": "2025-08-12T15:16:15.000Z",
    "textPlain": "We live in an irrational time. It's unclear if it was simply under reported in history or social changes in the last ~50-75 years have had breaking consequences.People are trying to make sense of this. For examples.The Canadian government heavily subsidizes junk food, then spends heavily on healthcare because of the resulting illnesses. It restrict and limits healthy food through supply management and promotes a “food pyramid” favoring domestic unhealthy food. Meanwhile, it spends billions marketing healthy living, yet fines people up to $25,000 for hiking in forests and zones cities so driving is nearly mandatory.Government is an easy target for irrational behaviours.",
    "parent": 44877076,
    "depth": 1
  }
]