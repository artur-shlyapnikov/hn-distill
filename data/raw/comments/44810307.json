[
  {
    "id": 44811400,
    "by": "djoldman",
    "timeISO": "2025-08-06T13:02:47.000Z",
    "textPlain": "> Bob needs a new computer for his job.... In order to obtain a new work computer he has to create a 4 paragraph business case explaining why the new computer will improve his productivity.> Bob’s manager receives 4 paragraphs of dense prose and realises from the first line that he’s going to have to read the whole thing carefully to work out what he’s being asked for and why. Instead, he copies the email into the LLM.... The 4 paragraphs are summarised as “The sender needs a new computer as his current one is old and slow and makes him unproductive.” The manager approves the request.\"LLM inflation\" as a \"bad\" thing often reflects a \"bad\" system.In the case described, the bad system is the expectation that one has to write, or is more likely to obtain a favorable result from writing, a 4 paragraph business case. Since Bob inflates his words to fill 4 paragraphs and the manager deflates them to summarise, it's clear that the 4 paragraph expectation/incentive is the \"bad\" thing here.This phenomenon of assigning the cause of \"bad\" things to LLMs is pretty rife.In fact, one could say that the LLM is optimizing given the system requirement: it's a lot easier to get around this bad framework.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44812692,
    "by": "verbify",
    "timeISO": "2025-08-06T14:42:55.000Z",
    "textPlain": "Engaging with why we might actually want inflation of text:1) For pedagogical or explanatory purposes. For example, if I were to write:> ∀x∈R,x^2≥0I've used 10 characters to say> For every real number x, it's square is greater than or equal to zeroFor a mathematician, the first is sufficient. For someone learning, the second might be better (and perhaps as expansion of 'real number' or that 'square' is 'multiplying it by itself').2) To make sure everything is stated and explicit. \"He finally did x\" implies that something has been anticipated/worked on for awhile, but \"after a period of anticipation he did x\" makes it more clear. This also raises the question of who was anticipating, which could be made explicit too.As someone who spends a lot of time converting specifications to code (and explaining technical problems to non-technical people), unstated assumptions are very prevalent. And then sometimes people have different conceptions of the unstated assumption (i.e. some people might think that nobody was anticipating, it just took longer than you'd expect otherwise).So longer text might seem like a simple expansion, but then it ends up adding detail.I definitely agree with the authors point, I just want to argue that having a text-expander tool isn't quite as useless as 'generate garbage for me'.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811248,
    "by": "danielbln",
    "timeISO": "2025-08-06T12:46:06.000Z",
    "textPlain": "This image originally came out just around the time of ChatGPT release and captures it well: https://i.imgur.com/RHGD9Tk.png",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44812058,
    "by": "nathan_compton",
    "timeISO": "2025-08-06T13:52:31.000Z",
    "textPlain": "The older I get the more concise I find myself (which is not to say I'm actually concise, as my comment history will demonstrate), but LLM's have really driven home just how much noise day to day communication involves. So much filler text.It still surprises me when I see non-technical enthusiasts get excited about LLMs drafting almost useless copy or email or whatever. So much garbage text no one reads but has to be written for some reason. Its weird.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44810802,
    "by": "unglaublich",
    "timeISO": "2025-08-06T11:57:01.000Z",
    "textPlain": "An LLM is effectively a compressed model of its input data.Inference is then the decompression stage where it generates text from the input prompt and the compressed model.Now that compressing and decompressing texts is trivial with LLMs, we humans should focus - in business at least - on communicating only the core of what we want to say.If the argument to get a new keyboard is: \"i like it\", then this should suffice, for inflated versions of this argument can be trivially generated.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44814591,
    "by": "ruuda",
    "timeISO": "2025-08-06T16:57:15.000Z",
    "textPlain": "I consider inflation a double insult. (https://ruudvanasseldonk.com/2025/llm-interactions) It says \"I couldn't be bothered to spend time writing this myself, but I'm expecting you to read all the fluff.\"",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44814069,
    "by": "numpad0",
    "timeISO": "2025-08-06T16:18:48.000Z",
    "textPlain": "> That we are using LLMs for inflation should not be taken as a criticism of these wonderful tools. It might, however, make us consider why we find ourselves inflating content. At best we’re implicitly rewarding obfuscation and time wasting; at worst we’re allowing a lack of clear thinking to be covered up. I think we’ve all known this to be true, but LLMs allow us to see the full extent of this with our own eyes. Perhaps it will encourage us to change!Yeah, this is the problem. Wealth distribution stopped working sometime in the late 20th century and we're fighting each others for competitive advantages. That's the core of this phenomenon.No one needs containers full of baby sized left shoes, but proof of work must be shown. So the leathers must be cut and shoes must be sewn, only to be left in the ever growing pile in the backyard. That's kind of wrong.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44814535,
    "by": "nlawalker",
    "timeISO": "2025-08-06T16:53:12.000Z",
    "textPlain": "Long documents in business contexts that get summarized and go mostly unread are the byproduct of a specific and common level of trust and accountability in those contexts: people don't believe someone has done enough critical thinking or has a strong enough justification for a proposal unless they've put it on the page, but if it is on the page, it's assumed that it does in fact represent critical thinking and legitimate justification.If trust was higher, shorter documents would be more desirable. If trust was lower, or accountability higher, summarization would be used a lot more carefully.LLMs haven't changed anything in this regard except that they've made it extremely easy to abuse trust at that specific level. The long-term result will be that trust will fall in the general case, and people will eventually become more careful about using summarization. I don't think it will be long before productized AI used in business contexts will be pretrained/fine-tuned to perform a basic level of AI content detection or include a qualitative measure of information density by default when performing summarization.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44812797,
    "by": "sdenton4",
    "timeISO": "2025-08-06T14:49:40.000Z",
    "textPlain": "Huh, this post is not what I thought it would be! Even after the first two paragraphs!There's a line of thought which states that intelligence rhymes with compression: Identifying patterns allows better prediction, enables better compression of the data.However, internally, LLMs typically do the opposite: Tokenization and vectorization multiply the bit rate of the input signal. Chain of thought techniques add a lot of extra text, further increasing the bit rate.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811011,
    "by": "roxolotl",
    "timeISO": "2025-08-06T12:21:40.000Z",
    "textPlain": "My PM said they’d written a bunch of tickets for a project yesterday morning that we hadn’t fully scoped yet. I was pleasantly surprised because I can’t complain if they are going to get ahead of things and start scaffolding tickets.Of course when I went to read them they were 100% slop. The funniest requirement were progress bars for actions that don’t have progress. The tickets were, even if you assume the requirements weren’t slop, at least 15 points a piece.But ok maybe with all of these new tools we can respond by implementing these insane requirements. The real problem is what this article is discussing. Each ticket was also 500-700 words. Requirements that boil down to a single if statement were described in prose. While this is hilarious the problem is it makes them harder to understand.I tried to explain this and they just said “ok fine rewrite them then”. Which I did in maybe 15min because there wasn’t actually much to write.At this point I’m at a loss for how to even work with people that are so convinced these things will save time because they look at the volume of the output.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811108,
    "by": "santiagobasulto",
    "timeISO": "2025-08-06T12:31:54.000Z",
    "textPlain": "> the load on my server is reducedisn't this the opposite? Enabling compression will INCREASE the load on your server as you need more CPU to compress/decompress the data.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44816478,
    "by": "amdivia",
    "timeISO": "2025-08-06T19:23:22.000Z",
    "textPlain": "I think the usage of LLMs will push for a societal change in how we communicate.instead of elongated sentences, we perhaps might start seeing an increase in just communicating through the minimum constructing points of whatever meaning we hope to convey, leaving the presentation work for the LLM on the receiving side",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44813042,
    "by": "jnmandal",
    "timeISO": "2025-08-06T15:08:08.000Z",
    "textPlain": "LLM Inflation is an interesting choice of terminology. Like with many things in our contemporary society there is a temptation to assign absolute, quantitative value to everyday concepts but realistically we should know this to be a fallacy. Many concepts actually have no \"on paper\" value but still manifest significant social value. Marketing is the typical example, and yet we don't refer to advertising as inflation (though maybe we should).This concept probably applies to lots of work in the \"AI\" space right now. The idea of using huge amounts of compute to generate lifelike voices for LLMs comes to mind as being recently maligned (something many users may not want). Or people upset about getting AI summaries in search that they didn't ask for. And yet, swaths of capital has been invested in these ideas and perhaps its a worthwhile use of resources. I am not sure personally. Time will tell. But I suspect its more complicated than the author is implying here.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811269,
    "by": "amelius",
    "timeISO": "2025-08-06T12:48:47.000Z",
    "textPlain": "Perhaps we should judge the performance of an LLM by how well it can compress arbitrary information. A higher IQ would mean more compression, after all.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811030,
    "by": "dspillett",
    "timeISO": "2025-08-06T12:23:45.000Z",
    "textPlain": "This type of verbiage inflation was happening in business all the time anyway. LLMs are just being used as a method for doing it faster.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811435,
    "by": "jdoliner",
    "timeISO": "2025-08-06T13:06:08.000Z",
    "textPlain": "I saw an interesting argument recently that the reason you get this type of verbose language in corporate settings is that English lacks a formal tense. Apparently it's much less common in languages that have one. But in corporate English the verbosity is used as a signal that you took time to produce the text out of respect for the person you're communicating with.This of course now gets weird with LLMs because I doubt it can last as a signal of respect for very long when it just means you fed some bullet points to ChatGPT.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811117,
    "by": "PeterStuer",
    "timeISO": "2025-08-06T12:32:26.000Z",
    "textPlain": "I call BS.The 4 paragraphs requirement was not introduced 'because LLM'. It was there all along for what just should have been 'gimme 2 -3 bullet points'. They wanted Bob to hold back on requesting the new machine he needed, not by denying his request openly, but by making the process convoluted. Now Bob can cut through the BS, they want to blame the LMM for wasting their time and resources? BS!",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44810750,
    "by": "jasode",
    "timeISO": "2025-08-06T11:50:33.000Z",
    "textPlain": ">Creating the necessary prose is torturous for most of us, so Bob fires up the LLM du jour, types in “Please create a 4 paragraph long business case for my manager, explaining why I need to replace my old, slow computer” and copies the result into his email.>Bob’s manager receives 4 paragraphs of dense prose and realises from the first line that he’s going to have to read the whole thing carefully to work out what he’s being asked for and why. Instead, he copies the email into the LLM du jour and types at the start “Please summarise this email for me in one sentence”. The 4 paragraphs are summarised as “The sender needs a new computer as his current one is old and slow and makes him unproductive.”Sam Altman actually had a concise tweet about this blog's topic (https://x.com/sama/status/1631394688384270336)>something very strange about people writing bullet points, having ChatGPT expand it to a polite email, sending it, and the sender using ChatGPT to condense it into the key bullet points  2:42 PM · Mar 2, 2023  · 1.2M  Views",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44815035,
    "by": "g9yuayon",
    "timeISO": "2025-08-06T17:31:19.000Z",
    "textPlain": "The example in the article does not look like LLM Inflation, but that LLM can't reduce the waste in a bureaucratic process.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811193,
    "by": "thimabi",
    "timeISO": "2025-08-06T12:40:41.000Z",
    "textPlain": "One of the things that makes me hopeful for the future of LLMs is precisely this: humans are needlessly verbose, and LLMs can cut through the crap.I expect smaller models to become incrementally better at compressing what truly matters in terms of information. Books, reports, blog posts… all kinds of long-form content can be synthesized in just a few words or pages. It’s no wonder that even small LLMs can provide accurate results for many queries.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44813619,
    "by": "geor9e",
    "timeISO": "2025-08-06T15:50:15.000Z",
    "textPlain": "Why choose the word \"inflation\" to mean the opposite of compression? If you said it to a stranger, they'd assume you mean the price of LLMs is going up due to scarcity. I would call this LLM fluffing or LLM decompression",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44815332,
    "by": "codr7",
    "timeISO": "2025-08-06T17:52:49.000Z",
    "textPlain": "I've seen this happen IRL.My former (obviously) wannabe manager used GAI to pimp our CV's before sending out to clients, pretty sure they too consulted stupid to summarize on their end.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44815137,
    "by": "itaysk",
    "timeISO": "2025-08-06T17:38:44.000Z",
    "textPlain": "https://x.com/itaysk/status/1887942925042033069",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811437,
    "by": "tossandthrow",
    "timeISO": "2025-08-06T13:06:13.000Z",
    "textPlain": "Where I work, I do the opposite: I let my colleagues know that they should write much mess and much more concise.I actually straight up reject it when text is too inflated, and I remind people that LLMs are available to expand on request.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44820337,
    "by": "kazinator",
    "timeISO": "2025-08-07T03:37:43.000Z",
    "textPlain": "We've also had XML inflation for 30 years.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44814357,
    "by": "larodi",
    "timeISO": "2025-08-06T16:40:09.000Z",
    "textPlain": "Good point to better use it for haikus. Not sure if it that good at it though.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811267,
    "by": "zacksiri",
    "timeISO": "2025-08-06T12:48:40.000Z",
    "textPlain": "The problem described in this post has nothing to do with LLMs. It has everything to do with work culture and bureaucracy. Rules and laws that don't make sense remain because changing it requires time, energy and effort that most people in companies have either tried and failed or don't care enough to make a change.This is one example of the \"horseless carriage\" AI solutions. I've begun questioning further that actually we're going into a generation where a lot of the things we are doing now are not even necessary.I'll give you one more example. The whole \"Office\" stack of [\"Word\", \"Excel\", \"Powerpoint\"] can also go away. But we still use it because change is hard.Answer me this question. In the near future if we could have LLMs that can traverse to massive amount of data why do we need to make excel sheets anymore? Will we as a society continue to make excel spreadsheets because we want the insights the sheet provides or do we make excel sheets to make excel sheets.The current generation of LLM products I find are horseless carriages. Why would you need agents to make spreadsheets when you should just be able to ask the agent to give you answers you are looking for from the spreadsheet.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811508,
    "by": "boxed",
    "timeISO": "2025-08-06T13:12:12.000Z",
    "textPlain": "> Brevity is the soul of witNow that pachinko machines can create lots of prose, maybe it's time to finally learn this lesson.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811438,
    "by": "BobbyTables2",
    "timeISO": "2025-08-06T13:06:17.000Z",
    "textPlain": "Bob is highly optimistic!",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44814509,
    "by": "TOGoS",
    "timeISO": "2025-08-06T16:51:00.000Z",
    "textPlain": "> At best we’re implicitly rewarding obfuscation and time wasting; at worst we’re allowing a lack of clear thinking to be covered up.Most people don't think very clearly.  That's why rhetoric is effective.  That's why most communication is fluffy social signaling.  You can give people great advice and their eyes glaze over because the words didn't fill them with emotion, or something, and they do the exact opposite.No wonder LLMs get put to work playing that stupid game.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44810957,
    "by": "watwut",
    "timeISO": "2025-08-06T12:15:30.000Z",
    "textPlain": "> Bob needs a new computer for his job. In order to obtain a new work computer he has to create a 4 paragraph business case explaining why the new computer will improve his productivity.Is this situation in any way realistic one? Because the way companies work in my beck of woods, no one wants your 4 paragraph business case essay about computer. Like, it is funny anecdote.But, in real world, at least in my experience, pretty much everyone preferred short for emails and messages. They would skim the long ones at best, especially in situation that can be boiled down to \"Tom wants a new computer and is verbose about it\".",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44811711,
    "by": "OsrsNeedsf2P",
    "timeISO": "2025-08-06T13:27:56.000Z",
    "textPlain": "The author made up a fake situation to drive a point that doesn't exist",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44810806,
    "by": "stocksinsmocks",
    "timeISO": "2025-08-06T11:57:27.000Z",
    "textPlain": "> One of the signal achievements of computing is data compressionAh, yes. It is an achievement in signals in a way.",
    "parent": 44810307,
    "depth": 1
  },
  {
    "id": 44821912,
    "by": "nicbou",
    "timeISO": "2025-08-07T08:11:40.000Z",
    "textPlain": "I write guides for a living, and my audience is largely comprised of non-native speakers. I write simply and unambiguously, and I've been told multiple times that my style seeps through my blog posts, my comments and my text messages.You are so right! LLMs produce so much noise. If you ask them to be concise, they struggle to cut just the fat, and the output is often vague or misleading. I see that again and again when I ask it to produce different versions of a sentence.I imagine it's how artists feel about AI art. It seems right at first glance, but you can tell that no thought or craftsmanship went into it.",
    "parent": 44812058,
    "depth": 2
  },
  {
    "id": 44812721,
    "by": "integralid",
    "timeISO": "2025-08-06T14:44:28.000Z",
    "textPlain": "\"I wrote this mail slightly longer because I didn't have time to make it short\" - someone famousWhen writing something I want people to read, I always take time at the end to make it shorter - remove distracting sentences, unnecessary adjectives and other noise. Really works wonders for team communication.",
    "parent": 44812058,
    "depth": 2
  },
  {
    "id": 44819131,
    "by": "Gigachad",
    "timeISO": "2025-08-06T23:42:35.000Z",
    "textPlain": "On one side you have people using LLMs to fluff a sentence in to an essay. And on the receiver side they are hitting a button to AI summarise it back to a sentence.What incredible technology.",
    "parent": 44812058,
    "depth": 2
  },
  {
    "id": 44810990,
    "by": "AIPedant",
    "timeISO": "2025-08-06T12:19:35.000Z",
    "textPlain": "What I hate about this is that often a novel and interesting idea truly needs extra space to define and illustrate itself, and by virtue of its novelty LLMs will have substantially more difficulty summarizing it correctly. But it sounds like we are heading to a medium-term where people cynically assume any long email must be LLM-generated fluff, and hence nothing is lost by asking for an LLM summary.What a horrible technology.",
    "parent": 44810802,
    "depth": 2
  },
  {
    "id": 44811074,
    "by": "onlyrealcuzzo",
    "timeISO": "2025-08-06T12:27:45.000Z",
    "textPlain": "> If the argument to get a new keyboard is: \"i like it\", then this should sufficeThis seems like exactly what LLMs are supposed to be good at, according to you, so why don't they just near-losslessly compress the data first, and then train on that?Also, if they're so good at this, then why are their answers often long-winded and require so much skimming to get what I want?I'm skeptical LLMs are accurately described as \"near lossless de/compression engines\".If you change the temperature settings, they can get quite creative.They are their algorithm, run on their inputs, which can be roughly described as a form of compression, but it's unlike the main forms of compression we think of - and it at least appears to have emergent decompression properties we aren't used to.If you up the lossy-ness on a JPEG, you don't really end up with creative outputs. Maybe you do by coincidence, and maybe you only do with LLMs - but at much higher rates.Whatever is happening does not seem to be what I think people typically associate with simple de/compression.Theoretically, you can train an LLM on all of Physics, except a few things, and it could discover the missing pieces through reasoning.Yeah, maybe a JPEG could, too, but the odds of that seem astronomically lower.",
    "parent": 44810802,
    "depth": 2
  },
  {
    "id": 44810905,
    "by": "tomrod",
    "timeISO": "2025-08-06T12:10:30.000Z",
    "textPlain": "The inverse of this is \"AI Loopidity\" where we burn cycles inflating then deflating information (in emails, say, or in AI code that blows up then gets reduced or summarized). This often also leads to weird comms outcomes, like saving a jpg at 85% a dozen times.",
    "parent": 44810802,
    "depth": 2
  },
  {
    "id": 44811115,
    "by": "1980phipsi",
    "timeISO": "2025-08-06T12:32:16.000Z",
    "textPlain": "Be more trivial",
    "parent": 44810802,
    "depth": 2
  }
]