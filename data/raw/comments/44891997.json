[
  {
    "id": 44892409,
    "by": "kevinventullo",
    "timeISO": "2025-08-13T19:00:23.000Z",
    "textPlain": "Is anyone else getting tired of these articles?“Area man who had poor judgement ten years ago now has both poor judgement and access to chatbots”",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892485,
    "by": "pryelluw",
    "timeISO": "2025-08-13T19:06:33.000Z",
    "textPlain": "These AIs are taking away the jobs of psychics and other snake oil peddlers. How will the median person get their confirmation bias serviced when the AI becomes too expensive?",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892265,
    "by": "slicktux",
    "timeISO": "2025-08-13T18:48:24.000Z",
    "textPlain": "Does that title seem like a cluster to anyone else? I tried rewording it in my head but only came up with a slightly better solution: \n“Man develops rare condition after cutting consumption of salt do to a ChatGPT query”.",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892320,
    "by": "throwmeaway222",
    "timeISO": "2025-08-13T18:52:17.000Z",
    "textPlain": "You're absolutely right! If you stop eating salt you will become god!",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892509,
    "by": "gdbsjjdn",
    "timeISO": "2025-08-13T19:08:32.000Z",
    "textPlain": "The industry is really trying to make \"the computer cannot be held responsible\" a feature instead of a bug.Sure the machine very confidently lies about dangerous things, but you shouldn't trust it. But you should employ it to replace humans.",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892400,
    "by": "zahlman",
    "timeISO": "2025-08-13T18:59:36.000Z",
    "textPlain": "https://archive.is/6x39K",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892220,
    "by": "MarkusQ",
    "timeISO": "2025-08-13T18:44:22.000Z",
    "textPlain": "LLMs don't think.  At all.  They do next token prediction.If they are conditioned on a large data set that includes lots of examples of the result of people thinking, what they produce will look sort of like the results of thinking, but then if they were conditioned on a large data set of people repeating the same seven knock knock jokes over and over and over in some complex pattern (e.g. every third time, in French), what they produced will look like that, and nothing like thinking.Failing to recognize this is going to get someone killed, if it hasn't already.",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892430,
    "by": "unyttigfjelltol",
    "timeISO": "2025-08-13T19:02:10.000Z",
    "textPlain": "The US medical system practically requires patients to steer their care among specialists. If the gentleman steered himself to a liver doctor, he’d hear liver advice. Psychologist, he’d talk about his feelings. Can one really blame him for taking it one step further and investigating whatever he was worried about on his own too?Plus, if you don’t have some completely obvious dread disease, doctors will essentially gaslight you.These researchers get up on a pedestal, snicker at creative self-help, and ignore the systemic dysfunction that led to it.",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892120,
    "by": "some_random",
    "timeISO": "2025-08-13T18:34:34.000Z",
    "textPlain": "Is it just me or is the title kinda unclear?>The patient told doctors that after reading about the negative effects of sodium chloride, or table salt, he consulted ChatGPT about eliminating chloride from his diet and started taking sodium bromide over a three-month period. This was despite reading that “chloride can be swapped with bromide, though likely for other purposes, such as cleaning”. Sodium bromide was used as a sedative in the early 20th century.In any case, I feel like I really need to see the actual conversation itself to judge how badly chatgpt messed up, if there's no extra context assuming that the user is talking about cleaning doesn't seem _that_ unreasonable.",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892132,
    "by": "bell-cot",
    "timeISO": "2025-08-13T18:35:09.000Z",
    "textPlain": "Same news, Ars Technica, 5 comments, 5 days ago:  https://news.ycombinator.com/item?id=44829824",
    "parent": 44891997,
    "depth": 1
  },
  {
    "id": 44892465,
    "by": "MangoToupe",
    "timeISO": "2025-08-13T19:05:14.000Z",
    "textPlain": "It would be a little less tiring if we were to prosecute the folks responsible.",
    "parent": 44892409,
    "depth": 2
  },
  {
    "id": 44892330,
    "by": "jleyank",
    "timeISO": "2025-08-13T18:53:23.000Z",
    "textPlain": "How about “man gets bromine poisoning after taking ChatGPT medical advice”?",
    "parent": 44892265,
    "depth": 2
  },
  {
    "id": 44892339,
    "by": "neom",
    "timeISO": "2025-08-13T18:54:08.000Z",
    "textPlain": "It's clunky but I understood it immediately, I presumed from the title that it was going to be about your title, however I also thought it was a bit clunky.",
    "parent": 44892265,
    "depth": 2
  },
  {
    "id": 44892434,
    "by": "dfee",
    "timeISO": "2025-08-13T19:02:28.000Z",
    "textPlain": "still haven't clicked in, but was confused.still am, unless i re-interpret \"do\" as \"due\".",
    "parent": 44892265,
    "depth": 2
  },
  {
    "id": 44892369,
    "by": "genter",
    "timeISO": "2025-08-13T18:56:51.000Z",
    "textPlain": "I read it as \"race condition\". I was then trying to figure out what salt has to do with a race condition.",
    "parent": 44892265,
    "depth": 2
  },
  {
    "id": 44892374,
    "by": "neom",
    "timeISO": "2025-08-13T18:57:16.000Z",
    "textPlain": "You're absolutely right! I was locked in with GPT5 last night and I actually discovered that salt is a geometric fractal containing a key insight that can be used by physicists everywhere to solve math. Don't worry, I've emailed everyone I can find about it.",
    "parent": 44892320,
    "depth": 2
  },
  {
    "id": 44892398,
    "by": "foobarian",
    "timeISO": "2025-08-13T18:58:58.000Z",
    "textPlain": "Why do you say that?",
    "parent": 44892320,
    "depth": 2
  },
  {
    "id": 44892436,
    "by": "cortic",
    "timeISO": "2025-08-13T19:02:41.000Z",
    "textPlain": "I'm not sure humans are any different;Humans don't think. At all. They do next token prediction.If they are [raised in environments] that includes lots of examples of the result of people thinking, what they produce will look sort of like the results of people thinking, but then if they were [raised in an environment] of people repeating the same seven knock knock jokes over and over and over in some complex pattern (e.g. every third time, in French), what they produced will look like that, and nothing like thinking.I believe this can be observed in examples of feral children and accidental social isolation in childhood.  It also explains the slow start but nearly exponential growth of knowledge within the history of human civilization.",
    "parent": 44892220,
    "depth": 2
  },
  {
    "id": 44892375,
    "by": "uh_uh",
    "timeISO": "2025-08-13T18:57:21.000Z",
    "textPlain": "> LLMs don't think. At all.How can you so confidently proclaim that? Hinton and Ilya Sutskever certainly seem to think that LLMs do think. I'm not saying that you should accept what they say blindly due to their authority in the field, but their opinions should give your confidence some pause at least.",
    "parent": 44892220,
    "depth": 2
  },
  {
    "id": 44892333,
    "by": "hcdx6",
    "timeISO": "2025-08-13T18:53:40.000Z",
    "textPlain": "Are you thinking over every character you type? You are conditioned too by all the info flowing into your head from birth. Does that gauruntee everything your brain says and does is perfect?People believed in non existent WMDs and tens of thousands got killed. After that what happened ? Chimps with 3 inch brains feel super confident to run orgs and make decisions that effect entire populations and are never held accountable. Ask Snowden what happened after he recognized that.",
    "parent": 44892220,
    "depth": 2
  },
  {
    "id": 44892598,
    "by": "henearkr",
    "timeISO": "2025-08-13T19:15:42.000Z",
    "textPlain": "A weights tensor is very similar to a truth table or a LUT in a FPGA, it's just a generalization of it with real numbers instead of booleans.And then again, would you say that you cannot build a (presumably extremely complex) machine that thinks?Do you think our brains are not complex biological machines?Where I agree is that LLMs are absolutely not the endgame. They are super-human litterary prodiges. That's it. Litterary specialists, like poets, writers, scenarists, transcriptors, and so on. We should not ask them anything else.",
    "parent": 44892220,
    "depth": 2
  },
  {
    "id": 44892238,
    "by": "nimbius",
    "timeISO": "2025-08-13T18:45:52.000Z",
    "textPlain": "yeah sure, but, did it enrich the shareholders?",
    "parent": 44892220,
    "depth": 2
  },
  {
    "id": 44892168,
    "by": "Flozzin",
    "timeISO": "2025-08-13T18:38:13.000Z",
    "textPlain": "The article digs a little deeper after. Saying the chat records are lost, and that when they asked ChatGPT, it didn't give that guidance about cleaning purposely only, and that it never asked why they wanted to know.Really though, this could have just as easily happened in a google search. It's not ChatGPT's fault as much as this persons fault for using a non-medical professional for medical guidance.",
    "parent": 44892120,
    "depth": 2
  },
  {
    "id": 44892392,
    "by": "zahlman",
    "timeISO": "2025-08-13T18:58:21.000Z",
    "textPlain": "Wow. I thought this was just going to be about hyponatremia or something. (And from other research I've done, I really do think that on balance the US experts are recommending inappropriately low levels of sodium intake that are only appropriate for people who already have hypertension, and that typical North American dietary levels of sodium are just fine, really.) But replacing table salt with sodium bromide? Oof.> to judge how badly chatgpt messed up, if there's no extra context assuming that the user is talking about cleaning doesn't seem _that_ unreasonable.This would be a bizarre assumption for the simple reason that table salt is not normally used in cleaning.",
    "parent": 44892120,
    "depth": 2
  },
  {
    "id": 44892177,
    "by": "OJFord",
    "timeISO": "2025-08-13T18:39:18.000Z",
    "textPlain": "Yeah I thought it was a bit misleading too, it's not exactly 'stopping salt' that caused it, any more than you could describe the ill-effects of swapping nasturtiums for lily of the valley in your salads as 'avoiding edible flowers'.",
    "parent": 44892120,
    "depth": 2
  },
  {
    "id": 44892335,
    "by": "topaz0",
    "timeISO": "2025-08-13T18:53:53.000Z",
    "textPlain": "I'd say that the thing that messed up was the AI hype machine for pretending it might ever be a good idea to take chatgpt output as advice.",
    "parent": 44892120,
    "depth": 2
  },
  {
    "id": 44892337,
    "by": "emorning3",
    "timeISO": "2025-08-13T18:54:05.000Z",
    "textPlain": "[dead]",
    "parent": 44892120,
    "depth": 2
  },
  {
    "id": 44892182,
    "by": "HelloUsername",
    "timeISO": "2025-08-13T18:39:33.000Z",
    "textPlain": "Also today https://news.ycombinator.com/item?id=44887459",
    "parent": 44892132,
    "depth": 2
  }
]