[
  {
    "id": 44853504,
    "by": "donperignon",
    "timeISO": "2025-08-10T07:42:19.000Z",
    "textPlain": "LLM’s are basically glorified slot machines. Some people try very hard to come up with techniques or theories about when the slot machine is hot, it’s only an illusion, let me tell you, it’s random and arbitrary, maybe today is your lucky day maybe not. Same with AI, learning the “skill” is as difficult as learning how to google or how to check stackoverflow, trivial. All the rest is luck and how many coins do you have in your pocket.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44849147,
    "by": "tptacek",
    "timeISO": "2025-08-09T19:01:59.000Z",
    "textPlain": "Learning how to use LLMs in a coding workflow is trivial. There is no learning curve. You can safely ignore them if they don’t fit your workflows at the moment.I have never heard anybody successfully using LLMs say this before. Most of what I've learned from talking to people about their workflows is counterintuitive and subtle.It's a really weird way to open up an article concluding that LLMs make one a worse programmer: \"I definitely know how to use this tool optimally, and I conclude the tool sucks\". Ok then. Also: the piano is a terrible, awful instrument; what a racket it makes.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44853823,
    "by": "itsalotoffun",
    "timeISO": "2025-08-10T08:56:40.000Z",
    "textPlain": "I think we're still in the gray zone of the \"Incessant Obsolescence Postulate\" (the Wait Calculation). Are you better off \"skilling up\" on the tech as it is today, or waiting for it to just \"get better\" so by the time you kick off, you benefit from the solved-problems X years from now. I also think this calculation differs by domain, skill level, and your \"soft skill\" abilities to communicate, explain and teach. In some domains, if you're not already on this train, you won't even get hired anymore.The current state of LLM-driven development is already several steps down the path of an end-game where the overwhelming majority of code is written by the machine; our entire HCI for \"building\" is going to be so far different to how we do it now that we'll look back at the \"hand-rolling code era\" in a similar way to how we view programming by punch-cards today. The failure modes, the \"but it SUCKS for my domain\", the \"it's a slot machine\" etc etc are not-even-wrong. They're intermediate states except where they're not.The exceptions to this end-game will be legion and exist only to prove the end-game rule.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44853846,
    "by": "hiAndrewQuinn",
    "timeISO": "2025-08-10T09:03:15.000Z",
    "textPlain": ">I made a CLI logs viewers and querier for my job, which is very useful but would have taken me a few days to write (~3k LoC)I recall The Mythical Man-Month stating a rough calculation that the average software developer writes about 10 net lines of new, production-ready code per day. For a tool like this going up an order of magnitude to about 100 lines of pretty good internal tooling seems reasonable.OP sounds a few cuts above the 'average' software developer in terms of skill level. But here we also need to point out a CLI log viewer and querier is not the kind of thing you actually needed to be a top tier developer to crank out even in the pre-LLM era, unless you were going for lnav [1] levels of polish.[1]: https://lnav.org/",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44853870,
    "by": "eric-burel",
    "timeISO": "2025-08-10T09:11:45.000Z",
    "textPlain": "Good read. I just want to pinpoint that LLMs seems to write better React code, but as an experienced frontend developers my opinion is that it's also bad at React. Its approach is outdated as it doesn't follow the latest guidelines. It writes React as I would have written it in 2020. So as usual, you need to feed the right context to get proper results.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44853604,
    "by": "jamboca",
    "timeISO": "2025-08-10T08:06:29.000Z",
    "textPlain": "Have built many pipelines integrating LLMs to drive real $ results. I think this article boils it down too simply. But i always remember, if the LLM is the most interesting part of your work, something is severely wrong and you probably aren’t adding much value. Context management based on some aspects of your input is where LLMs get good, but you need to do lots of experimentation to tune something. Most cases i have seen are about developing one pipeline to fit 100s of extremely different cases; LLM does not solve this problem but basically serves as an approximator for you to discretize previously large problems in to some information sub space where you can treat the infinite set of inputs as something you know. LLMs are like a lasso (and a better/worse one than traditional lassos depending on use case) but once you get your catch you still need to process it, deal with it progammatically to solve some greater problem. I hate how so many LLM related articles/comments say “ai is useless throw it away dont use it” or “ai is the future if we dont do it now we’re doomed lets integrate it everywhere it can solve all our problems” like can anyone pick a happy medium? Maybe thats what being in a bubble looks like",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44848846,
    "by": "ebiester",
    "timeISO": "2025-08-09T18:25:28.000Z",
    "textPlain": "I disagree from almost the first sentence:> Learning how to use LLMs in a coding workflow is trivial. There is no learning curve. You can safely ignore them if they don’t fit your workflows at the moment.Learning how to use LLMs in a coding workflow is trivial to start, but you find you get a bad taste early if you don't learn how to adapt both your workflow and its workflow. It is easy to get a trivially good result and then be disappointed in the followup. It is easy to try to start on something it's not good at and think it's worthless.The pure dismissal of cursor, for example, means that the author didn't learn how to work with it. Now, it's certainly limited and some people just prefer Claude code. I'm not saying that's unfair. However, it requires a process adaptation.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44849341,
    "by": "simonw",
    "timeISO": "2025-08-09T19:25:31.000Z",
    "textPlain": "Learning how to use LLMs in a coding workflow is trivial. There is no learning curve. [...]LLMs will always suck at writing code that has not be written millions of times before. As soon as you venture slightly offroad, they falter.That right there is your learning curve! Getting LLMs to write code that's not heavily represented in their training data takes experience and skill and isn't obvious to learn.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44849921,
    "by": "kodisha",
    "timeISO": "2025-08-09T20:31:58.000Z",
    "textPlain": "LLM driven coding can yield awesome results, but you will be typing a lot and, as article states, requires already well structured codebase.I recently started with fresh project, and until I got to the desired structure I only used AI to ask questions or suggestions. I organized and written most of the code.Once it started to get into the shape that felt semi-permanent to me, I started a lot of queries like:```- Look at existing service X at folder services/x- see how I deploy the service using k8s/services/x- see how the docker file for service X looks like at services/x/Dockerfile- now, I started service Y that does [this and that]- create all that is needed for service Y to be skaffolded and deployed, follow the same pattern as service X```And it would go, read existing stuff for X, then generate all of the deployment/monitoring/readme/docker/k8s/helm/skaffold for YWith zero to none mistakes.\nBoth claude and gemini are more than capable to do such task.\nI had both of them generate 10-15 files with no errors, with code being able to be deployed right after (of course service will just answer and not do much more than that)Then, I will take over again for a bit, do some business logic specific to Y, then again leverage AI to fill in missing bits, review, suggest stuff etc.It might look slow, but it actually cuts most boring and most error prone steps when developing medium to large k8s backed project.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44848603,
    "by": "randfish",
    "timeISO": "2025-08-09T17:57:38.000Z",
    "textPlain": "Deeply curious to know if this is an outlier opinion, a mainstream but pessimistic one, or the general consensus. My LinkedIn feed and personal network certainly suggests that it's an outlier, but I wonder if the people around me are overly optimistic or out of synch with what the HN community is experiencing more broadly.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44849868,
    "by": "spenrose",
    "timeISO": "2025-08-09T20:26:00.000Z",
    "textPlain": "So many articles should prepend “My experience with ...” to their title. Here is OP's first sentence: “I spent the past ~4 weeks trying out all the new and fancy AI tools for software development.” Dude, you have had some experiences and they are worth writing up and sharing. But your experiences are not a stand-in for \"the current state.\" This point applies to a significant fraction of HN articles, to the point that I wish the headlines were flagged “blog”.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44853299,
    "by": "MitziMoto",
    "timeISO": "2025-08-10T06:55:52.000Z",
    "textPlain": "My favorite setup so far is using the Claude code extension in VScode. All the power of CC, but it opens files and diffs in VScode. Easy to read and modify as needed.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44849170,
    "by": "dezmou",
    "timeISO": "2025-08-09T19:05:23.000Z",
    "textPlain": "OP did miss the vscode extension for claude code, it is still terminal based but: \n - it show you the diff of the incoming changes in vscode ( like git ) \n - it know the line you selected in the editor for context",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44850822,
    "by": "stephc_int13",
    "timeISO": "2025-08-09T22:16:09.000Z",
    "textPlain": "I have not tried every IDE/CLI or models, only a few, mostly Claude and Qwen.I work mostly in C/C++.The most valuable improvement of using this kind of tools, for me, is to easily find help when I have to work on boring/tedious tasks or when I want to have a Socratic conversation about a design idea with a not-so-smart but extremely knowledgeable colleague.But for anything requiring a brain, it is almost useless.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44850595,
    "by": "bachmeier",
    "timeISO": "2025-08-09T21:49:42.000Z",
    "textPlain": "> By being particularly bad at anything outside of the most popular languages and frameworks, LLMs force you to pick a very mainstream stack if you want to be efficient.I haven't found that to be true with my most recent usage of AI. I do a lot of programming in D, which is not popular like Python or Javascript, but Copilot knows it well enough to help me with things like templates, metaprogramming, and interoperating with GCC-produced DLL's on Windows. This is true in spite of the lack of a big pile of training data for these tasks. Importantly, it gets just enough things wrong when I ask it to write code for me that I have to understand everything well enough to debug it.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44851742,
    "by": "joshuamoyers",
    "timeISO": "2025-08-10T00:37:23.000Z",
    "textPlain": "> By being particularly bad at anything outside of the most popular languages and frameworks, LLMs force you to pick a very mainstream stack if you want to be efficient.Almost like hiring and scaling a team? There are also benchmarks that specifically measure this, and its in theory a very temporary problem (Aider Polyglot Benchmark is one such).",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44850796,
    "by": "singularity2001",
    "timeISO": "2025-08-09T22:12:04.000Z",
    "textPlain": "\"LLMs won’t magically make you deliver production-ready code\"Either I'm extremely lucky or I was lucky to find the guy who said it must all be test driven and guided by the usual principles of DRY etc. Claude Code works absolutely fantastically nine out of 10 times and when it doesn't we just roll back the three hours of nonsense it did postpone this feature or give it extra guidance.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44849200,
    "by": "sudhirb",
    "timeISO": "2025-08-09T19:08:49.000Z",
    "textPlain": "I have a biased opinion since I work for a background agent startup currently - but there are more (and better!) out there than Jules and Copilot that might address some of the author's issues.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44850824,
    "by": "infoseek12",
    "timeISO": "2025-08-09T22:16:21.000Z",
    "textPlain": "There are kind of a lot of errors in this piece. For instance, the problem the author had with Gemini CLI running out of tokens in ten minutes is what happens when you don’t set up (a free) API key in your environment.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44851649,
    "by": "stopachka",
    "timeISO": "2025-08-10T00:23:23.000Z",
    "textPlain": "> By being particularly bad at anything outside of the most popular languages and frameworks, LLMs force you to pick a very mainstream stack if you want to be efficient.I use clojure for my day-to-day work, and I haven't found this to be true. Opus and GPT-5 are great friends when you start pushing limits on Clojure and the JVM.> Or 4.1 Opus if you are a millionaire and want to pollute as much possibleI know this was written tongue-in-cheek, but at least in my opinion it's worth it to use the best model if you can. Opus is definitely better on harder programming problems.> GPT 4.1 and 5 are mostly bad, but are very good at following strict guidelines.This was interesting. At least in my experience GPT-5 seemed about as good as Opus. I found it to be _less_ good at following strict guidelines though. In one test Opus avoided a bug by strictly following the rules, while GPT-5 missed.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44850022,
    "by": "philipwhiuk",
    "timeISO": "2025-08-09T20:44:42.000Z",
    "textPlain": "There’s an IntelliJ extension for GitHub CoPilot.It’s not perfect but it’s okay.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44852236,
    "by": "abrookewood",
    "timeISO": "2025-08-10T02:09:47.000Z",
    "textPlain": "\"Google’s enshittification has won and it looks like no competent software developers are left. I would know, many of my friends work there\". Ouch ... I hope his friends are in marketing!",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44849807,
    "by": "weeksie",
    "timeISO": "2025-08-09T20:20:07.000Z",
    "textPlain": "Yet another developer who is too full of themselves to admit that they have no idea how to use LLMs for development. There's an arrogance that can set in when you get to be more senior and unless you're capable of force feeding yourself a bit of humility you'll end up missing big, important changes in your field.It becomes farcical when not only are you missing the big thing but you're also proud of your ignorance and this guy is both.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44849899,
    "by": "dash2",
    "timeISO": "2025-08-09T20:29:24.000Z",
    "textPlain": "They missed OpenAI Codex, maybe deliberately? It's less llm-development and more vibe-coding, or maybe \"being a PHB of robots\". I'm enjoying it for my side project this week.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44850641,
    "by": "Vektorceraptor",
    "timeISO": "2025-08-09T21:54:05.000Z",
    "textPlain": "I agree. I had a similar experience.https://speculumx.at/pages/read_post.html?post=59",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44851316,
    "by": "Mystery-Machine",
    "timeISO": "2025-08-09T23:27:02.000Z",
    "textPlain": "> Claude 4 Sonnet\n> Or 4.1 Opus if you are a millionaire and want to pollute as much possibleThat was an unnecessary guilt-shaming remark.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44850279,
    "by": "yogthos",
    "timeISO": "2025-08-09T21:12:08.000Z",
    "textPlain": "Personally, I’ve had a pretty positive experience with the coding assistants, but I had to spend some time to develop intuition for the types of tasks they’re likely to do well. I would not say that this was trivial to do.Like if you need to crap out a UI based on a JSON payload, make a service call, add a server endpoint, LLMs will typically do this correctly in one shot. These are common operations that are easily extrapolated from their training data. Where they tend to fail are tasks like business logic which have specific requirements that aren’t easily generalized.I’ve also found that writing the scaffolding for the code yourself really helps focus the agent. I’ll typically add stubs for the functions I want, and create overall code structure, then have the agent fill the blanks. I’ve found this is a really effective approach for preventing the agent from going off into the weeds.I also find that if it doesn’t get things right on the first shot, the chances are it’s not going to fix the underlying problems. It tends to just add kludges on top to address the problems you tell it about. If it didn’t get it mostly right at the start, then it’s better to just do it yourself.All that said, I find enjoyment is an important aspect as well and shouldn’t be dismissed. If you’re less productive, but you enjoy the process more, then I see that as a net positive. If all LLMs accomplish is to make development more fun, that’s a good thing.I also find that there's use for both terminal based tools and IDEs. The terminal REPL is great for initially sketching things out, but IDE based tooling makes it much easier to apply selective changes exactly where you want.As a side note, got curious and asked GLM-4.5 to make a token field widget with React, and it did it in one shot.It's also strange not to mention DeepSeek and GLM as options given that they cost orders of magnitude less per token than Claude or Gemini.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44850118,
    "by": "SadErn",
    "timeISO": "2025-08-09T20:54:54.000Z",
    "textPlain": "It's all about the Kilo Code extension.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44853606,
    "by": "jstummbillig",
    "timeISO": "2025-08-10T08:07:04.000Z",
    "textPlain": "We know what random* looks like: a coin toss, the roll of a die. Token generation is neither.",
    "parent": 44853504,
    "depth": 2
  },
  {
    "id": 44851031,
    "by": "SkyPuncher",
    "timeISO": "2025-08-09T22:42:30.000Z",
    "textPlain": "> Learning how to use LLMs in a coding workflow is trivial. There is no learning curve. You can safely ignore them if they don’t fit your workflows at the moment.That's a wild statement. I'm now extremely productive with LLMs in my core codebases, but it took a lot of practice to get it right and repeatable. There's a lot of little contextual details you need to learn how to control so the LLM makes the right choices.Whenever I start working in a new code base, it takes a a non-trivial amount of time to ramp back up to full LLM productivity.",
    "parent": 44849147,
    "depth": 2
  },
  {
    "id": 44853123,
    "by": "rocqua",
    "timeISO": "2025-08-10T06:12:31.000Z",
    "textPlain": "The OPs point seems to be: it's very quick for LLMs to be a net benefit to your skills, if it is a benefit at all. That is, he's only speaking of the very beginning part of the learning curve.",
    "parent": 44849147,
    "depth": 2
  },
  {
    "id": 44849260,
    "by": "edfletcher_t137",
    "timeISO": "2025-08-09T19:16:31.000Z",
    "textPlain": "The first two points directly contradict each other, too. Learning a tool should have the outcome that one is productive with it. If getting to \"productive\" is non-trivial, then learning the tool is non-trivial.",
    "parent": 44849147,
    "depth": 2
  },
  {
    "id": 44849317,
    "by": "prerok",
    "timeISO": "2025-08-09T19:23:20.000Z",
    "textPlain": "I agree with your assessment about this statement. I actually had to reread it a few times to actually understand it.He is actually recommending Copilot for price/performance reasons and his closing statement is \"Don’t fall for the hype, but also, they are genuinely powerful tools sometimes.\"So, it just seems like he never really gave a try at how to engineer better prompts that these more advanced models can use.",
    "parent": 44849147,
    "depth": 2
  },
  {
    "id": 44849854,
    "by": "bgwalter",
    "timeISO": "2025-08-09T20:24:21.000Z",
    "textPlain": "Pianists' results are well known to be proportional to their talent/effort. In open source hardly anyone is even using LLMs and the ones that do have barely any output, In many cases less output than they had before using LLMs.The blogging output on the other hand ...",
    "parent": 44849147,
    "depth": 2
  },
  {
    "id": 44849887,
    "by": "troupo",
    "timeISO": "2025-08-09T20:27:59.000Z",
    "textPlain": "> I have never heard anybody successfully using LLMs say this before. Most of what I've learned from talking to people about their workflows is counterintuitive and subtle.Because for all our posturing about being skeptical and data driven we all believe in magic.Those \"counterintuitive non-trivial workflows\"? They work about as well as just prompting \"implement X\" with no rules, agents.md, careful lists etc.Because 1) literally no one actually measures whether magical incarnations work and 2) it's impossible to make such measurements due to non-determinism",
    "parent": 44849147,
    "depth": 2
  },
  {
    "id": 44853900,
    "by": "OldfieldFund",
    "timeISO": "2025-08-10T09:18:36.000Z",
    "textPlain": "I don't agree. Cursor is mind-blowingly good with the new agentic updates.",
    "parent": 44853870,
    "depth": 2
  },
  {
    "id": 44848923,
    "by": "mkozlows",
    "timeISO": "2025-08-09T18:34:20.000Z",
    "textPlain": "\"There's no learning curve\" just means this guy didn't get very far up, which is definitely backed up by thinking that Copilot and other tools are all basically the same.",
    "parent": 44848846,
    "depth": 2
  },
  {
    "id": 44851909,
    "by": "skydhash",
    "timeISO": "2025-08-10T01:03:29.000Z",
    "textPlain": "If you have a big rock (a software project), there's quite a difference between pushing it uphill (LLM usage) and hauling it up with a winch (traditional tooling and methods).People are claiming that it takes time to build the muscles and train the correct footing to push, while I'm here learning mechanical theory and drawing up levers. If one managed to push the rock for one meter, he comes clamoring, ignoring the many who was injured by doing so, saying that one day he will be able to pick the rock up and throw it at the moon.",
    "parent": 44849341,
    "depth": 2
  },
  {
    "id": 44849488,
    "by": "TheSamFischer",
    "timeISO": "2025-08-09T19:44:00.000Z",
    "textPlain": "[dead]",
    "parent": 44849341,
    "depth": 2
  },
  {
    "id": 44851185,
    "by": "manmal",
    "timeISO": "2025-08-09T23:02:54.000Z",
    "textPlain": "My workflow with a medium sized iOS codebase is a bit like that. By the time everything works and is up to my standards, I‘ve usually taken longer, or almost as long, as if I‘d written everything manually. That’s with Opus-only Claude Code. It’s complicated stuff (structured concurrency and lots of custom AsyncSequence operators) which maybe CC just isn‘t suitable for.Whipping up greenfield projects is almost magical, of course. But that’s not most of my work.",
    "parent": 44849921,
    "depth": 2
  }
]