[
  {
    "id": 44848846,
    "by": "ebiester",
    "timeISO": "2025-08-09T18:25:28.000Z",
    "textPlain": "I disagree from almost the first sentence:> Learning how to use LLMs in a coding workflow is trivial. There is no learning curve. You can safely ignore them if they don’t fit your workflows at the moment.Learning how to use LLMs in a coding workflow is trivial to start, but you find you get a bad taste early if you don't learn how to adapt both your workflow and its workflow. It is easy to get a trivially good result and then be disappointed in the followup. It is easy to try to start on something it's not good at and think it's worthless.The pure dismissal of cursor, for example, means that the author didn't learn how to work with it. Now, it's certainly limited and some people just prefer Claude code. I'm not saying that's unfair. However, it requires a process adaptation.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44848603,
    "by": "randfish",
    "timeISO": "2025-08-09T17:57:38.000Z",
    "textPlain": "Deeply curious to know if this is an outlier opinion, a mainstream but pessimistic one, or the general consensus. My LinkedIn feed and personal network certainly suggests that it's an outlier, but I wonder if the people around me are overly optimistic or out of synch with what the HN community is experiencing more broadly.",
    "parent": 44847741,
    "depth": 1
  },
  {
    "id": 44848862,
    "by": "MobiusHorizons",
    "timeISO": "2025-08-09T18:27:03.000Z",
    "textPlain": "My impression has been that in corporate settings (and I would include LinkedIn in that) AI optimism is basically used as virtue signaling, making it very hard to distinguish people who are actually excited about the tech from people wanting to be accepted.My personal experience has been that AI has trouble keeping the scope of the change small and targeted. I have only been using Gemini 2.5 pro though, as we don’t have access to other models at my work. My friend tells me he uses Claud for coding and Gemini for documentation.",
    "parent": 44848603,
    "depth": 2
  },
  {
    "id": 44848841,
    "by": "WD-42",
    "timeISO": "2025-08-09T18:24:55.000Z",
    "textPlain": "I think it’s pretty common among people whose job it is to provide working, production software.If you go by MBA types on LinkedIn that aren’t really developers or haven’t been in a long time, now they can vibe out some react components or a python script so it’s a revolution.",
    "parent": 44848603,
    "depth": 2
  },
  {
    "id": 44848771,
    "by": "Terretta",
    "timeISO": "2025-08-09T18:17:58.000Z",
    "textPlain": "Which part of the opinion?I tend to strongly agree with the \"unpopular opinion\" about the IDEs mentioned versus CLI (specifically, aider.chat and Claude Code).Assuming (this is key) you have mastery of the language and framework you're using, working with the CLI tool in 25 year old XP practices is an incredible accelerant.Caveats:- You absolutely must bring taste and critical thinking, as the LLM has neither.- You absolutely must bring systems thinking, as it cannot keep deep weirdness \"in mind\". By this I mean the second and third order things that \"gotcha\" about how things ought to work but don't.- Finally, you should package up everything new about your language or frameworks since a few months or year before the knowledge cutoff date, and include a condensed synthesis in your context (e.g., Swift 6 and 6.1 versus the 5.10 and 2024's WWDC announcements that are all GPT-5 knows).For this last one I find it useful to (a) use OpenAI's \"Deep Research\" to first whitepaper the gaps, then another pass to turn that into a Markdown context prompt, and finally bring that over to your LLM tooling to include as needed when doing a spec or in architect mode.  Similarly, (b) use repomap tools on dependencies if creating new code that leverages those dependencies, and have that in context for that work.I'm confused why these two obvious steps aren't built into leading agentic tools, but maybe handling the LLM as a naive and outdated \"Rain Man\" type doesn't figure into mental models at most KoolAid-drinking \"AI\" startups, or maybe vibecoders don't care, so it's just not a priority.Either way, context based development beats Leroy Jenkins.",
    "parent": 44848603,
    "depth": 2
  }
]