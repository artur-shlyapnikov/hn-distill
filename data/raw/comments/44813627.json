[
  {
    "id": 44816148,
    "by": "nisten",
    "timeISO": "2025-08-06T18:59:03.000Z",
    "textPlain": "If you want to have an opinion on it,just install lmstudio and run the q8_0 version of it i.e. here https://huggingface.co/bartowski/Qwen_Qwen3-4B-Instruct-2507....you can even run it on a 4gb raspberry pi Qwen_Qwen3-4B-Instruct-2507-Q4_K_L.gguf\nhttps://lmstudio.ai/Keep in mind if you run it at the full 262144 tokens of context youll need ~65gb of ram.Anyway if you're on mac you can search for \"qwen3 4b 2507 mlx 4bit\"    and run the mlx version which is often faster  on m chips. Crazy impressive what you get from a 2gb file in my opinion.It's pretty good for summaries etc, can even make simple index.html sites if you're teaching students but it can't really vibecode in my opinion. However for local automation tasks like summarizing your emails, or home automation or whatever it is excellent.It's crazy that we're at this point now.",
    "parent": 44813627,
    "depth": 1
  },
  {
    "id": 44815355,
    "by": "film42",
    "timeISO": "2025-08-06T17:54:36.000Z",
    "textPlain": "Is there a crowd-sourced sentiment score for models? I know all these scores are juiced like crazy. I stopped taking them at face value months ago. What I want to know is if other folks out there actually use them or if they are unreliable.",
    "parent": 44813627,
    "depth": 1
  },
  {
    "id": 44814443,
    "by": "esafak",
    "timeISO": "2025-08-06T16:45:47.000Z",
    "textPlain": "This one should work on personal computers! I'm thankful for Chinese companies raising the floor.",
    "parent": 44813627,
    "depth": 1
  },
  {
    "id": 44814505,
    "by": "frontsideair",
    "timeISO": "2025-08-06T16:50:44.000Z",
    "textPlain": "According to the benchmarks, this one is improved in every one of them compared to the previous version, some better than 30B-A3B. Definitely worth a try, it’ll easily fit into memory and token generation speed will be pleasantly fast.",
    "parent": 44813627,
    "depth": 1
  },
  {
    "id": 44814376,
    "by": "gok",
    "timeISO": "2025-08-06T16:41:38.000Z",
    "textPlain": "So this 4B dense model gets very similar performance to the 30B MoE variant with 7.5x smaller footprint.",
    "parent": 44813627,
    "depth": 1
  },
  {
    "id": 44816101,
    "by": "svnt",
    "timeISO": "2025-08-06T18:54:57.000Z",
    "textPlain": "It is interesting to think about how they are achieving these scores. The evals are rated by GPT-4.1. Beyond just overfitting to benchmarks, is it possible the models are internalizing how to manipulate the ratings model/agent? Is anyone manually auditing these performance tables?",
    "parent": 44813627,
    "depth": 1
  },
  {
    "id": 44814566,
    "by": "tolerance",
    "timeISO": "2025-08-06T16:55:32.000Z",
    "textPlain": "Is there like a leaderboard or power rankings sort of thing that tracks these small open models and assigns ratings or grades to them based on particular use cases?",
    "parent": 44813627,
    "depth": 1
  },
  {
    "id": 44819513,
    "by": "Demiurge",
    "timeISO": "2025-08-07T00:51:56.000Z",
    "textPlain": "I've been trying this today, and I'm getting a lot of hallucinations for suggestions. However, the analysis of problems really quite good.",
    "parent": 44813627,
    "depth": 1
  },
  {
    "id": 44815247,
    "by": "jampa",
    "timeISO": "2025-08-06T17:46:48.000Z",
    "textPlain": "I am reading this right, is this model way better than Gemma 3n[1]? (For only the benchmarks that are common among the models)=====LiveCodeBenchE4B IT: 13.2Qwen: 55.2=====\nAIME25E4B IT: 11.6Qwen: 81.3[1]: https://huggingface.co/google/gemma-3n-E4B",
    "parent": 44813627,
    "depth": 1
  }
]