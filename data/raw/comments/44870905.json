[
  {
    "id": 44903555,
    "by": "Sesse__",
    "timeISO": "2025-08-14T17:57:46.000Z",
    "textPlain": "The fastest way of doing a heap I've found is generally: Don't. For many of the relevant operations (graph search, merging streams, etc.), you can do just as well with a winner-tree; it can usually be updated branch-free with min/max operations, whereas with a heap you'll usually have completely unpredictable branches for every single operation.A winner-tree, or its counterpart the loser-tree (for min instead of max), is a very simple binary tree: Bottom layer is all your values (2^N of them). The layer above that is the highest of pairs of values. The layer above that is the highest of pairs of pairs. And so on, until you get to the top of the tree, which contains the largest value. Updating a value is trivial; you overwrite the relevant one at the bottom, and then run exactly log2(n) max operations upwards until the you hit the root. Inserting and deleting may, of course, be more complicated.",
    "parent": 44870905,
    "depth": 1
  },
  {
    "id": 44904110,
    "by": "superjan",
    "timeISO": "2025-08-14T18:48:12.000Z",
    "textPlain": "i have wasted several weeks worth of evenings on vectorizing heaps (4ary heaps: with SIMD, you’re not limited to binary heaps). It did not provide any speedup. I’d expect that halving heap depth would help but no. Still don’t know why.",
    "parent": 44870905,
    "depth": 1
  },
  {
    "id": 44903833,
    "by": "_ache_",
    "timeISO": "2025-08-14T18:22:33.000Z",
    "textPlain": "Can't see the Website.I'm the only one with a HTTPS problem here? Bad domain, `art.mahajana.net` instead of 0x80.pl.",
    "parent": 44870905,
    "depth": 1
  },
  {
    "id": 44903406,
    "by": "CalChris",
    "timeISO": "2025-08-14T17:45:55.000Z",
    "textPlain": "It's 2025 and the simd operations in this aren't that obscure. So I wonder how close std::simd gets to the instrinsics' performance with clang and gcc.",
    "parent": 44870905,
    "depth": 1
  },
  {
    "id": 44900396,
    "by": "dooglius",
    "timeISO": "2025-08-14T13:53:56.000Z",
    "textPlain": "is_heap doesn't seem like a particularly useful operation though, generally a heap is intentionally constructed as such via push_heap/pop_heap",
    "parent": 44870905,
    "depth": 1
  },
  {
    "id": 44904230,
    "by": "DennisL123",
    "timeISO": "2025-08-14T18:58:19.000Z",
    "textPlain": "A winner tree uses extra space, doesn't it? That might exclude it from certain applications to be an alternative. Four-ary heaps are roughly (ymmv) twice as fast as binary heaps by exploiting cache locality in a better way for small key/value types. And it seems to be a sweet spot since eight-ary heaps don’t deliver additional improvements.",
    "parent": 44903555,
    "depth": 2
  },
  {
    "id": 44901876,
    "by": "mananaysiempre",
    "timeISO": "2025-08-14T15:49:18.000Z",
    "textPlain": "Indeed that part seems more like an artist’s study than an attempt at actual usefulness, but that’s okay when figuring out if anything at all in the neighbourhood of what you’re trying to do with SIMD is even possible. As far as constructing heaps, don’t forget about (linear-time) heapify, which can be significantly faster if you have a bunch of elements and want to construct a heap with all of them in it. (This doesn’t get you a linear-time heap sort because you’ll still pay the full linearithmic price for the subsequent pop_heaps.)",
    "parent": 44900396,
    "depth": 2
  },
  {
    "id": 44901850,
    "by": "simonask",
    "timeISO": "2025-08-14T15:47:33.000Z",
    "textPlain": "I think it's fairly useful. It means that you can convert a contiguous array to a heap with a fast O(n) read-only check instead of O(n log n) writes, so if you know that's the common case, you can detect it up front and only revert to normal binary heap insertion if it returns false.",
    "parent": 44900396,
    "depth": 2
  },
  {
    "id": 44903150,
    "by": "camel-cdr",
    "timeISO": "2025-08-14T17:24:14.000Z",
    "textPlain": "make_heap should be vectorizable, that would be more useful.\nI can also see a path to vectorize bulk insert, but that seems harder.",
    "parent": 44900396,
    "depth": 2
  }
]