[
  {
    "id": 44863332,
    "by": "jmkni",
    "timeISO": "2025-08-11T12:16:17.000Z",
    "textPlain": "If you run these on your own hardware can you take the guard-rails off (ie \"I'm afraid I can't assist with that\"), or are they baked into the model?",
    "parent": 44862542,
    "depth": 1
  },
  {
    "id": 44863184,
    "by": "tyfon",
    "timeISO": "2025-08-11T11:53:05.000Z",
    "textPlain": "I have a 5950x with 128 gb ram and a 12 gb 3060 gpu. \nThe speed of generating tokens is excellent, the killer is that when the context grows even a little processing of it is super slow. \nHopefully someone smart will optimize this, but as it is now I keep using other models like qwen, mistral and gemma.",
    "parent": 44862542,
    "depth": 1
  },
  {
    "id": 44863425,
    "by": "GTP",
    "timeISO": "2025-08-11T12:29:14.000Z",
    "textPlain": "LLM noob here. Would this optimization work with any MoE model or is it specific for this one?",
    "parent": 44862542,
    "depth": 1
  },
  {
    "id": 44863445,
    "by": "nativeit",
    "timeISO": "2025-08-11T12:32:03.000Z",
    "textPlain": "…and yet a much more capable model (my own brain) still runs better than this on pop tarts.",
    "parent": 44862542,
    "depth": 1
  },
  {
    "id": 44862836,
    "by": "amelius",
    "timeISO": "2025-08-11T10:56:29.000Z",
    "textPlain": "But how many micro-Einsteins does it have?",
    "parent": 44862542,
    "depth": 1
  },
  {
    "id": 44863356,
    "by": "hnuser123456",
    "timeISO": "2025-08-11T12:19:21.000Z",
    "textPlain": "You need to find an abliterated finetune, where someone sends prompts that would hit the guardrails, traces the activated neurons, finds the pathway that leads to refusal, and deletes it.",
    "parent": 44863332,
    "depth": 2
  },
  {
    "id": 44863352,
    "by": "stainablesteel",
    "timeISO": "2025-08-11T12:19:01.000Z",
    "textPlain": "they're baked in but there's a community of people who crack and modify themeven chat gpt will help you crack them if you ask it nicely",
    "parent": 44863332,
    "depth": 2
  },
  {
    "id": 44863249,
    "by": "MaxikCZ",
    "timeISO": "2025-08-11T12:03:04.000Z",
    "textPlain": "I would so appreciate concrete data instead of subjectivities like \"excellent\" and \"super slow\".How many tokens is excellent?\nHow many is super slow? How many is non-filled context?",
    "parent": 44863184,
    "depth": 2
  },
  {
    "id": 44863333,
    "by": "captainregex",
    "timeISO": "2025-08-11T12:16:18.000Z",
    "textPlain": "What are you aiming to do with these models that isn’t chat/text manipulation?",
    "parent": 44863184,
    "depth": 2
  },
  {
    "id": 44863469,
    "by": "magicalhippo",
    "timeISO": "2025-08-11T12:35:06.000Z",
    "textPlain": "It's just doing a regex on the layer names, so should work with other models as long as they have the expert layers named similarly.It worked with Qwen 3 for me, for example.The option is just a shortcut, you can provide your own regex to move specific layers to specific devices.",
    "parent": 44863425,
    "depth": 2
  },
  {
    "id": 44863528,
    "by": "MaxikCZ",
    "timeISO": "2025-08-11T12:44:14.000Z",
    "textPlain": "Your comment will get donvoted to invisibility anyways (or mayhaps even flagged), but I have to ask: what are you trying to accomplish with comments such this? Just shitting at it because it isnt as good as youd like yet? You want the best of tomorrow today, and will only be rambling about how its not good enough yesterday?",
    "parent": 44863445,
    "depth": 2
  },
  {
    "id": 44863575,
    "by": "Leonadopeterson",
    "timeISO": "2025-08-11T12:51:51.000Z",
    "textPlain": "[dead]",
    "parent": 44863445,
    "depth": 2
  }
]