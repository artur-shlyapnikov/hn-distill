[
  {
    "id": 44815815,
    "by": "jerf",
    "timeISO": "2025-08-06T18:31:55.000Z",
    "textPlain": "This post gets the reason why people are cutting off LLMs exactly backwards and consequently completely fails to address the core issue. The whole reason people are blocking LLMs is precisely that they believe it kills the flow of readers to your content. The LLMs present your ideas and content, maybe with super-tiny attribution that nobody notices or uses [1], maybe with no attribution at all, and you get nothing. People are blocking LLMs with the precise intent of trying to preserve the flow to their content, be it commercially, reputationally, whatever.[1]: https://www.pewresearch.org/short-reads/2025/07/22/google-us...",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815799,
    "by": "nerdjon",
    "timeISO": "2025-08-06T18:30:51.000Z",
    "textPlain": "That is basically several paragraphs to just say \"well you should just adapt to the new world instead of pushing against bad practices\". There is barely any \"why\" actually said here.We just had the article about how AI search is leading to less clicks, so where is that supposed \"pipeline\"?Also completely ignores how you may not want your information to be misconstrued (lied basically) to the user with a helpful link telling them where the source is, but they may never click through. And worse if they know that the information being told to them is wrong, they may then think it was because your site was wrong and trust you less, all without ever clicking that link.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815770,
    "by": "riffraff",
    "timeISO": "2025-08-06T18:28:20.000Z",
    "textPlain": "> LLMs are the next generation’s search layer. They’re already generating massive amounts of pipeline for the companies and websites that have gotten good at getting their content displayed in LLMs[citation needed]",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817740,
    "by": "shortstuffsushi",
    "timeISO": "2025-08-06T20:56:02.000Z",
    "textPlain": "I'm surprised I don't see any comments here to this effect yet: isn't this just AMP 2.0? Website authors don't want their content scraped and rehosted by a 3rd party, even when that 3rd party claims it's for their own benefit. We have a whole kerfuffle about this nearly a decade ago. The arguments for both sides don't appear to have changed.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815824,
    "by": "bellBivDinesh",
    "timeISO": "2025-08-06T18:32:27.000Z",
    "textPlain": "Incredibly simplistic. I’m having a hard time believing a real person wrote this, read it over and decided they had made anything resembling a point.How about the fact that Google (ideally) sends users to you rather than sharing your work unattributed?",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817021,
    "by": "eric-burel",
    "timeISO": "2025-08-06T20:04:03.000Z",
    "textPlain": "The first sentence of the article is literally wrong as it conflates LLM and the search part of a RAG (retrieval augmented generation, when you mix a web search and an LLM).\nBlocking bots cuts you off from the next-generation search, because it cuts you off from search at all. So far, blocking LLM simply prevents you from being part of the training dataset, which is not the same thing.\nPlease stop upvoting such bad content it really makes Hackernews a terrible place for staying informed on LLMs.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815839,
    "by": "ryandrake",
    "timeISO": "2025-08-06T18:33:55.000Z",
    "textPlain": "Like everything else on the web, LLMs are going to eventually be ruined by marketing teams trying to get them to say \"Pepsi\" instead of \"Coke.\"",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815860,
    "by": "mflaherty22",
    "timeISO": "2025-08-06T18:35:45.000Z",
    "textPlain": "Very reductionist - so much so that I'm not even sure you understand why websites block LLMs.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815981,
    "by": "JSR_FDED",
    "timeISO": "2025-08-06T18:44:49.000Z",
    "textPlain": "Nonsensical article. Even if your goal is to create something on the web “for others” (as the article asserts), when 99.9% of your costs go to serving LLM crawlers, it puts that very objective at risk.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44816178,
    "by": "politelemon",
    "timeISO": "2025-08-06T19:01:01.000Z",
    "textPlain": "I never managed to get far on this post due to the obnoxious pop-ups. Perhaps blocking humans from reading your posts is ok.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815952,
    "by": "ashwinsundar",
    "timeISO": "2025-08-06T18:42:35.000Z",
    "textPlain": "But how many of you wouldn’t hook up your website to Google?\n\nMe. https://ashwinsundar.com/robots.txtYour computer doesn't have the right to scrape what I say or do anything with it.    I know one of the primary reasons that I do anything online is to provide an outlet for someone else to see it. If I didn’t want someone else to see it, I’d write it down on my notebook, not on the public web.\n\nSounds like the same schpiel from the anti-privacy advocates who think that we should all expose everything we're doing because \"you should have nothing to hide\".https://archive.is/WjbcUThis article was written for Wired by Moxie Marlinspike in 2013, who went on to later develop the Signal protocol.I don't want my thoughts or ideas spread across the web promiscuously. The things I say publicly are curated and full of context. That's why I have my own website, and don't post elsewhere.I'm not playing the same game you are, which appears to be to post liberally and have loose thoughts to maximize \"reach\".",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44816671,
    "by": "merelysounds",
    "timeISO": "2025-08-06T19:38:19.000Z",
    "textPlain": "> most LLMs have an agentic web-search component that will actively generate linksI guess that’s the problem - search being only a component.Is the possible search traffic worth having your content become part of an LLM’s training set and possibly used elsewhere?I guess the answer depends on the content and the website’s business model.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817661,
    "by": "ayaros",
    "timeISO": "2025-08-06T20:48:10.000Z",
    "textPlain": "Screw this. I didn't put effort into writing many paragraphs of content for my own websites just so it could be summarized by an LLM. I wrote it because I wanted other human beings to read it.This is just yet another person running an AI company telling me why I should provide free data and labor to the LLMs that power their company. These AI companies are acting as middlemen between the end-user and the content creator; its the latest iteration of an age-old business model which works-out great for the middlemen. Meanwhile, people on either side are taken advantage of.If the \"next-generation\" of search is accessed mostly through an LLM, then there's no incentive to participate in it unless you're directly selling a product or service... and then you have to hope and pray the LLM doesn't lie and misrepresent you. Otherwise, if you're making a website to share information or show off your own work, there's zero incentive to participate.If AI companies want to pay me cold hard cash every time they query my site, then we can negotiate.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815802,
    "by": "pryelluw",
    "timeISO": "2025-08-06T18:31:14.000Z",
    "textPlain": "“Providing high quality content that LLMs will actually cite is the new game in town.”That is not my job nor is it my goal. These companies are taking my work, repurposing it, and selling it under the assumption that because they can access it they can sell it.Maybe the OP should leave their house door open so people can come in and use his couch. The new game in town is to let other people use your couch.The mental gymnastics in this post qualify for the Special Olympics.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815795,
    "by": "righthand",
    "timeISO": "2025-08-06T18:30:34.000Z",
    "textPlain": "It’s not dumb because Googlebot follows the robots.txt rules. That is the sincere crux of it all. No one is going to casually open their site up to Llms that are blatantly scraping their site to then use their information to displace them.Not blocking violent, bad-actor scrapers is dumb. Letting through bad-actor scrapers because a bunch of rich people want to make it the norm is dumb.Llms are not directing traffic to the sites and that is the tradeoff that site owners allow with Googlebot. Even if Perplexity or Claude will provide a source, the Llm user is most likely not asking/clicking for it 99% of the time.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44816786,
    "by": "skwee357",
    "timeISO": "2025-08-06T19:46:04.000Z",
    "textPlain": "I'm somewhat torn on this one.As an amateur blogger, I would not like LLMs to \"steal\" my content, display the users the needed pieces they are looking for, while leaving me with zero visitors. The reason I write is to convey a particular message, which the meaning of gets lost, or worse communicated wrongly, due to LLMs.As an online business owner, I do see both ChatGPT and Perplexity as referrers to my business, meaning that potential customers ask LLM a question/service recommendation, and LLM is directing them to my service, and I would not like to lose this vertical of organic customer acquisition.---On a completely different note, medium should die as a platform, together with substack. The amount of intrusive popups, \"install our app\" bars, and paywalls is just insane. Bloggers, especially technically savvy ones, should be able to host their own blog.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44819045,
    "by": "johnnienaked",
    "timeISO": "2025-08-06T23:29:50.000Z",
    "textPlain": "And here's me, wondering how anyone in their right mind would ever consider putting anything original or worth reading on the internet ever again.If you do you're just feeding the AI monster for free.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817175,
    "by": "iamwil",
    "timeISO": "2025-08-06T20:15:58.000Z",
    "textPlain": "I agree with the sentiment. I remember Gwern in an interview remarking something to the effect that if you make your writing and thoughts invisible to LLMs, then your thoughts are going to be invisible to the future, as LLMs are here to stay.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817085,
    "by": "Wilder7977",
    "timeISO": "2025-08-06T20:08:49.000Z",
    "textPlain": "Once again I see someone mistaking an LLM regurgitating (in a right, wrong, misleading way, who knows) your content for people \"accessing\" your content. If the LLM sits between me and my reader and acts as a filter (because the information is rehashed, because maybe sometimes doesn't reference me), basically my goal is to provide information to tools for other companies to make money?\nI don't write for money, but if you remove also the basic human interaction reader-writer, I might as well really write in my notes.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44816861,
    "by": "ramoz",
    "timeISO": "2025-08-06T19:51:30.000Z",
    "textPlain": "It doesn't if the agent sits alongside users on their desktops.LLMs are being blocked by standard bot detection - and the use cases are very much the same. People want smarter bots for the same shitty use cases.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817454,
    "by": "Mars008",
    "timeISO": "2025-08-06T20:34:52.000Z",
    "textPlain": "Instead of fighting you can submit text advertising to LLM bots. And sell it. This 'knowledge' will be embedded into next models.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44816441,
    "by": "andreagrandi",
    "timeISO": "2025-08-06T19:20:14.000Z",
    "textPlain": "Another one not having a clue about what “consent” means. Next?",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817213,
    "by": "blindriver",
    "timeISO": "2025-08-06T20:18:02.000Z",
    "textPlain": "This article is stupid.You write content so that you get paid, usually through ads and clicks. If people aren't seeing your content because am LLM has consumed it and is regurgitating it and taking your ad clicks, then there's no benefit for you only for the LLM. You're doing the work of Sam Altman and helping him attain his multibillionaire status and you get nothing in return.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815820,
    "by": "jkingsman",
    "timeISO": "2025-08-06T18:32:16.000Z",
    "textPlain": "> how many of you wouldn’t hook up your website to Google?If there was a paid-only search engine with dubious ethics practices that was overwhelming my site with traffic in order resell search trained off of (among other things) my personally generated content, I would absolute block it.LLMs are not search engines, and I'm not gaining any followers or customers in any meaningful way because an LLM indexes my site.> it also cuts you off from the fastest-growing distribution channel on the web.I haven't seen the needle tip at all in my acquisition channels from LLMs. Unless you're a household name or very large, LLMs aren't going to shill for your business.> most LLMs have an agentic web-search component that will actively generate linksTotally. Which is why I don't care if the LLMs index it. Let web content search be good, and lead LLMs to good content; product placement in LLM weights ain't what I'm gonna optimize for, or even permit, if it comes at a cost to me and my infra.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817141,
    "by": "acrispino",
    "timeISO": "2025-08-06T20:13:38.000Z",
    "textPlain": "Why was the link title changed?",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817295,
    "by": "stego-tech",
    "timeISO": "2025-08-06T20:22:19.000Z",
    "textPlain": "Good, because this “next generation search” doesn’t cite sources, invents falsehoods, steals content, and doesn’t direct traffic to the site in question, which was the whole point of search engines in the first place.The fact LLM companies constantly keep getting dinged for ignoring every barrier we throw up to stop their scraping short of something like Anubis shows what their real goal is: theft, monopolization, and reality authoring.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817589,
    "by": "altairprime",
    "timeISO": "2025-08-06T20:43:27.000Z",
    "textPlain": "Good.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44816669,
    "by": "watwut",
    "timeISO": "2025-08-06T19:38:09.000Z",
    "textPlain": "The whole thing about LLM is training on content other people created, redirecting that traffic to you and ultimately earn money on it. The whole thing about LLM being pushed everywhere is to get free training data too.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815859,
    "by": "lambdadelirium",
    "timeISO": "2025-08-06T18:35:41.000Z",
    "textPlain": "Stupid bait post",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815830,
    "by": "calyth2018",
    "timeISO": "2025-08-06T18:33:17.000Z",
    "textPlain": "Even if we take the argument at face value, we should allow LLMs to train their models for free, on the backs of real people's work, just so that there's a chance that they actually improved well enough to replace humans, all that just to have a temporary boost on search discovery of our content.Not to mention LLMs still spew a lot of badly wrong results (no I will not anthropomorphize the models, they're not ready yet).This is one heck of a poison chalice. 王先生，你願意喝這杯鶴酒嗎？",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44816024,
    "by": "frozenseven",
    "timeISO": "2025-08-06T18:49:16.000Z",
    "textPlain": "Why was this flagged? A difference in opinion is no excuse for censorship.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44816965,
    "by": "skywhopper",
    "timeISO": "2025-08-06T20:00:59.000Z",
    "textPlain": "This article is based on the false assumption that use of a site by an LLM directs any user traffic to it whatsoever.Why would anyone choose to anonymously and freely provide content to LLMs? Actually the only use case for that is deliberately seeding misinformation. Which is likely already happening and will soon be the majority of the content accessible to LLMs regardless of what blocking legitimate content providers choose to use.",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44815894,
    "by": "girriPal",
    "timeISO": "2025-08-06T18:38:17.000Z",
    "textPlain": "[dead]",
    "parent": 44815125,
    "depth": 1
  },
  {
    "id": 44817143,
    "by": "SideburnsOfDoom",
    "timeISO": "2025-08-06T20:13:41.000Z",
    "textPlain": "I don't know what you mean ... by including \"eventually\" in that sentence.",
    "parent": 44815839,
    "depth": 2
  },
  {
    "id": 44820652,
    "by": "sshine",
    "timeISO": "2025-08-07T04:44:27.000Z",
    "textPlain": "> If there was a paid-only search engine with dubious ethics practices that was overwhelming my site with traffic in order resell search trained off of (among other things) my personally generated content, I would absolute block it.Let’s compare Google with OpenAI:Paid-only: neither check; both have free tiers, eventually supported by ads (Google took 10+ years before it got littered with ads, I promise OpenAI will make the ad experience even stinkier because they keep you on the site as opposed to Google who only have you for a few seconds. The ads will be blinky, and they will be nested into the content.Dubious ethics: both check.Overwhelming bot traffic: both check.Make money on your content: both check.> LLMs are not search engines, and I'm not gaining any followers or customers in any meaningful way because an LLM indexes my site.So paywall it?The Anubis PoW captcha is an option, too. Then you will block trainers and allow agents.",
    "parent": 44815820,
    "depth": 2
  },
  {
    "id": 44816632,
    "by": "bufferoverflow",
    "timeISO": "2025-08-06T19:35:19.000Z",
    "textPlain": "[dead]",
    "parent": 44815820,
    "depth": 2
  },
  {
    "id": 44820711,
    "by": "sshine",
    "timeISO": "2025-08-07T04:53:31.000Z",
    "textPlain": "> this “next generation search” doesn’t cite sourcesThe training done on the content does not provide citable references with current models. The agentic search and summary done post-training does.A lot of the heavy traffic is for training, though, because AI companies are in competition for large amounts of training data.",
    "parent": 44817295,
    "depth": 2
  },
  {
    "id": 44817402,
    "by": "cactusplant7374",
    "timeISO": "2025-08-06T20:30:39.000Z",
    "textPlain": "If your website is included in next gen search and the user asks for a source, then your website as a source will be included.",
    "parent": 44817295,
    "depth": 2
  },
  {
    "id": 44817399,
    "by": "BoorishBears",
    "timeISO": "2025-08-06T20:30:31.000Z",
    "textPlain": "It cites sources and while it generates less traffic, that traffic converts significantly better",
    "parent": 44817295,
    "depth": 2
  },
  {
    "id": 44816752,
    "by": "debugnik",
    "timeISO": "2025-08-06T19:42:58.000Z",
    "textPlain": "When I asked dang about why are very low quality submissions allowed despite them resulting in low quality discussion, he told me and I quote:> You can flag submissions that you think don't belong on Hacker News.Well, this is a very low quality submission in my eyes. A tiny read with an unsubstantiated, purely contrarian take that completely misses the point of the debate. Just to be clear, I think anyone is free to post anything on their blogs, that's what they're for, but I don't think posts like these contribute to HN having a good atmosphere for discussion; if I were to write something like this, I'd be ok with it being unsuitable for HN.BTW I hadn't flagged this before reading your comment. I've done so after reading the submission though.",
    "parent": 44816024,
    "depth": 2
  }
]