[
  {
    "id": 44842100,
    "by": "artisin",
    "timeISO": "2025-08-08T21:58:09.000Z",
    "textPlain": "Maybe it's just me, but…> \"The attack successfully guided the new model to produce a step-by-step manual for creating a Molotov cocktail\"hardly qualifies as Bond-villain material",
    "parent": 44840973,
    "depth": 1
  },
  {
    "id": 44842183,
    "by": "king_geedorah",
    "timeISO": "2025-08-08T22:07:18.000Z",
    "textPlain": "I don’t see anything in the article besides the jailbreaking in terms of faults and I’d expect “can be made to do things OpenAI does not want you to make it do” to be a good (or at least neutral) thing for users and a bad thing for OpenAI. I expect “enterprise” to fall into the former category rather than the latter, so I don’t understand where the unusable claim comes from.What have I missed or what am I misunderstanding?",
    "parent": 44840973,
    "depth": 1
  },
  {
    "id": 44842056,
    "by": "ath3nd",
    "timeISO": "2025-08-08T21:52:14.000Z",
    "textPlain": "[flagged]",
    "parent": 44840973,
    "depth": 1
  },
  {
    "id": 44842324,
    "by": "andy99",
    "timeISO": "2025-08-08T22:25:58.000Z",
    "textPlain": "The molotov cocktail example is so stupid, because how to make it is essentially entailed in knowing what it is. At least they could do making meth, or better still- something not readily found on the internet that gives a non-expert new capabilities. If there was a Claude code for crime, that wouldn't be in society's interest. As it is, these trivial examples are just testing the strength of built in refusals, and should be represented as such, instead of anything related to safety.",
    "parent": 44842100,
    "depth": 2
  },
  {
    "id": 44842476,
    "by": "nerdsniper",
    "timeISO": "2025-08-08T22:46:33.000Z",
    "textPlain": "“AI Safety” is really about whether its “safe” (economically, legally, reputationally) for a third partyy corporation (not the company which created the model) to let customers/the public interact with them via an AI interface.If a Mastercard AI talks with customers and starts saying the n-word, it’s not “safe” for Mastercard to use that in a public-facing role.As org size increases, even purely internal uses could be legally/reputationally hazardous.",
    "parent": 44842183,
    "depth": 2
  }
]