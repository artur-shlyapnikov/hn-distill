[
  {
    "id": 44798605,
    "by": "simonw",
    "timeISO": "2025-08-05T14:41:45.000Z",
    "textPlain": "I found myself agreeing with quite a lot of this article.I'm a pretty huge proponent for AI-assisted development, but I've never found those 10x claims convincing. I've estimated that LLMs make me 2-5x more productive on the parts of my job which involve typing code into a computer, which is itself a small portion of that I do as a software engineer.That's not too far from this article's assumptions. From the article:> I wouldn't be surprised to learn AI helps many engineers do certain tasks 20-50% faster, but the nature of software bottlenecks mean this doesn't translate to a 20% productivity increase and certainly not a 10x increase.I think that's an under-estimation - I suspect engineers that really know how to use this stuff effectively will get more than a 0.2x increase - but I do think all of the other stuff involved in building software makes the 10x thing unrealistic in most cases.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44804091,
    "by": "voxleone",
    "timeISO": "2025-08-05T20:50:42.000Z",
    "textPlain": "There’s something ironic here. For decades, we dreamed of semi-automating software development. CASE tools, UML, and IDEs all promised higher-level abstractions that would \"let us focus on the real logic.\"Now that LLMs have actually fulfilled that dream — albeit by totally different means — many devs feel anxious, even threatened. Why? Because LLMs don’t just autocomplete. They generate. And in doing so, they challenge our identity, not just our workflows.I think Colton’s article nails the emotional side of this: imposter syndrome isn’t about the actual 10x productivity (which mostly isn't real), it’s about the perception that you’re falling behind. Meanwhile, this perception is fueled by a shift in what “software engineering” looks like.LLMs are effectively the ultimate CASE tools — but they arrived faster, messier, and more disruptively than expected. They don’t require formal models or diagrams. They leap straight from natural language to executable code. That’s exciting and unnerving. It collapses the old rites of passage. It gives power to people who don’t speak the “sacred language” of software. And it forces a lot of engineers to ask: What am I actually doing now?",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798571,
    "by": "generalizations",
    "timeISO": "2025-08-05T14:39:50.000Z",
    "textPlain": "In many ways this feels like average software engineers telling on themselves. If you know the tech you're building, and you're good at splitting up your work, then you know ahead of time where the complexity is and you can tell the AI what level of granularity to build at. AI isn't magic; there is an upper limit to the complexity of a program that e.g. Sonnet 4 can write at once. If you can grok that limit, and you can grok the tech of your project, then you can tell the AI to build individual components that stay below that threshold. That works really well.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798771,
    "by": "megaloblasto",
    "timeISO": "2025-08-05T14:51:50.000Z",
    "textPlain": "I thought this would be another AI hate article, but it made some great points.One thing that AI has helped me with is finding pesky bugs. I mainly work on numerical simulations. At one point I was stuck for almost a week trying to figure out why my simulation was acting so strange. Finally I pulled up chatgpt, put some of my files into the context and wrote a prompt explaining the strange behavior and what I thought might be happening. In a few seconds it figured out that I had improperly scaled one of my equations. It came down to a couple missing parentheses, and once I fixed it the simulation ran perfectly.This has happened a few times where AI was easily able to see something I was overlooking. Am I a 10x developer now that I use AI? No... but when used well, AI can have a hugely positive impact on what I am able to get done.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44810594,
    "by": "allanmacgregor",
    "timeISO": "2025-08-06T11:30:04.000Z",
    "textPlain": "I'm skeptical of the 10x claims for different reasons than the author focuses on. The productivity gains might be real for individual tasks, but they're being measured wrong.Most of the AI productivity stories I hear sound like they're optimizing for the wrong metric. Writing code faster doesn't necessarily mean shipping better products faster. In my experience, the bottleneck is rarely \"how quickly can we type characters into an editor\" - it's usually clarity around requirements, decision-making overhead, or technical debt from the last time someone optimized for speed over maintainability.The author mentions that real 10x engineers prevent unnecessary work rather than just code faster. That rings true to me. I've seen more productivity gains from saying \"no\" to features or talking teams out of premature microservices(or adopting Kafka :D) than from any coding tool.What worries me more is the team dynamic this creates. When half your engineers feel like they're supposed to be 10x more productive and aren't, that's a morale problem that compounds. The engineers who are getting solid 20-30% gains from AI (which seems realistic) start questioning if they're doing it wrong.Has anyone actually measured this stuff properly in a production environment with consistent teams over 6+ months? Most of the data I see is either anecdotal or from artificial coding challenges.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799032,
    "by": "Glyptodon",
    "timeISO": "2025-08-05T15:11:08.000Z",
    "textPlain": "I don't consider myself a 10x engineer. The number one thing that I've realized makes me more productive than other engineers at my company is thinking through system design and business needs with patterns that don't take badly written product tickets literally.What I've seen with AI is that it does not save my coworkers from the pain of overcomplicating simple things that they don't really think through clearly. AI does not seem to solve this.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798497,
    "by": "tptacek",
    "timeISO": "2025-08-05T14:34:18.000Z",
    "textPlain": "This article sets a ludicrous bar (\"10x\"), then documents the author's own attempt  over some indeterminate time to clear that bar. As a result, the author has classified all the AI-supporters in the industry into three categories: (1) people who are wrong in good faith, (2) people who are selling AI tools, and (3) evil bosses trying to find leverage in programmer anxiety.That aside: I still think complaining about \"hallucination\" is a pretty big \"tell\".",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799659,
    "by": "lordnacho",
    "timeISO": "2025-08-05T15:54:15.000Z",
    "textPlain": "I'm getting a lot of side-quest productivity out of AI. There's always a bunch of things I could do, but they are tedious. Yet they are still things I wish I could get done. Those kinds of things AI is fantastic at. Building a mock, making tests, abstracting a few things into libraries, documentation.So it's not like I'm delivering features in one day that would have taken two weeks. But I am delivering features in two weeks that have a bunch of extra niceties attached to them. Reality being what it is, we often release things before they are perfect. Now things are a bit closer to perfect when they are released.I hope some of that extra work that's done reduces future bug-finding sessions.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798491,
    "by": "simpaticoder",
    "timeISO": "2025-08-05T14:34:13.000Z",
    "textPlain": "The expectations are higher than reality, but LLMs are quite useful in many circumstances. You can characterize their use by \"level of zoom\", from \"vibe coding\" on the high end, to \"write this function given its arguments and what it should return\" at the low end. The more 'zoomed in' you are, the better it works, in my experience.Plus there are use-cases for LLMs that go beyond augmenting your ability to produce code, especially for learning new technologies. The yield depends on the distribution of tasks you have in your role. For example, if you are in lots of meetings, or have lots of administrative overhead to push code, LLMs will help less. (Although I think applying LLMs to pull request workflow, commit cleanup and reordering, will come soon).",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44800474,
    "by": "TrackerFF",
    "timeISO": "2025-08-05T16:45:22.000Z",
    "textPlain": "Say you want to create a web app, but you don't know any web dev. You spend a couple of months reading front-end and back-end dev, incrementally create something, and after half a year you've made a web app you like. Say you spent 4 hours a day, 5 days a week, for 6 weeks, going from zero to a functional web app. So you spent 120 hours in total.Now let's say you use Claude code, or whatever, and you're able to create the same web app over a weekend. You spend 6 hours a day on Saturday and Sunday, in total 12 hours.That's 10x increase in productivity right there. Did it make you a 10x better programmer? Nope, probably not. But your productivity went up by a tenfold.And at least to me, that's sort of how it has worked. Things I didn't have motivation or energy to get into before, I can get into over a weekend.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798729,
    "by": "izzydata",
    "timeISO": "2025-08-05T14:49:34.000Z",
    "textPlain": "I don't believe that literal typing of code is the limiting factor in development work. There is the research and planning and figuring out what it is even you need to develop in the first place. By the time you know what questions to even ask an LLM you are not saving much time in my opinion. On top of that you introduce the risk of LLM hallucination when you could have looked it up from a normal web search yourself in slightly more time.Overall it feels negligible too me in its current state.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798568,
    "by": "efields",
    "timeISO": "2025-08-05T14:39:43.000Z",
    "textPlain": "In a week, Claude Code and I have built a PoC Rails App for a significant business use case. I intend to formally demo it for buy-in tomorrow after already doing a short \"is this kind of what you're looking for?\" walkthrough last week. From here, I intend to \"throw it over the fence\" for my staff, RoR and full-stack devs, to pick it apart and/or improve what they want to in order to bring it from 80-100% over the next two months. If they want to rewrite it from scratch, that's on the table.It's not a ground-breaking app, its CRUD and background jobs and CSV/XLSX exports and reporting, but I found that I was able to \"wireframe\" with real code and thus come up with unanswered questions, new requirements, etc. extremely early in the project.Does that make me a 10x engineer? Idk. If I wasn't confident working with CC, I would have pushed back on the project in the first place unless management was willing to devote significant resources to this. I.e. \"is this really a P1 project or just a nice to have?\" If these tools didn't exist I would have written spec's and excalidraw or Sketch/Figma wireframes that would have taken me at least the same amount of time or more, but there'd be less functional code for my team to use as a resource.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44800601,
    "by": "nathan_compton",
    "timeISO": "2025-08-05T16:53:26.000Z",
    "textPlain": "I use AI all the time. Usually I'm a curmudgeon but I decided to go all in on LLM AI stuff and have used ChatGPT and other models extensively to write code. Having thought about it a lot, I think the magic here is that AI combines three things:1. googling stuff about how APIs work\n2. writing boilerplate\n3. typing syntax correctlyThese three things combined make up a huge amount of programming. But when real cognition is required I find I'm still thinking just as hard in basically the same ways I've always thought about programming: identifying appropriate abstractions, minimizing dependencies between things, pulling pieces together towards a long term goal. As far as I can tell, AI still isn't really capable of helping much with this. It can even get in the way, because writing a lot of code before key abstractions are clearly understood can be counterproductive and AI tends to have a monolithic rather than decoupled understanding of how to program. But if you use it right it can make certain tasks less boring and maybe a little faster.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44806259,
    "by": "lemonwaterlime",
    "timeISO": "2025-08-06T00:29:05.000Z",
    "textPlain": "I'm consistently baffled at why software engineering is the only engineering to obsess over a mythical \"10x\" contributor. Mechanical, electrical, civil, and chemical engineers do not have this concept.What makes an excellent engineer is risk mitigation and designing systems under a variety of possible constraints. This design is performed using models of the domains involved and understanding when and where these models hold and where they break down. There's no \"10x\". There is just being accountable for designing excellent systems to perform as desired.If there were a \"10x\" software engineer, such an engineer would prevent data breaches from occurring, which is a common failure mode in software to the detriment of society. I want to see 10x less of that.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799744,
    "by": "zaking17",
    "timeISO": "2025-08-05T15:59:06.000Z",
    "textPlain": "The other day I asked chatgpt (o3) to help me compare a bunch of task orchestration systems and arrange them according to some variables I care about (popularity, feature richness, durability, whether can be self-hosted, etc.). I ended up using https://www.inngest.com/ -- which was new to me -- and that single tool sped up my particular task by at least 10x for the week. That was a one-off project, so it won't generalize in a clean way, but I keep finding individual cases where the particular strengths of LLMs can save me a whole bunch of time. (another example: creating and evaluating responses to technical interview questions). I don't expect that these are easy to quantify, but they are significant.This is not to disagree with the OP, but to point out that, even for engineers, the speedups might not appear where you expect. [EDIT I see like 4 other comments making the same point :)]",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44801579,
    "by": "itissid",
    "timeISO": "2025-08-05T17:50:17.000Z",
    "textPlain": "A few things need to happen very soon(if the signs are not here already):1. Tech Company's should be able to accelerate and supplant the FAANGs of this world. Like even if 10x was discounted to 5x. It would mean that 10 human years of work would be shrunk down to 2 to make multi-billion dollar companies. This is not happening right now. If this does not start happening with the current series of model, murphy's law (e.g. interest rate spike at some point) or just damn show me the money brutal questions would tell people if it is \"working\".2. I think Anthropic's honcho did a back of the envelope number of 600$ for every human in the US(I think just it was just the US) was necessary to justify Nvidia's market Cap. This should play out by the end of this year or in Q3 report.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799028,
    "by": "swader999",
    "timeISO": "2025-08-05T15:10:56.000Z",
    "textPlain": "This was the best insight in the article: Do 10x engineers actually exist? \"This debate isn't something I want to weigh in on but I might have to. My answer is sometimes, kinda. When I have had engineers who were 10x as valuable as others it was primarily due to their ability to prevent unnecessary work. Talking a PM down from a task that was never feasible. Getting another engineer to not build that unnecessary microservice. Making developer experience investments that save everyone just a bit of time on every task. Documenting your work so that every future engineer can jump in faster. These things can add up over time to one engineer saving 10x the time company wide than what they took to build it.\"So true, a lot of value and gains are had when tech leads can effectively negotiate and creatively offer less costly solutions to all aspects of a feature.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44814640,
    "by": "Fuhrmanator",
    "timeISO": "2025-08-06T17:01:23.000Z",
    "textPlain": "I recently experimented with Gemini on Colab for building a discrete simulation in Python—initially started with ChatGPT, then moved platforms due to free-tier limits. Gemini was responsive in analyzing graph outputs and made quick progress with rapid prototyping. However, when I shifted focus to refactoring and improving code structure, e.g., extracting classes and encapsulating behavior, it defaulted to a weird hybrid class/functional approach, often placing logic outside domain objects rather than applying polymorphism. Even after I explicitly mentioned principles like \"Tell, don’t ask,\" I had to insist before it adjusted its design choices accordingly. I asked why those principles are NOT there by default, and it said basically most coders don't use them and it seeks direct solutions.While Gemini performed well in tweaking visualizations (it even understood the output of matplotlib) and responding to direct prompts, it struggled with debugging and multi-step refactorings, occasionally failing with generic error messages. My takeaway is that these tools are incredibly productive for greenfield coding with minimal constraints, but when it comes to making code reusable or architecturally sound, they still require significant human guidance. The AI doesn’t prioritize long-term code quality unless you actively steer it in that direction.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799722,
    "by": "adocomplete",
    "timeISO": "2025-08-05T15:57:53.000Z",
    "textPlain": "AI is making me 100x productive in some tasks, and 2-4x in others, and 0x in some. Knowing which tasks AI is great at and delegating is like 95% of the battle.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798577,
    "by": "siva7",
    "timeISO": "2025-08-05T14:40:24.000Z",
    "textPlain": "I beg to differ. My diffs are 10x bigger than before though i don't have any more time to review them.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44808682,
    "by": "clauderoux",
    "timeISO": "2025-08-06T07:10:43.000Z",
    "textPlain": "This article nails it. The claim 10x is in my opinion one of these tactics used by large corporations to force engineers into submission. The idea that you could be replaced with an AI is frightening enough to keep people in check, when negotiating your salary.  AI is a wonderful tool that I use everyday, and I have been able to implement stuff that I would have considered too cumbersome to even start working on. But, it doesn't make you a 10x more efficient engineer. It gives you an edge when you start a new project, which is already a lot. But don't expect your whole project of 100,000 lines to be handled by the machine. It won't happen any time soon.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798334,
    "by": "jf22",
    "timeISO": "2025-08-05T14:23:19.000Z",
    "textPlain": "> What LLMs produce is often broken, hallucinated, or below codebase standards.With enough rules and good prompting this is not true. The code I generate is usually better than what I'd do by hand.The reason the code is better all the extra polish and gold plating is essentially free.Everything I generate comes out commented great error handling, logging, SOLID, and united tested using established patterns in the code base.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799177,
    "by": "dowager_dan99",
    "timeISO": "2025-08-05T15:21:24.000Z",
    "textPlain": "I am a dinosaur but still feel strongly enough to post this PSA: please go back and read \"No Silver Bullet\" (and his follow up) again. You should probably schedule a re-read every 2-5 years, just to keep your sanity in these crazy, exhausting times.I believe his original thesis remains true: \"There is no single development, in either technology or management technique, which by itself promises even one order-of-magnitude improvement within a decade in productivity, in reliability, in simplicity.\"Over the years this has been misrepresented or misinterpreted to suggest it's false but it sure feels like \"Agentic Coding\" is a single development promising a massive multiplier in improvement that once again is, another accidental tool that can be helpful but is definitely not a silver bullet.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799531,
    "by": "paulhodge",
    "timeISO": "2025-08-05T15:46:35.000Z",
    "textPlain": "I've had days where it really does feel like 5x or 10x...Here's what the 5x to 10x flow looks like:1. Plan out the tasks (maybe with the help of AI)2. Open a Git worktree, launch Claude Code in the worktree, give it the task, let it work. It gets instructions to push to a Github pull request when it's done. Claude gets to work. It has access to a whole bunch of local tools, test suites, and lots of documentation.3. While that terminal is running, I go start more tasks. Ideally there are 3 to 5 tasks running at a time.4. Periodically check on the tabs to make sure they're not stuck or lost their minds.5. Finally, review the finished pull requests and merge them when they are ready. If they have issues then go back to the related chat and tell it to work on it some more.With that flow it's reasonable to merge 10 to 20 pull requests every day. I'm sure someone will respond \"oh just because there are a lot of pull requests, doesn't mean you are productive!\" I don't know how to prove to you that the PRs are productive other than just say that they are each basically equivalent to what one human does in one small PR.A few notes about the flow:- For the AI to work independently, it really needs tasks that are easy to medium difficulty. There are definitely 'hard' tasks that need a lot of human attention in order to get done successfully.- This does take a lot of initial investment in tooling and documentation. Basically every \"best practice\" or code pattern that you want to use use in the project must be written down. And the tests must be as extensive as possible.Anyway the linked article talks about the time it takes to review pull requests. I don't think it needs to take that long, because you can automate a lot..- Code style issues are fully automated by the linter.- Other checks like unit test coverage can be checked in the PR as well.- When you have a ton of automated tests that are checked in the PR, that also reduces how much you need to worry about as a code revie",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44800933,
    "by": "hintymad",
    "timeISO": "2025-08-05T17:13:24.000Z",
    "textPlain": "I think AI is going to make senior engineers at big tech companies 10x more productive.A lot of senior engineers in the big tech companies spend most of their time in meetings. They're still brilliant. For instance, they read papers and map out the core ideas, but they haven't been in the weeds for a long time. They don't necessarily know all the day-to-day stuff anymore.Things like: which config service is standard now? What's the right Terraform template to use? How do I write that gnarly PromQL query? How do I spin up a new service that talks to 20 different systems? Or in general, how do I map my idea to deployable and testable code in the company's environment?They used to have to grab a junior engineer to handle all that boilerplate and operational work. Now, they can just use an AI to bridge that gap and build it themselves.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44802348,
    "by": "quaintdev",
    "timeISO": "2025-08-05T18:40:37.000Z",
    "textPlain": "Interesting that title of this post was changed. I think I have seen this happening 2nd time now. It seems Hacker News does not favor AI negative narratives.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799252,
    "by": "OutputRiff",
    "timeISO": "2025-08-05T15:27:38.000Z",
    "textPlain": "I find myself largely agreeing with this post.In some cases, LLMs can be a real speed boost. Most of the time, that has to do with writing boilerplate and prototyping a new \"thing\" I want to try out.Inevitably, if I like the prototype, I end up re-writing large swaths of it to make it even half way productizable. Fundamentally, LLMs are bad at keeping an end goal in mind while working on a specific feature and it's terrible at holding enough context to avoid code duplication and spaghetti.I'd like to see them get better and better, but they really are limited to whatever code they can ingest on the internet. A LOT of important code is just not open for consumption in sufficient quantities for it to learn. For this reason, I suspect LLMs will really never be all that good for non-web based engineering. Wheres all the training data gonna come from?",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44804771,
    "by": "abhinuvpitale",
    "timeISO": "2025-08-05T21:43:22.000Z",
    "textPlain": "Such an insightful article. The tools are allowing us to 10x-100x productivity in shorter bursts, which makes total sense. There's a lot more to software engineering beyond those bits, and that's why the 10x engineer imposter syndrome.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798790,
    "by": "nimos",
    "timeISO": "2025-08-05T14:53:52.000Z",
    "textPlain": "Claude max is $200 a month.Consider a fully loaded cost of 200k for an engineer or $16,666 per month. They only have to be >1.012x engineer for the \"AI\" to be worth it. Of course that $200 dollars per month is probably VC subsidized right now but there is lots of money on the table for <2x improvement.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44800419,
    "by": "HarHarVeryFunny",
    "timeISO": "2025-08-05T16:41:49.000Z",
    "textPlain": "There was a recent study concluding that AI made experienced developers 20% SLOWER to complete tasks rather than any faster !https://arxiv.org/abs/2507.09089Obviously it depends on what you are using the AI to do, and how good a job you do of creating/providing all the context to give it the best chance of being successful in what you are asking.Maybe a bit like someone using a leaf blower to blow a couple of leaves back and forth across the driveway for 30 sec rather than just bending down to pick them up.... It seems people find LLMs interesting, and want to report success in using them, so they'll spend a ton of time trying over and over to tweak the context and fix up what the AI generated, then report how great it was, even though it'd have been quicker to do it themselves.I think agentic AI may also lead to this illusion of, or reported, AI productivity ... you task an agent to do something and it goes off and 30 min later creates what you could have done in 20 min while you are chilling and talking to your workmates about how amazing this new AI is ...",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44803142,
    "by": "abelanger",
    "timeISO": "2025-08-05T19:34:23.000Z",
    "textPlain": "One thing I've been wondering recently: has the experience of using software (specifically web apps) been getting better? It seems like a natural extension of significantly increased productivity would lead to fewer buggy websites and apps, more intuitive UIs, etc.Linear was a very early-stage product I tested a few months after their launch where I was genuinely blown away by the polish and experience relative to their team size. That was in 2020, pre-LLMs.I have yet to see an equally polished and impressive early-stage product in the past few years, despite claims of 10x productivity.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799958,
    "by": "zahlman",
    "timeISO": "2025-08-05T16:13:15.000Z",
    "textPlain": "> When I have had engineers who were 10x as valuable as others it was primarily due to their ability to prevent unnecessary work. Talking a PM down from a task that was never feasible. Getting another engineer to not build that unnecessary microservice. Making developer experience investments that save everyone just a bit of time on every task. Documenting your work so that every future engineer can jump in faster. These things can add up over time to one engineer saving 10x the time company wide than what they took to build it.What about just noticing that coworkers are repeatedly doing something that could easily be automated?",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798937,
    "by": "bilsbie",
    "timeISO": "2025-08-05T15:04:24.000Z",
    "textPlain": "I’m actually infinity more productive because I wouldn’t start projects without AI. (Just lazy and burned out from the tedium of codin g) but I’m enjoying it if the AI does a lot of the tedium.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44808844,
    "by": "lmeyerov",
    "timeISO": "2025-08-06T07:32:01.000Z",
    "textPlain": "It took me a month , despite having done prompt engineering for work the 2 years prior, to hit the real starting line of Claude code productivityBasically, the ability to order my thoughts into a task list long & clear enough for the LLM to follow that I can be working on 3 or so of these in parallel, and maybe email. Any individual run may be faster or slower than I can do it manually, but critically, they take less total human time / attention.  No individual technique is fundamentally tricky here, but it is still a real skill.If you read the article, the author is simply not there, and sees what they know as only 1 weeks worth of knowledge. So for their learning rate .. maybe they need 3x longer of learning & experience?",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798526,
    "by": "lightweb",
    "timeISO": "2025-08-05T14:36:23.000Z",
    "textPlain": "LLMs still leave something to be desired for DevOps related work; infrastructure code. There is still not really enough context available when crossing the division between the hardware, OS, and software.For Terraform, specifically, Claude 4 can get thrown into infinite recursive loops trying to solve certain issues within the bounds of the language. Claude still tries to add completely invalid procedures into things like templates.It does seem to work a bit better for standard application programming tasks.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44808567,
    "by": "amichayg",
    "timeISO": "2025-08-06T06:54:04.000Z",
    "textPlain": "The core value of LLMs is simple: sometimes you need to write code, but what you really want is to design, experiment, or just get something usable.Even when you do write code, you often only care about specific aspects—you just want to automate the rest.This is hard to reconcile with modern business models. If you tell someone that a software engineer can also design, they’ll just fire the designer and pile more work on the engineer. But it doesn’t change the underlying truth: a single engineer who can touch many parts of the software with low cognitive friction is simply a better kind of engineer.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44819778,
    "by": "subtlesoftware",
    "timeISO": "2025-08-07T01:49:45.000Z",
    "textPlain": "The author focuses too much on the strawman of 10x engineer. If an engineer is even 2x more productive overall, that's a huge deal.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798685,
    "by": "Jcampuzano2",
    "timeISO": "2025-08-05T14:46:38.000Z",
    "textPlain": "The only people who get 10x productivity are people who are either:- solo projects- startups with few engineers doing very little intense code review if any at all- people who don't know how to code themselves.Nobody else is realistically able to get 10x multipliers. But that doesn't mean you can't get a 1.5-2x multiplier. I'd say even myself at a large company that moves slow have been able to realize this type of multiplier on my work using cursor/claude code. But as mentioned in the article the real bottleneck becomes processes and reviews. These have not gotten any faster - so in real terms time to ship/deliver isn't much different than before.The only attempt that we should make at minimizing review times is by making them higher priority than development itself. Technically this should already be the case but in my experience almost no engineer outside of really disciplined companies and not in FAANG actually makes reviews a high priority, because unfortunately code reviews are not usually part of someones performance review and slows down your own projects. And usually your project manager couldn't give two shits about someone elses work being slow.Processes are where we can make the biggest dent. Most companies as they get large have processes that get in the way of forward velocity. AI first companies will minimize anything that slows time to ship. Companies simply utilizing AI and expecting 10x engineers without actually putting in the work to rally around AI as a first class citizen will fall behind.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44799945,
    "by": "thephyber",
    "timeISO": "2025-08-05T16:12:39.000Z",
    "textPlain": "The important things to remember about these claims/articles is that LLMs are useful for a wide variety of tasks. An engineer doesn’t only code, but also has to learn, search, gather / define requirements, write tests, troubleshoot, read/review other people's code, deal with project management tools, document (both for developers and for customers).Also, one underestimated aspect is that LLMs don’t get writer’s block or get tired (so long as you can pay to keep the tokens flowing).Also, one of the more useful benefits of coding with LLMs is that you are explicitly defining the requirements/specs in English before coding. This effectively means LLM-first code is likely written via Behavior Driven Development, so it is easier to review, troubleshoot, upgrade. This leads to lower total cost of ownership compared to code which is just cowboyed/YOLOed into existence.",
    "parent": 44798189,
    "depth": 1
  },
  {
    "id": 44798562,
    "by": "2d8a875f-39a2-4",
    "timeISO": "2025-08-05T14:39:22.000Z",
    "textPlain": "Only vibe-coding influencers were ever talking about 10x multipliers.Internally we expected 15%-25%. A big-3 consultancy told senior leadership \"35%-50%\" (and then tried to upsell an AI Adoption project). And indeed we are seeing 15%-35% depending on which part of the org you look and how you measure the gains.",
    "parent": 44798189,
    "depth": 1
  }
]