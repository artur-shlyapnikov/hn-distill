[
  {
    "id": 44879004,
    "by": "henriquegodoy",
    "timeISO": "2025-08-12T17:00:14.000Z",
    "textPlain": "Looking at this evaluation it's pretty fascinating how badly these models perform even on decades old games that almost certainly have walkthroughs scattered all over their training data. Like, you'd think they'd at least brute force their way through the early game mechanics by now, but honestly this kinda validates something I've been thinking about like real intelligence isn't just about having seen the answers before, it's about being good at games and specifically new situations where you can't just pattern match your way outThis is exactly why something like arc-agi-3 feels so important right now. Instead of static benchmarks that these models can basically brute force with enough training data, like designing around interactive environments where you actually need to perceive, decide, and act over multiple steps without prior instructions, that shift from \"can you reproduce known patterns\" to \"can you figure out new patterns\" seems like the real test of intelligence.What's clever about the game environment approach is that it captures something fundamental about human intelligence that static benchmarks miss entirely, like, when humans encounter a new game, we explore, form plans, remember what worked, adjust our strategy all that interactive reasoning over time that these text adventure results show llms are terrible at, we need systems that can actually understand and adapt to new situations, not just really good autocomplete engines that happen to know a lot of trivia.",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44879366,
    "by": "andai",
    "timeISO": "2025-08-12T17:25:21.000Z",
    "textPlain": "The GPT-5 used here is the Chat version, presumably gpt‑5‑chat‑latest, which from what I can tell is the same version used in ChatGPT, which is not actually a model but a \"system\" -- a router that semi-randomly forwards your request to various different models (in a way designed to massively reduce costs for OpenAI, based on people reporting inconsistent output and often worse results than 4o).So from this it seems that not only would many of these requests not touch a reasoning model (or as it works now, have reasoning set to \"minimal\"?), but they're probably being routed to a mini or nano model?It would make more sense, I think, to test on gpt-5 itself (and ideally the -mini and -nano as well), and perhaps with different reasoning effort, because that makes a big difference in many evals.EDIT: Yeah the Chat router is busted big time. It fails to apply thinking even for problems that obviously call for it (analyzing financial reports). You have to add \"Think hard.\" to the end of the prompt, or explicitly switch to the Thinking model in the UI.",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44878951,
    "by": "SquibblesRedux",
    "timeISO": "2025-08-12T16:56:22.000Z",
    "textPlain": "This is another great example of how LLMs are not really any sort of AI, or even proper knowledge representation. Not saying they don't have their uses (like souped up search and permutation generators), but definitely not something that resembles intelligence.",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44878756,
    "by": "andrewla",
    "timeISO": "2025-08-12T16:41:56.000Z",
    "textPlain": "The article links to a previous article discussing methodology for this. The prompting is pretty extensive.It is difficult here to separate out how much of this could be fixed or improved by better prompting. A better baseline might be to just give the LLM direct access to the text adventure, so that everything the LLM replies is given to the game directly. I suspect that the LLMs would do poorly on this task, but would undoubtedly improve over time and generations.EDIT: Just started playing 9:05 with GPT-4 with no prompting and it did quite poorly; kept trying to explain to me what was going on with the ever more complex errors it would get. Put in a one line \"You are playing a text adventure game\" and off it went -- it took a shower and got dressed and drove to work.",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44878665,
    "by": "jameshart",
    "timeISO": "2025-08-12T16:34:43.000Z",
    "textPlain": "Nothing in the article mentioned how good the LLMs were at even entering valid text adventure commands into the games.If an LLM responds to “You are standing in an open field west of a white house” with “okay, I’m going to walk up to the house”, and just gets back “THAT SENTENCE ISN'T ONE I RECOGNIZE”, it’s not going to make much progress.",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44878740,
    "by": "lottaFLOPS",
    "timeISO": "2025-08-12T16:40:39.000Z",
    "textPlain": "related research that was also announced this week: https://www.textquests.ai/",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44877430,
    "by": "throwawayoldie",
    "timeISO": "2025-08-12T15:21:30.000Z",
    "textPlain": "My takeaway is: LLMs are not great at text adventures, even when those text adventures are decades old and have multiple walkthroughs available on the Internet. Slow clap.",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44878659,
    "by": "benlivengood",
    "timeISO": "2025-08-12T16:34:20.000Z",
    "textPlain": "Wouldn't playthroughs for these games be potentially in the pretraining corpus for all of these models?",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44878703,
    "by": "fzzzy",
    "timeISO": "2025-08-12T16:37:33.000Z",
    "textPlain": "I tried this earlier this year. I wrote a tool that let an llm play Zork. It was pretty fun.",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44879196,
    "by": "wiz21c",
    "timeISO": "2025-08-12T17:11:41.000Z",
    "textPlain": "adventure games require spatial reasoning (although text based), requires understanding  puns, requires cultural references, etc. For me they really need human-intelligence to be solved (heck, they've been designed like that).I find it funny that some AI do very good score on ARC-AI but fails at these games...",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44877814,
    "by": "the_af",
    "timeISO": "2025-08-12T15:44:21.000Z",
    "textPlain": "I know they define \"achievements\" in order to measure \"how well\" the LLM plays the game, and by definition this is arbitrary. As an experiment, I cannot argue with this.However, I must point out the kind of \"modern\" (relatively speaking) adventure games mentioned in the article -- which are more accurately called \"interactive fiction\" by the community -- is not very suitable for this kind of experiment. Why? Well, because so many of them are exploratory/experimental, and not at all about \"winning\" (unlike, say, \"Colossal Cave Adventure\", where there is a clear goal).You cannot automate (via LLM) \"playing\" them, because they are all about the thoughts and emotions (and maybe shocked laughter) they elicit in human players. This cannot be automated.If you think I'm being snobby, consider this: the first game TFA mentions is \"9:05\". Now, you can set goals for a bot to play this game, but truly -- if you've played the game -- you know this would be completely missing the point. You cannot \"win\" this game, it's all about subverting expectations, and about replaying it once you've seen the first, most straightforward ending, and having a laugh about it.Saying more will spoil the game :)(And do note there's no such thing as \"spoiling a game\" for an LLM, which is precisely the reason they cannot truly \"play\" these games!)",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44877542,
    "by": "ForHackernews",
    "timeISO": "2025-08-12T15:26:32.000Z",
    "textPlain": "What blogging software is this with the sidenotes?",
    "parent": 44877404,
    "depth": 1
  },
  {
    "id": 44879607,
    "by": "da_chicken",
    "timeISO": "2025-08-12T17:46:46.000Z",
    "textPlain": "I saw it somewhere else recently, but the idea is that LLMs are language models, not world models. This seems like a perfect example of that. You need a world model to navigate a text game.Otherwise, how can you determine that \"North\" is a context change, but not always a context change.",
    "parent": 44879004,
    "depth": 2
  },
  {
    "id": 44879591,
    "by": "msgodel",
    "timeISO": "2025-08-12T17:45:51.000Z",
    "textPlain": "I've been experimenting with this as well with the goal of using it for robotics. I don't think this will be as hard to train for as people think though.It's interesting he wrote a separate program to wrap the z-machine interpreter. I integrated my wrapper directly into my pytorch training program.",
    "parent": 44879004,
    "depth": 2
  },
  {
    "id": 44879755,
    "by": "kqr",
    "timeISO": "2025-08-12T17:59:06.000Z",
    "textPlain": "This is correct, and was the reason I made sure to always append \"Chat\" to the end of \"GPT-5\". I should perhaps have been more clear about this. The reason I settled for the lesser router is I don't have access to the full GPT-5, which would have been a much better baseline, I agree.",
    "parent": 44879366,
    "depth": 2
  },
  {
    "id": 44879356,
    "by": "nonethewiser",
    "timeISO": "2025-08-12T17:24:30.000Z",
    "textPlain": "While I agree, it's still shocking how far next token prediction gets us to looking like intelligence. It's amazing we need examples such as this to demonstrate it.",
    "parent": 44878951,
    "depth": 2
  },
  {
    "id": 44879775,
    "by": "kqr",
    "timeISO": "2025-08-12T18:01:39.000Z",
    "textPlain": "The previous article (linked in this one) gives an idea of that.",
    "parent": 44878665,
    "depth": 2
  },
  {
    "id": 44878673,
    "by": "throwawayoldie",
    "timeISO": "2025-08-12T16:35:12.000Z",
    "textPlain": "\"You're absolutely right, that's not a sentence you recognize...\"",
    "parent": 44878665,
    "depth": 2
  },
  {
    "id": 44879803,
    "by": "kqr",
    "timeISO": "2025-08-12T18:04:50.000Z",
    "textPlain": "They seem to be going for a much simpler route of just giving the LLM a full transcript of the game with its own reasoning interspersed. I didn't have much luck with that, and I'm worried it might not be effective once we're into the hundreds of turns because of inadvertent context poisoning. It seems like this might indeed be what happens, given the slowing of progress indicated in the paper.",
    "parent": 44878740,
    "depth": 2
  },
  {
    "id": 44878895,
    "by": "1970-01-01",
    "timeISO": "2025-08-12T16:52:27.000Z",
    "textPlain": "Very interesting how they all clearly suck at it. Even with hints, they can't understand the task enough to complete the game.",
    "parent": 44878740,
    "depth": 2
  },
  {
    "id": 44879024,
    "by": "abraxas",
    "timeISO": "2025-08-12T17:01:46.000Z",
    "textPlain": "that's a great tracker. How often is the laderboard updated?",
    "parent": 44878740,
    "depth": 2
  },
  {
    "id": 44879216,
    "by": "quesera",
    "timeISO": "2025-08-12T17:13:23.000Z",
    "textPlain": "Reproducing specific chunks of long form text from distilled (inherently lossy) model data is not something that I would expect LLMs to be good at.And of course, there's no actual reasoning or logic going on, so they cannot compete in this context with a curious 12 year old, either.",
    "parent": 44878659,
    "depth": 2
  },
  {
    "id": 44878778,
    "by": "throwawayoldie",
    "timeISO": "2025-08-12T16:43:40.000Z",
    "textPlain": "As a longtime IF fan, I can basically guarantee there are.",
    "parent": 44878659,
    "depth": 2
  },
  {
    "id": 44879504,
    "by": "bongodongobob",
    "timeISO": "2025-08-12T17:38:14.000Z",
    "textPlain": "Did you do anything special? I tried this with just copy and paste with GPT-4o and it was absolutely terrible at it. It usually ended up spamming help in a loop and trying commands that didn't exist.",
    "parent": 44878703,
    "depth": 2
  },
  {
    "id": 44880001,
    "by": "Terr_",
    "timeISO": "2025-08-12T18:22:02.000Z",
    "textPlain": "That's like saying it's wrong to test a robot's ability to navigate and traverse a mountain... because the mountain has no win-condition and is really a context for human emotional experiences.",
    "parent": 44877814,
    "depth": 2
  },
  {
    "id": 44879092,
    "by": "fmbb",
    "timeISO": "2025-08-12T17:06:14.000Z",
    "textPlain": "Of course you can automate ”having fun” and ”being entertained”. That is if you believe humanity will ever build artificial intelligence.",
    "parent": 44877814,
    "depth": 2
  },
  {
    "id": 44878350,
    "by": "kqr",
    "timeISO": "2025-08-12T16:15:51.000Z",
    "textPlain": "I disagree. Lockout, Dreamhold, Lost Pig, and So Far are new games but in the old style. Plundered Hearts is literally one of the old games (though ahead of its time).I'll grant you that 9:05 and For a Change are somewhat more modern: the former has easy puzzles, the latter very abstract puzzles.I disagree new text adventures are not about puzzles and winning. They come in all kinds of flavours these days. Even games like 9:05 pace their narrative with traditional puzzles, meaning we can measure forward progress just the same. And to be fair, LLMs are so bad at these games that in these articles, I'm merely trying to get them to navigate the world at all.If anything, I'd argue Adventure is a bad example of the genre you refer to. It was (by design) more of a caving simulator/sandbox with optinal loot than a game with progress toward a goal.",
    "parent": 44877814,
    "depth": 2
  },
  {
    "id": 44877834,
    "by": "hombre_fatal",
    "timeISO": "2025-08-12T15:45:11.000Z",
    "textPlain": "Noticed it was written in org mode with custom css so I found this post on their site: https://entropicthoughts.com/new-and-improved-now-powered-by...",
    "parent": 44877542,
    "depth": 2
  }
]