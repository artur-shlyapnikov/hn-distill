[
  {
    "id": 44908659,
    "by": "johnnyfeng",
    "timeISO": "2025-08-15T04:33:18.000Z",
    "textPlain": "Nice approach! Reader engagement beats synthetic benchmarks any day. Bookmarked to try later - curious which models actually hook readers vs just score well on tests.",
    "parent": 44903265,
    "depth": 1
  },
  {
    "id": 44908642,
    "by": "BoorishBears",
    "timeISO": "2025-08-15T04:31:01.000Z",
    "textPlain": "I run a site that does something similar, but on a more granular level (prompts at the page level rather than the chapter)I think right now we're at the point where novelcrafter is an excellent proxy for the best models for readers, because LLMs are still mostly losing engagement due to technical errors as opposed to subjective ones:That's repetition problems, moralizing/soft-censorship, grammatical quirks, missing instructions, forgetting major plot points, etc.Those kinds of errors are so obvious you can almost rank these models with an N=1 vibe test, and they limit how much people will consume unless you're scratching certain itches like NSFWHowever I do think with enough post-training you can beat that level of problems and move to a stage where the writing is technically sound (and that's what I've spent most of the last year working on).From there you get to more challenging problems that require much more feedback along some level of specialization per user (like what Midjourney does during onboarding to build up a style profile). Once you're not making technical mistakes, you now have to codify the ethereal concept of \"user taste\", and that will be a really interesting challenge for LLMs.",
    "parent": 44903265,
    "depth": 1
  }
]