[
  {
    "id": 44902240,
    "by": "canyon289",
    "timeISO": "2025-08-14T16:14:07.000Z",
    "textPlain": "Hi all, I built these models with a great team. They're available for download across the open model ecosystem so give them a try! I built these models with a great team and am thrilled to get them out to you.From our side we designed these models to be strong for their size out of the box, and with the goal you'll all finetune it for your use case. With the small size it'll fit on a wide range of hardware and cost much less to finetune. You can try finetuning them yourself in a free colab in under 5 minutesFor picking a Gemma size this is a video I recorded for the 1b to 27b sizes earlier this year, 270m being the newest additionhttps://www.youtube.com/watch?v=qcjrduz_YS8Hacker News Disclaimer\nI really like working at Google so with that; All my opinions here are my own, I'm a researcher so I'll largely focus on technical questions, and I'll share what I can.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44904459,
    "by": "mrtimo",
    "timeISO": "2025-08-14T19:18:03.000Z",
    "textPlain": "I'm a business professor who teaches Python and more. I'd like to develop some simple projects to help my students fine tune this for a business purpose. If you have ideas (or datasets for fine tuning), let me know!",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903731,
    "by": "jefb",
    "timeISO": "2025-08-14T18:12:32.000Z",
    "textPlain": "My lovely interaction with the 270M-F16 model:> what's second tallest mountain on earth?The second tallest mountain on Earth is Mount Everest.> what's the tallest mountain on earth?The tallest mountain on Earth is Mount Everest.> whats the second tallest mountain?The second tallest mountain in the world is Mount Everest.> whats the third tallest mountain?The third tallest mountain in the world is Mount Everest.> what's the forth tallest mountain?The forth tallest mountain is Mount Everest.> but you said the tallest was Everest alreadyYou are right! I'm glad to hear that.> so whats the second tallest?The second tallest is *Mount Everest*.> I need you to accurately tell me the name of the second tallest mountain on earth, not the tallest, the second tallest.The second tallest mountain on Earth is Mount Everest.> The tallest mountain on earth is mount everest. What is the second tallest mountain?The second tallest mountain on Earth is Mount Everest.> Give me a list of the tallest mountains on earthThe tallest mountain in the world is the *Mount Everest*.> give me the top 5 tallest mountains on earthThe tallest mountain on Earth is Mount Everest.> List in order the tallest mountains on earth from 1 to 51. Mount Everest\n2. Mount K2\n3. Mount Sahel\n4. Mount Fuji\n5. Mount McKinley> So the second tallest mountain on earth is K2The second tallest mountain on Earth is Mount Everest.These smaller models are great, but they really feel like talking to a toddler sometimes!",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44902980,
    "by": "simonw",
    "timeISO": "2025-08-14T17:10:43.000Z",
    "textPlain": "This model is a LOT of fun. It's absolutely tiny - just a 241MB download - and screamingly fast, and hallucinates wildly about almost everything.Here's one of dozens of results I got for \"Generate an SVG of a pelican riding a bicycle\". For this one it decided to write a poem:  +-----------------------+\n  |   Pelican Riding Bike |\n  +-----------------------+\n  |  This is the cat!  |\n  |  He's got big wings and a happy tail.  |\n  |  He loves to ride his bike!  |\n  +-----------------------+\n  |   Bike lights are shining bright.  |\n  |   He's got a shiny top, too!  |\n  |   He's ready for adventure!  |\n  +-----------------------+\n\nThere are a bunch more attempts in this Gist, some of which do at least include an SVG tag albeit one that doesn't render anything: https://gist.github.com/simonw/25e7b7afd6a63a2f15db48b3a51ec...I'm looking forward to seeing people fine-tune this in a way that produces useful output for selected tasks, which should absolutely be feasible.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903495,
    "by": "mrcwinn",
    "timeISO": "2025-08-14T17:54:03.000Z",
    "textPlain": "Apple should be doing this. Unless their plan is to replace their search deal with an AI deal -- it's just crazy to me how absent Apple is. Tim Cook said, \"it's ours to take\" but they really seem to be grasping at the wind right now. Go Google!",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44904066,
    "by": "miohtama",
    "timeISO": "2025-08-14T18:43:16.000Z",
    "textPlain": "Out of curiosity: because there seems to be a race to optimise models for local inference, how much \"parameters one could save\" by dropping unneeded language and domain-specific information.Like, can you have a model that is English-only, but does more with the same amount of parameters if Chinese and European languages are dropped from the training?",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44904181,
    "by": "AJRF",
    "timeISO": "2025-08-14T18:54:11.000Z",
    "textPlain": "I've got a very real world use case I use DistilBERT for - learning how to label wordpress articles. It is one of those things where it's kind of valuable (tagging) but not enough to spend loads on compute for it.The great thing is I have enough data (100k+) to fine-tune and run a meaningful classification report over. The data is very diverse, and while the labels aren't totally evenly distributed, I can deal with the imbalance with a few tricks.Can't wait to swap it out for this and see the changes in the scores. Will report back",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903748,
    "by": "KTibow",
    "timeISO": "2025-08-14T18:14:02.000Z",
    "textPlain": "To add to the article: Gemma 3 270M's exact IFEval score is 51.2, and Qwen 3 would be at (0.6, 59.2) on the scatter plot.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903182,
    "by": "whinvik",
    "timeISO": "2025-08-14T17:26:45.000Z",
    "textPlain": "Curious. Are there real world usecases where people have finetuned such tiny models and put them into production.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903817,
    "by": "perching_aix",
    "timeISO": "2025-08-14T18:21:11.000Z",
    "textPlain": "Is it time for me to finally package a language model into my Lambda deployment zips and finally cut through the corporate red tape around AI use?Update #1:Tried it. Well, dreams dashed - would now fit space wise (<250 MB despite the name), but it sadly really doesn't seem to work for my specific prospective workload.I'd have wanted it to perform natural-language to command-invocation translation (or better, emit me some JSON), but it's super not willing to do that, not in the lame way I'm trying to make it do so at least (literally just prompting it to). Oh well.Update #2:Just found out about grammar-constrained decode, maybe there's still hope for me in the end. I don't think I can amend this comment today with any more updates, but will see.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44902895,
    "by": "lemonish97",
    "timeISO": "2025-08-14T17:04:47.000Z",
    "textPlain": "Never thought I'd run an LLM released in 2025, on my phone, in full BF16.\nWith ~80tps on an iPhone 16 pro btw.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903914,
    "by": "nerdix",
    "timeISO": "2025-08-14T18:30:11.000Z",
    "textPlain": "Is it possible to finetune a model like this with local hardware? Every tutorial I've come across on finetuning a local LLM uses some cloud service like colab or runpod.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903149,
    "by": "jasonjmcghee",
    "timeISO": "2025-08-14T17:24:09.000Z",
    "textPlain": "I'm _very_ interested to see what this can be fine-tuned to do.I've heard folks say a number of times that neuromuscular control / locomotion (or w/e) are hundreds of millions of parameters rather than billions.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903188,
    "by": "jtbayly",
    "timeISO": "2025-08-14T17:27:03.000Z",
    "textPlain": "Can somebody give me a link to a tutorial on how I would go about fine-tuning this?Also, what sorts of things might I consider fine-tuning it for?",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44902789,
    "by": "44za12",
    "timeISO": "2025-08-14T16:55:38.000Z",
    "textPlain": "I’ve had great luck with all gemma 3 variants, on certain tasks it the 27B quantized version has worked as well as 2.5 flash. Can’t wait to get my hands dirty with this one.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44904444,
    "by": "metalliqaz",
    "timeISO": "2025-08-14T19:16:19.000Z",
    "textPlain": "is there a good resource for getting started with downloading and running something like this for a demo?  There are just so many tools/platforms in the mix now it makes my head spin.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903840,
    "by": "robbru",
    "timeISO": "2025-08-14T18:23:12.000Z",
    "textPlain": "Excited to try this out, thanks for sharing.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44902845,
    "by": "Alex-Programs",
    "timeISO": "2025-08-14T16:59:56.000Z",
    "textPlain": "This is cool. I'm looking forward to trying it - I wonder what it'll be useful for.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44904065,
    "by": "bbor",
    "timeISO": "2025-08-14T18:43:10.000Z",
    "textPlain": "Really impressive stuff, as always. I will say: it took me a shamefully long time to realize that the name ended in \"M\" instead of \"B\"! Perhaps they should consider renaming this to \"Gemma 3 .27B\"...",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903049,
    "by": "dcreater",
    "timeISO": "2025-08-14T17:15:19.000Z",
    "textPlain": "I've been saying he we need sub 1B models for the edge so thanks fot this.I am however disappointed that there is no examples, or benchmarks, provided to get a sense of performance. It's a given that benchmark values would be lower than gemma 3n, but having a sense of performance vs size curve and comparison to existing small models is needed",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903696,
    "by": "dismalaf",
    "timeISO": "2025-08-14T18:09:43.000Z",
    "textPlain": "It's fast at spitting out nonsense but incredibly slow at trying to parse any context.  Also absolutely atrocious at following instructions.Probably would be good as a game NPC or a chatbot, not very good for integrating into an application which specific functionality though.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903475,
    "by": "NorwegianDude",
    "timeISO": "2025-08-14T17:52:54.000Z",
    "textPlain": "The Gemma 3 models are great! One of the few models that can write Norwegian decently, and the instruction following is in my opinion good for most cases. I do however have some issues that might be related to censorship that I hope will be fixed if there is ever a Gemma 4. Maybe you have some insight into why this is happening?I run a game when players can post messages, it's a game where players can kill each other, and people often send threats along the lines of \"I will kill you\". Telling Gemma that it should classify a message as game related or a real life threat, and that it is for a message in a game where players can kill each other and threats are a part of the game, and that it should mark it as game related if it is unclear if the message is a game related threat or a real life threat does not work well. For other similar tasks it seems to follow instructions well, but for serious topics it seems to be very biased, and often err on the side of caution, despite being told not to. Sometimes it even spits out some help lines to contact.I guess this is because it was trained to be safe, and that affects it's ability to follow instructions for this? Or am I completely off here?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44904457,
    "by": "imasl42",
    "timeISO": "2025-08-14T19:17:31.000Z",
    "textPlain": "Awesome! I’m curious how is the team you built these models with? Is it great?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903827,
    "by": "ceroxylon",
    "timeISO": "2025-08-14T18:21:59.000Z",
    "textPlain": "You reminded me of an awesome Google engineer I met at BSidesSF last year who tirelessly answered my questions, and when I clicked on the video, it was you! That was a really inspiring moment for me, thank you.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903942,
    "by": "jmorgan",
    "timeISO": "2025-08-14T18:32:09.000Z",
    "textPlain": "Amazing work. This model feels really good at one-off tasks like summarization and autocomplete. I really love that you released a quantized aware training version on launch day as well, making it even smaller!",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903226,
    "by": "simonw",
    "timeISO": "2025-08-14T17:30:09.000Z",
    "textPlain": "Do you have any practical examples of fine-tuned variants of this that you can share? A description would be great, but a demo or even downloadable model weights (GGUF ideally) would be even better.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44904366,
    "by": "patrickaljord",
    "timeISO": "2025-08-14T19:09:34.000Z",
    "textPlain": "Would it be possible to have a specialized rust only dev or Reactjs only dev while getting rid of all other languages to minimize size of model?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44904326,
    "by": "blitzar",
    "timeISO": "2025-08-14T19:05:56.000Z",
    "textPlain": "> I built these models with a great team ... I built these models with a great teamIf Gemini is going to repeat something at least its that the team is great, and not a disgrace!",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44904296,
    "by": "_1",
    "timeISO": "2025-08-14T19:03:32.000Z",
    "textPlain": "> and with the goal you'll all finetune it for your use case.What use-cases are a good fit for finetuning this model?  More specific instruction following, knowledge from proprietary data, response tone?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44902889,
    "by": "beoberha",
    "timeISO": "2025-08-14T17:04:18.000Z",
    "textPlain": "Awesome work! I’m really bullish on small models and think they have the most potential to change our daily lives. Can’t wait to play around with this",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903851,
    "by": "nerdsniper",
    "timeISO": "2025-08-14T18:25:39.000Z",
    "textPlain": "What are some of the use cases that you think the 270M would be most appropriate for? What would you love to see people trying with it?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903234,
    "by": "cgdl",
    "timeISO": "2025-08-14T17:30:41.000Z",
    "textPlain": "Very cool. For the INT4 QAT model, what is the recommended precision for the activations and for the key and values stored in KV cache?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903087,
    "by": "tmaly",
    "timeISO": "2025-08-14T17:18:45.000Z",
    "textPlain": "Are there any fine tuning in a box type options available in the cloud for this?  This is amazing work, thank you.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44904147,
    "by": "stefan_",
    "timeISO": "2025-08-14T18:50:52.000Z",
    "textPlain": "I suppose the odd repetition of \"I built these models with a great team\" is to warm us up to this model slipping into infinite gibberish repetition?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903700,
    "by": "andrewstuart",
    "timeISO": "2025-08-14T18:10:05.000Z",
    "textPlain": "What effort do you folks take to see your models actually running on hardware such as AMD Strix Halo or Apple M3M4?I get the sense that AI is at the “hobby kit computing” stage where they used to dump all the components in a box and give you a schematic and a soldering iron and happily say “you make it work!”And that worked in the early days of computing because there was a small number of people really motivated for the outcome.But fully assembled and packaged and tested in a nice looking box is where the real demand turned out to be.I’m looking forward to the day Google doesn’t just dump a model and say “you do the rest”.I want to fire up Ubuntu on a Strix Halo and say apt install then load the browser interface. Or just download and run a Mac installer and have it just work.Arcane complex multi step build install configure processes for AI need to end in favor of one click install. I’m not interested in the process of making it run.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44902940,
    "by": "fibers",
    "timeISO": "2025-08-14T17:07:45.000Z",
    "textPlain": "Great job. Do you know how well it performs in sanity checks with NER since it is on the press release page?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44902766,
    "by": "ActorNightly",
    "timeISO": "2025-08-14T16:54:23.000Z",
    "textPlain": "How does the 270 perform with coding?I use Gemma27b currently with a custom agent wrapper and its working pretty well.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903338,
    "by": "VirusNewbie",
    "timeISO": "2025-08-14T17:39:43.000Z",
    "textPlain": "hi Ravin, fellow Googler here. Curious if you can share here (or internally?) how these models were trained.   Wondering if you face all the chaos the large models have during training?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903858,
    "by": "gnulinux",
    "timeISO": "2025-08-14T18:26:05.000Z",
    "textPlain": "Well, this is a 270M model which is like 1/3 of 1B parameters. In the grand scheme of things, it's basically a few matrix multiplications, barely anything more than that. I don't think it's meant to have a lot of knowledge, grammar, or even coherence. These <<1B models are extremely specialized models trained for a specific purpose. Models like this are optimized for things like this (not limited):input:\n```\nCustomer Review says: ai bought your prod-duct and I wanna return becaus it no good.Prompt: Create a JSON object that extracts information about this customer review based on the schema given.\n```output:\n```\n{\n\"type\": \"review\",\n\"class\": \"complaint\",\n\"sentiment\": -0.853,\n\"request\": \"return\"\n}\n```So essentially just \"making sense of\" natural language such that it can be used in programmatic context. (among other applications of course)To get good results, you probably need to fine tune this model to expected data very aggressively.The idea is, if a 270MB model can do with fine tuning, why ship a 32GB generalist model?",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44904173,
    "by": "canyon289",
    "timeISO": "2025-08-14T18:53:18.000Z",
    "textPlain": "To add to the comments, we were not aiming for perfect factuality. Even ignoring the model size, these weights are frozen in time now.My suggestions here are to hook this model up to a RAG system, then you can rely on an external knowledge store. Or you can try finetuning this model with the facts that are important to you, if you do that it should pick up that new knowledge quite quickly.",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44904186,
    "by": "yomismoaqui",
    "timeISO": "2025-08-14T18:54:28.000Z",
    "textPlain": "Evaluating a 270M model on encyclopedic knowledge is like opening a heavily compressed JPG image and saying \"it looks blocky\"",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44903799,
    "by": "cristyansv",
    "timeISO": "2025-08-14T18:19:05.000Z",
    "textPlain": "But in your prompts you're trying to assess knowledge, and this model isn't suited for that use caseas mentioned in the blog post: \n> \"it can execute tasks like text classification and data extraction with remarkable accuracy, speed, and cost-effectiveness.\"",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44903908,
    "by": "aldousd666",
    "timeISO": "2025-08-14T18:29:34.000Z",
    "textPlain": "It's an instruction following model, not a micro-wikipedia. It's not meant to answer factual questions nor even be general purpose. It's meant to follow instructions and be easy to fine-tune for your own specific use case.",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44904018,
    "by": "leopoldj",
    "timeISO": "2025-08-14T18:39:38.000Z",
    "textPlain": "You are testing this model for knowledge. That's not the primary use of a model like this. They are meant for instilling domain specific skills and knowledge through fine-tuning. The blog post goes into that a lot. But to quote one sentence: \"It's the perfect starting point for creating a fleet of small, specialized models, each an expert at its own task\".",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44904165,
    "by": "mvdtnz",
    "timeISO": "2025-08-14T18:52:34.000Z",
    "textPlain": "> These smaller models are greatAre they?",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44903423,
    "by": "roughly",
    "timeISO": "2025-08-14T17:47:35.000Z",
    "textPlain": "I audibly laughed at this one: https://gist.github.com/simonw/25e7b7afd6a63a2f15db48b3a51ec... where it generates a… poem? Song? And then proceeds to explain how each line contributes to the SVG, concluding with:> This SVG code provides a clear and visually appealing representation of a pelican riding a bicycle in a scenic landscape.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903383,
    "by": "0x00cl",
    "timeISO": "2025-08-14T17:43:42.000Z",
    "textPlain": "I see you are using ollamas ggufs. By default it will download Q4_0 quantization. Try `gemma3:270m-it-bf16` instead or you can also use unsloth ggufs `hf.co/unsloth/gemma-3-270m-it-GGUF:16`You'll get better results.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903148,
    "by": "ertgbnm",
    "timeISO": "2025-08-14T17:24:02.000Z",
    "textPlain": "He may generate useless tokens but boy can he generate ALOT of tokens.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903261,
    "by": "layer8",
    "timeISO": "2025-08-14T17:33:35.000Z",
    "textPlain": "> It's absolutely tiny - just a 241MB downloadThat still requires more than 170 floppy disks for installation.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903072,
    "by": "marinhero",
    "timeISO": "2025-08-14T17:17:22.000Z",
    "textPlain": "Serious question but if it hallucinates about almost everything, what's the use case for it?",
    "parent": 44902980,
    "depth": 2
  }
]