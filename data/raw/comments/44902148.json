[
  {
    "id": 44902240,
    "by": "canyon289",
    "timeISO": "2025-08-14T16:14:07.000Z",
    "textPlain": "Hi all, I built these models with a great team. They're available for download across the open model ecosystem so give them a try! I built these models with a great team and am thrilled to get them out to you.From our side we designed these models to be strong for their size out of the box, and with the goal you'll all finetune it for your use case. With the small size it'll fit on a wide range of hardware and cost much less to finetune. You can try finetuning them yourself in a free colab in under 5 minutesFor picking a Gemma size this is a video I recorded for the 1b to 27b sizes earlier this year, 270m being the newest additionhttps://www.youtube.com/watch?v=qcjrduz_YS8Hacker News Disclaimer\nI really like working at Google so with that; All my opinions here are my own, I'm a researcher so I'll largely focus on technical questions, and I'll share what I can.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903731,
    "by": "jefb",
    "timeISO": "2025-08-14T18:12:32.000Z",
    "textPlain": "My lovely interaction with the 270M-F16 model:> what's second tallest mountain on earth?The second tallest mountain on Earth is Mount Everest.> what's the tallest mountain on earth?The tallest mountain on Earth is Mount Everest.> whats the second tallest mountain?The second tallest mountain in the world is Mount Everest.> whats the third tallest mountain?The third tallest mountain in the world is Mount Everest.> what's the forth tallest mountain?The forth tallest mountain is Mount Everest.> but you said the tallest was Everest alreadyYou are right! I'm glad to hear that.> so whats the second tallest?The second tallest is *Mount Everest*.> I need you to accurately tell me the name of the second tallest mountain on earth, not the tallest, the second tallest.The second tallest mountain on Earth is Mount Everest.> The tallest mountain on earth is mount everest. What is the second tallest mountain?The second tallest mountain on Earth is Mount Everest.> Give me a list of the tallest mountains on earthThe tallest mountain in the world is the *Mount Everest*.> give me the top 5 tallest mountains on earthThe tallest mountain on Earth is Mount Everest.> List in order the tallest mountains on earth from 1 to 51. Mount Everest\n2. Mount K2\n3. Mount Sahel\n4. Mount Fuji\n5. Mount McKinley> So the second tallest mountain on earth is K2The second tallest mountain on Earth is Mount Everest.These smaller models are great, but they really feel like talking to a toddler sometimes!",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44902980,
    "by": "simonw",
    "timeISO": "2025-08-14T17:10:43.000Z",
    "textPlain": "This model is a LOT of fun. It's absolutely tiny - just a 241MB download - and screamingly fast, and hallucinates wildly about almost everything.Here's one of dozens of results I got for \"Generate an SVG of a pelican riding a bicycle\". For this one it decided to write a poem:  +-----------------------+\n  |   Pelican Riding Bike |\n  +-----------------------+\n  |  This is the cat!  |\n  |  He's got big wings and a happy tail.  |\n  |  He loves to ride his bike!  |\n  +-----------------------+\n  |   Bike lights are shining bright.  |\n  |   He's got a shiny top, too!  |\n  |   He's ready for adventure!  |\n  +-----------------------+\n\nThere are a bunch more attempts in this Gist, some of which do at least include an SVG tag albeit one that doesn't render anything: https://gist.github.com/simonw/25e7b7afd6a63a2f15db48b3a51ec...I'm looking forward to seeing people fine-tune this in a way that produces useful output for selected tasks, which should absolutely be feasible.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903495,
    "by": "mrcwinn",
    "timeISO": "2025-08-14T17:54:03.000Z",
    "textPlain": "Apple should be doing this. Unless their plan is to replace their search deal with an AI deal -- it's just crazy to me how absent Apple is. Tim Cook said, \"it's ours to take\" but they really seem to be grasping at the wind right now. Go Google!",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903914,
    "by": "nerdix",
    "timeISO": "2025-08-14T18:30:11.000Z",
    "textPlain": "Is it possible to finetune a model like this with local hardware? Every tutorial I've come across on finetuning a local LLM uses some cloud service like colab or runpod.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903748,
    "by": "KTibow",
    "timeISO": "2025-08-14T18:14:02.000Z",
    "textPlain": "To add to the article: Gemma 3 270M's exact IFEval score is 51.2, and Qwen 3 would be at (0.6, 59.2) on the scatter plot.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903817,
    "by": "perching_aix",
    "timeISO": "2025-08-14T18:21:11.000Z",
    "textPlain": "Is it time for me to finally package a language model into my Lambda deployment zips and finally cut through the corporate red tape around AI use?",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903182,
    "by": "whinvik",
    "timeISO": "2025-08-14T17:26:45.000Z",
    "textPlain": "Curious. Are there real world usecases where people have finetuned such tiny models and put them into production.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44902789,
    "by": "44za12",
    "timeISO": "2025-08-14T16:55:38.000Z",
    "textPlain": "I’ve had great luck with all gemma 3 variants, on certain tasks it the 27B quantized version has worked as well as 2.5 flash. Can’t wait to get my hands dirty with this one.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44902895,
    "by": "lemonish97",
    "timeISO": "2025-08-14T17:04:47.000Z",
    "textPlain": "Never thought I'd run an LLM released in 2025, on my phone, in full BF16.\nWith ~80tps on an iPhone 16 pro btw.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903149,
    "by": "jasonjmcghee",
    "timeISO": "2025-08-14T17:24:09.000Z",
    "textPlain": "I'm _very_ interested to see what this can be fine-tuned to do.I've heard folks say a number of times that neuromuscular control / locomotion (or w/e) are hundreds of millions of parameters rather than billions.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903840,
    "by": "robbru",
    "timeISO": "2025-08-14T18:23:12.000Z",
    "textPlain": "Excited to try this out, thanks for sharing.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903188,
    "by": "jtbayly",
    "timeISO": "2025-08-14T17:27:03.000Z",
    "textPlain": "Can somebody give me a link to a tutorial on how I would go about fine-tuning this?Also, what sorts of things might I consider fine-tuning it for?",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44902845,
    "by": "Alex-Programs",
    "timeISO": "2025-08-14T16:59:56.000Z",
    "textPlain": "This is cool. I'm looking forward to trying it - I wonder what it'll be useful for.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903049,
    "by": "dcreater",
    "timeISO": "2025-08-14T17:15:19.000Z",
    "textPlain": "I've been saying he we need sub 1B models for the edge so thanks fot this.I am however disappointed that there is no examples, or benchmarks, provided to get a sense of performance. It's a given that benchmark values would be lower than gemma 3n, but having a sense of performance vs size curve and comparison to existing small models is needed",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903696,
    "by": "dismalaf",
    "timeISO": "2025-08-14T18:09:43.000Z",
    "textPlain": "It's fast at spitting out nonsense but incredibly slow at trying to parse any context.  Also absolutely atrocious at following instructions.Probably would be good as a game NPC or a chatbot, not very good for integrating into an application which specific functionality though.",
    "parent": 44902148,
    "depth": 1
  },
  {
    "id": 44903942,
    "by": "jmorgan",
    "timeISO": "2025-08-14T18:32:09.000Z",
    "textPlain": "Amazing work. This model feels really good at one-off tasks like summarization and autocomplete. I really love that you released a quantized aware training version on launch day as well, making it even smaller!",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903475,
    "by": "NorwegianDude",
    "timeISO": "2025-08-14T17:52:54.000Z",
    "textPlain": "The Gemma 3 models are great! One of the few models that can write Norwegian decently, and the instruction following is in my opinion good for most cases. I do however have some issues that might be related to censorship that I hope will be fixed if there is ever a Gemma 4. Maybe you have some insight into why this is happening?I run a game when players can post messages, it's a game where players can kill each other, and people often send threats along the lines of \"I will kill you\". Telling Gemma that it should classify a message as game related or a real life threat, and that it is for a message in a game where players can kill each other and threats are a part of the game, and that it should mark it as game related if it is unclear if the message is a game related threat or a real life threat does not work well. For other similar tasks it seems to follow instructions well, but for serious topics it seems to be very biased, and often err on the side of caution, despite being told not to. Sometimes it even spits out some help lines to contact.I guess this is because it was trained to be safe, and that affects it's ability to follow instructions for this? Or am I completely off here?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903226,
    "by": "simonw",
    "timeISO": "2025-08-14T17:30:09.000Z",
    "textPlain": "Do you have any practical examples of fine-tuned variants of this that you can share? A description would be great, but a demo or even downloadable model weights (GGUF ideally) would be even better.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903851,
    "by": "nerdsniper",
    "timeISO": "2025-08-14T18:25:39.000Z",
    "textPlain": "What are some of the use cases that you think the 270M would be most appropriate for? What would you love to see people trying with it?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903827,
    "by": "ceroxylon",
    "timeISO": "2025-08-14T18:21:59.000Z",
    "textPlain": "You reminded me of an awesome Google engineer I met at BSidesSF last year who tirelessly answered my questions, and when I clicked on the video, it was you! That was a really inspiring moment for me, thank you.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44902889,
    "by": "beoberha",
    "timeISO": "2025-08-14T17:04:18.000Z",
    "textPlain": "Awesome work! I’m really bullish on small models and think they have the most potential to change our daily lives. Can’t wait to play around with this",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903234,
    "by": "cgdl",
    "timeISO": "2025-08-14T17:30:41.000Z",
    "textPlain": "Very cool. For the INT4 QAT model, what is the recommended precision for the activations and for the key and values stored in KV cache?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903700,
    "by": "andrewstuart",
    "timeISO": "2025-08-14T18:10:05.000Z",
    "textPlain": "What effort do you folks take to see your models actually running on hardware such as AMD Strix Halo or Apple M3M4?I get the sense that AI is at the “hobby kit computing” stage where they used to dump all the components in a box and give you a schematic and a soldering iron and happily say “you make it work!”And that worked in the early days of computing because there was a small number of people really motivated for the outcome.But fully assembled and packaged and tested in a nice looking box is where the real demand turned out to be.I’m looking forward to the day Google doesn’t just dump a model and say “you do the rest”.I want to fire up Ubuntu on a Strix Halo and say apt install then load the browser interface. Or just download and run a Mac installer and have it just work.Arcane complex multi step build install configure processes for AI need to end in favor of one click install. I’m not interested in the process of making it run.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903087,
    "by": "tmaly",
    "timeISO": "2025-08-14T17:18:45.000Z",
    "textPlain": "Are there any fine tuning in a box type options available in the cloud for this?  This is amazing work, thank you.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44902940,
    "by": "fibers",
    "timeISO": "2025-08-14T17:07:45.000Z",
    "textPlain": "Great job. Do you know how well it performs in sanity checks with NER since it is on the press release page?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44902766,
    "by": "ActorNightly",
    "timeISO": "2025-08-14T16:54:23.000Z",
    "textPlain": "How does the 270 perform with coding?I use Gemma27b currently with a custom agent wrapper and its working pretty well.",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903338,
    "by": "VirusNewbie",
    "timeISO": "2025-08-14T17:39:43.000Z",
    "textPlain": "hi Ravin, fellow Googler here. Curious if you can share here (or internally?) how these models were trained.   Wondering if you face all the chaos the large models have during training?",
    "parent": 44902240,
    "depth": 2
  },
  {
    "id": 44903858,
    "by": "gnulinux",
    "timeISO": "2025-08-14T18:26:05.000Z",
    "textPlain": "Well, this is a 270M model which is like 1/3 of 1B parameters. In the grand scheme of things, it's basically a few matrix multiplications, barely anything more than that. I don't think it's meant to have a lot of knowledge, grammar, or even coherence. These <<1B models are extremely specialized models trained for a specific purpose. Models like this are optimized for things like this (not limited):input:\n```\nCustomer Review says: ai bought your prod-duct and I wanna return becaus it no good.Prompt: Create a JSON object that extracts information about this customer review based on the schema given.\n```output:\n```\n{\n\"type\": \"review\",\n\"class\": \"complaint\",\n\"sentiment\": -0.853,\n\"request\": \"return\"\n}\n```So essentially just \"making sense of\" natural language such that it can be used in programmatic context. (among other applications of course)To get good results, you probably need to fine tune this model to expected data very aggressively.The idea is, if a 270MB model can do with fine tuning, why ship a 32GB generalist model?",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44903799,
    "by": "cristyansv",
    "timeISO": "2025-08-14T18:19:05.000Z",
    "textPlain": "But in your prompts you're trying to assess knowledge, and this model isn't suited for that use caseas mentioned in the blog post: \n> \"it can execute tasks like text classification and data extraction with remarkable accuracy, speed, and cost-effectiveness.\"",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44903908,
    "by": "aldousd666",
    "timeISO": "2025-08-14T18:29:34.000Z",
    "textPlain": "It's an instruction following model, not a micro-wikipedia. It's not meant to answer factual questions nor even be general purpose. It's meant to follow instructions and be easy to fine-tune for your own specific use case.",
    "parent": 44903731,
    "depth": 2
  },
  {
    "id": 44903423,
    "by": "roughly",
    "timeISO": "2025-08-14T17:47:35.000Z",
    "textPlain": "I audibly laughed at this one: https://gist.github.com/simonw/25e7b7afd6a63a2f15db48b3a51ec... where it generates a… poem? Song? And then proceeds to explain how each line contributes to the SVG, concluding with:> This SVG code provides a clear and visually appealing representation of a pelican riding a bicycle in a scenic landscape.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903383,
    "by": "0x00cl",
    "timeISO": "2025-08-14T17:43:42.000Z",
    "textPlain": "I see you are using ollamas ggufs. By default it will download Q4_0 quantization. Try `gemma3:270m-it-bf16` instead or you can also use unsloth ggufs `hf.co/unsloth/gemma-3-270m-it-GGUF:16`You'll get better results.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903148,
    "by": "ertgbnm",
    "timeISO": "2025-08-14T17:24:02.000Z",
    "textPlain": "He may generate useless tokens but boy can he generate ALOT of tokens.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903261,
    "by": "layer8",
    "timeISO": "2025-08-14T17:33:35.000Z",
    "textPlain": "> It's absolutely tiny - just a 241MB downloadThat still requires more than 170 floppy disks for installation.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903072,
    "by": "marinhero",
    "timeISO": "2025-08-14T17:17:22.000Z",
    "textPlain": "Serious question but if it hallucinates about almost everything, what's the use case for it?",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903344,
    "by": "nico",
    "timeISO": "2025-08-14T17:40:12.000Z",
    "textPlain": "Could be interesting to use in a RAG setup and also finetuning itFor sure it won’t generate great svgs, but it might be a really good conversational model",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903118,
    "by": "mdp2021",
    "timeISO": "2025-08-14T17:21:21.000Z",
    "textPlain": "> For this one it decided to write a poemCould it be tamed with good role-system prompt crafting? (Besides fine-tuning.)",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903077,
    "by": "campbel",
    "timeISO": "2025-08-14T17:17:56.000Z",
    "textPlain": "Do you take requests? We need to see how well this model works with some fine-tuning :D",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903127,
    "by": "volkk",
    "timeISO": "2025-08-14T17:22:25.000Z",
    "textPlain": "i was looking at the demo and reading the bed time story it generated and even there, there was confusion about the sprite and the cat. switched subjects instantly making for a confusing paragraph. what's the point of this model?",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903194,
    "by": "cyanydeez",
    "timeISO": "2025-08-14T17:27:28.000Z",
    "textPlain": "the question is wheather you can make a fine tuned version and spam any given forum within an hour with the most attuned but garbage content.",
    "parent": 44902980,
    "depth": 2
  },
  {
    "id": 44903888,
    "by": "potatolicious",
    "timeISO": "2025-08-14T18:28:10.000Z",
    "textPlain": "They do. The docs are right here: https://developer.apple.com/documentation/foundationmodels/g...If you have the latest betas installed you can call those APIs right now.They also support fine-tuning on the model that ships with ~every device:https://developer.apple.com/apple-intelligence/foundation-mo...",
    "parent": 44903495,
    "depth": 2
  },
  {
    "id": 44903771,
    "by": "syassami",
    "timeISO": "2025-08-14T18:15:46.000Z",
    "textPlain": "They have a GPT2 like model that's deployed right now for autocomplete https://jackcook.com/2023/09/08/predictive-text.html",
    "parent": 44903495,
    "depth": 2
  },
  {
    "id": 44903779,
    "by": "burnerRhodo",
    "timeISO": "2025-08-14T18:17:06.000Z",
    "textPlain": "steve jobs was the innovator, steve cook is the supply chain guy. They started an electric car not because they thought it was a good idea, but because everyone was going to leave to Tesla or rivian if they didn't. They had no direction and arguements that Tesla had about whether to have a steering wheel...Then Siri just kinda languishes for forever, and LLM's pass the torch of \"Cool Tech\", so they try and \"Reinvigurate\" the team, but with no clear direction. Are they going to be a cloud provider? Are they going to contract out the training? Are they gunna spin up a compute facility even after neglecting to do so since 2012?Apple needs to just stop trying shit, and just get that app store money. That's why jobs appointed cook. Jobs new cook was no innovator, but he could make apple a money printing machine. Thats what they should stick with.",
    "parent": 44903495,
    "depth": 2
  },
  {
    "id": 44903734,
    "by": "Lalabadie",
    "timeISO": "2025-08-14T18:12:45.000Z",
    "textPlain": "By \"this\", do you mean SLM (small language models)? That's absolutely something they've been working on for a good while.",
    "parent": 44903495,
    "depth": 2
  },
  {
    "id": 44903670,
    "by": "deepsquirrelnet",
    "timeISO": "2025-08-14T18:06:40.000Z",
    "textPlain": "I’m not sure what I’d use them for, except maybe tag generation? Encoders of this size usually outperform by a wide margin on tasks they would overlap with.",
    "parent": 44903182,
    "depth": 2
  },
  {
    "id": 44903218,
    "by": "cyanydeez",
    "timeISO": "2025-08-14T17:29:26.000Z",
    "textPlain": "9gag.com commenter",
    "parent": 44903182,
    "depth": 2
  },
  {
    "id": 44902977,
    "by": "elAhmo",
    "timeISO": "2025-08-14T17:10:32.000Z",
    "textPlain": "How do you actually run this on an iPhone?",
    "parent": 44902895,
    "depth": 2
  },
  {
    "id": 44903231,
    "by": "simonw",
    "timeISO": "2025-08-14T17:30:36.000Z",
    "textPlain": "This tutorial looks useful: https://ai.google.dev/gemma/docs/core/huggingface_text_full_...",
    "parent": 44903188,
    "depth": 2
  },
  {
    "id": 44903270,
    "by": "JLCarveth",
    "timeISO": "2025-08-14T17:34:25.000Z",
    "textPlain": "This was linked at the end of Google's announcement: https://docs.unsloth.ai/basics/gemma-3-how-to-run-and-fine-t...Not sure how much data is needed to realistically fine-tune something like this and get useful output.",
    "parent": 44903188,
    "depth": 2
  }
]