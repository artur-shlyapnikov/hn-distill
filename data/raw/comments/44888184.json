[
  {
    "id": 44920938,
    "by": "mattnewton",
    "timeISO": "2025-08-16T07:01:15.000Z",
    "textPlain": "There has got to be a way to map the activations back to the closest token embeddings and read the resulting sentence. Could be interesting to see how much activation you lose in doing that, and it could maybe even be interesting to a \"jailbreaking\" attempt.",
    "parent": 44888184,
    "depth": 1
  },
  {
    "id": 44920776,
    "by": "trehans",
    "timeISO": "2025-08-16T06:33:51.000Z",
    "textPlain": "I wonder what the prompt would look like as a sentence. Maybe activation maximization can be used to decipher it, maybe by seeing which sentence of length N would maximize similarity to the prompt when fed through a tokenizer",
    "parent": 44888184,
    "depth": 1
  },
  {
    "id": 44920857,
    "by": "nneonneo",
    "timeISO": "2025-08-16T06:47:41.000Z",
    "textPlain": "If you wanted to get a readable prompt, I wonder if you could follow the GCG trick used by jailbreak maximizers (e.g. https://arxiv.org/pdf/2307.15043)?Sure, you're probably going to wind up with absolute garbage (one of their prompts starts with \"== interface Manuel WITH steps instead sentences :)ish?\") but it might be very funny to read...",
    "parent": 44888184,
    "depth": 1
  }
]