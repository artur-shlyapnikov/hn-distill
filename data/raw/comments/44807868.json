[
  {
    "id": 44806825,
    "by": "mlboss",
    "timeISO": "2025-08-06T02:00:59.000Z",
    "textPlain": "Reddit post with generated audio sample: https://www.reddit.com/r/LocalLLaMA/comments/1mhyzp7/kitten_...",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44806734,
    "by": "nine_k",
    "timeISO": "2025-08-06T01:42:51.000Z",
    "textPlain": "I hope this is the future. Offline, small ML models, running inference on ubiquitous, inexpensive hardware. Models that are easy to integrate into other things, into devices and apps, and even to drive from other models maybe.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44812882,
    "by": "peanut_merchant",
    "timeISO": "2025-08-06T14:55:53.000Z",
    "textPlain": "I ran some quick benchmarks.Ubuntu 24, Razer Blade 16, Intel Core i9-14900HX  Performance Results:\n\n  Initial Latency: ~315ms for short text\n\n  Audio Generation Speed (seconds of audio per second of processing):\n  - Short text (12 chars): 3.35x realtime\n  - Medium text (100 chars): 5.34x realtime\n  - Long text (225 chars): 5.46x realtime\n  - Very Long text (306 chars): 5.50x realtime\n\n  Findings:\n  - Model loads in ~710ms\n  - Generates audio at ~5x realtime speed (excluding initial latency)\n  - Performance is consistent across different voices (4.63x - 5.28x realtime)",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44806821,
    "by": "blopker",
    "timeISO": "2025-08-06T02:00:17.000Z",
    "textPlain": "Web version: https://clowerweb.github.io/kitten-tts-web-demo/It sounds ok, but impressive for the size.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44807476,
    "by": "MutedEstate45",
    "timeISO": "2025-08-06T03:58:43.000Z",
    "textPlain": "The headline feature isn’t the 25 MB footprint alone. It’s that KittenTTS is Apache-2.0. That combo means you can embed a fully offline voice in Pi Zero-class hardware or even battery-powered toys without worrying about GPUs, cloud calls, or restrictive licenses. In one stroke it turns voice everywhere from a hardware/licensing problem into a packaging problem. Quality tweaks can come later; unlocking that deployment tier is the real game-changer.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44844952,
    "by": "skurtcastle",
    "timeISO": "2025-08-09T08:31:38.000Z",
    "textPlain": "Not bad. Something I would not want to listen for long without more clarity. Could work very well for non-english speakers in various tools an such.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44808718,
    "by": "antisol",
    "timeISO": "2025-08-06T07:15:54.000Z",
    "textPlain": "System Requirements\n  Works literally everywhere\n\nHaha, on one of my machines my python version is too old, and the package/dependencies don't want to install.On another machie the python version is too new, and the package/dependencies don't want to install.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44808551,
    "by": "klipklop",
    "timeISO": "2025-08-06T06:52:53.000Z",
    "textPlain": "I tried it. Not bad for the size (of the model) and speed. Once you install all the massive number of libraries and things needed we are a far cry away from 25MB though. Cool project nonetheless.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44807122,
    "by": "keyle",
    "timeISO": "2025-08-06T02:58:42.000Z",
    "textPlain": "I don't mind so much the size in MB, the fact that it's pure CPU and the quality, what I do mind however is the latency. I hope it's fast.Aside: Are there any models for understanding voice to text, fully offline, without training?I will be very impressed when we will be able to have a conversation with an AI at a natural rate and not \"probe, space, response\"",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44807307,
    "by": "sandreas",
    "timeISO": "2025-08-06T03:32:33.000Z",
    "textPlain": "Cool.While I think this is indeed impressive and has a specific use case (e.g. in the embedded sector), I'm not totally convinced that the quality is good enough to replace bigger models.With fish-speech[1] and f5-tts[2] there are at least 2 open source models pushing the quality limits of offline text-to-speech. I tested F5-TTS with an old NVidia 1660 (6GB VRAM) and it worked ok-ish, so running it on a little more modern hardware will not cost you a fortune and produce MUCH higher quality with multi-language and zero-shot support.For Android there is SherpaTTS[3], which plays pretty well with most TTS Applications.1: https://github.com/fishaudio/fish-speech2: https://github.com/SWivid/F5-TTS3: https://github.com/woheller69/ttsengine",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44806961,
    "by": "wkat4242",
    "timeISO": "2025-08-06T02:26:33.000Z",
    "textPlain": "Hmm the quality is not so impressive. I'm looking for a really naturally sounding model. Not very happy with piper/kokoro, XTTS was a bit complex to set up.For STT whisper is really amazing. But I miss a good TTS. And I don't mind throwing GPU power at it. But anyway. this isn't it either, this sounds worse than kokoro.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44809481,
    "by": "dr_kiszonka",
    "timeISO": "2025-08-06T08:48:19.000Z",
    "textPlain": "Microsoft's and some of Google's TTS models make the simplest mistakes. For instance, they sometimes read \"i.e.\" as \"for example.\" This is a problem if you have low vision and use TTS for, say, proofreading your emails.Why does it happen? I'm genuinely curious.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44806727,
    "by": "GaggiX",
    "timeISO": "2025-08-06T01:41:31.000Z",
    "textPlain": "https://huggingface.co/KittenML/kitten-tts-nano-0.1https://github.com/KittenML/KittenTTSThis is the model and Github page, this blog post looks very much AI generated.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44806757,
    "by": "toisanji",
    "timeISO": "2025-08-06T01:49:16.000Z",
    "textPlain": "Wow, amazing and good work, I hope to see more amazing models running on CPUs!",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44807532,
    "by": "vahid4m",
    "timeISO": "2025-08-06T04:07:11.000Z",
    "textPlain": "amazing! \ncan't wait to integrate it into https://desktop.with.audio\nI'm already using KokorosTTS without a GPU. It works fairly well on Apple Silicon.Foundational tools like this open up the possiblity of one-time payment or even free tools.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44810866,
    "by": "spapas82",
    "timeISO": "2025-08-06T12:05:26.000Z",
    "textPlain": "This great for english, but is there something similar for other languages? Could this be trained somehow to support other languages?",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44806882,
    "by": "pkaye",
    "timeISO": "2025-08-06T02:11:35.000Z",
    "textPlain": "Where does the training data come for the models? Is there an openly available dataset the people use?",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44806817,
    "by": "onair4you",
    "timeISO": "2025-08-06T01:59:07.000Z",
    "textPlain": "Okay, lots of details information and example code, great. But skimming through I didn’t see any audio samples to judge the quality?",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44807922,
    "by": "dang",
    "timeISO": "2025-08-06T05:12:49.000Z",
    "textPlain": "Most of these comments were originally posted to a different thread (https://news.ycombinator.com/item?id=44806543). I've moved them hither because on HN we always prefer to give the project creators credit for their work.(it does however explain how many of these comments are older than the thread they are now children of)",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44809815,
    "by": "ricardobeat",
    "timeISO": "2025-08-06T09:33:37.000Z",
    "textPlain": "The samples featured elsewhere seem to be from a larger model?After testing this locally, it still sounds quite mechanical, and fails catastrophically for simple phrases with numbers (\"easy as 1-2-3\"). If the 80M model can improve on this and keep the expressiveness seen in the reddit post, that looks promising.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44807444,
    "by": "maxloh",
    "timeISO": "2025-08-06T03:53:34.000Z",
    "textPlain": "Hi. Will the training and fine-tuning code also be released?It would be great if the training data were released too!",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44809330,
    "by": "killerstorm",
    "timeISO": "2025-08-06T08:30:29.000Z",
    "textPlain": "I'm curious why smallish TTS models have metallic voice quality.The pronunciation sounds about right - i thought it's the hard part. And the model does it well. But voice timbre should be simpler to fix? Like, a simple FIR might improve it?",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44809971,
    "by": "rishav_sharan",
    "timeISO": "2025-08-06T09:56:02.000Z",
    "textPlain": "Question for the experts here; What would be a SOTA TTS that can run on an average laptop (32GB RAM, 4GB VRAM). I just want to attach a TTS to my SLM output, and get the highest possible voice quality/ human resembleness.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44814995,
    "by": "77pt77",
    "timeISO": "2025-08-06T17:28:58.000Z",
    "textPlain": "How does this compare to say piper-tts?I ask because their models are pretty small. Some sound awesome and there is no depdendency hell like I'm seeing here.Example: https://rhasspy.github.io/piper-samples/#en_US-ryan-high",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44808311,
    "by": "babycommando",
    "timeISO": "2025-08-06T06:12:53.000Z",
    "textPlain": "Someone please port this to ONNX so we don't need to do all this ass tooling",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44833132,
    "by": "csukuangfj",
    "timeISO": "2025-08-08T03:36:34.000Z",
    "textPlain": "I have tested its speed on CPU and compared it with Piper, kokoro, and matcha. See https://github.com/KittenML/KittenTTS/issues/40",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44812641,
    "by": "the_arun",
    "timeISO": "2025-08-06T14:38:51.000Z",
    "textPlain": "I like the direction we are heading. Build models that can run on CPUs & AI can become even more mainstream.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44808332,
    "by": "victorbjorklund",
    "timeISO": "2025-08-06T06:15:45.000Z",
    "textPlain": "It is not the best TTS but it is freaking amazing it can be done by such a small model and it is good enough for so many use cases.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44806906,
    "by": "RobKohr",
    "timeISO": "2025-08-06T02:16:41.000Z",
    "textPlain": "What's a good one in reverse; speech to text?",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44809042,
    "by": "tapper",
    "timeISO": "2025-08-06T07:54:42.000Z",
    "textPlain": "I am blind and use NVDA with a sinth. How is this news? I don't get it! My sinth is called eloquence and is 4089KB",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44812537,
    "by": "akx",
    "timeISO": "2025-08-06T14:30:04.000Z",
    "textPlain": "This is a fun model for circuit-bending, because the voice style vectors are pretty small.For instance, try adding `np.random.shuffle(ref_s[0])` after the line `ref_s = self.voices[voice]`...EDIT: be careful with your system volume settings if you do this.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44809761,
    "by": "junon",
    "timeISO": "2025-08-06T09:25:47.000Z",
    "textPlain": "This feels different. This feels like a genuinely monumental release. Holy cow.Very well done. The quality is excellent and the technical parameters are, simply, unbelievable. Makes me want to try to embed this on a board just to see if it's possible.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44810139,
    "by": "alexnewman",
    "timeISO": "2025-08-06T10:19:20.000Z",
    "textPlain": "I'm so confused on how the model is actually made. It doesn't seem to be in the code or this stuff is way simpler than i thought. It seems to use a fancy library from japan, not sure how much it's just that",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44812711,
    "by": "butz",
    "timeISO": "2025-08-06T14:43:42.000Z",
    "textPlain": "How does one build similar model, but for different languages? I was under impression that being open source, there would be some instructions how to build everything on your own.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44810971,
    "by": "dirkc",
    "timeISO": "2025-08-06T12:16:47.000Z",
    "textPlain": "Have you considered adding some 'rendered' examples of what the model sounds like?I'm curious, but right now I don't want to install the package and run some code.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44809916,
    "by": "tecleandor",
    "timeISO": "2025-08-06T09:47:55.000Z",
    "textPlain": "Not bad for the size (with my very limited knowledge of this field) !In a couple tests, the \"Male 2\" voice sounds reasonable, but I've found it has problem with some groups of words, specially when played with little context. I think it's small sentences.For example, if you try to do just \"Hey gang!\", it will sound something like \"Chay yang\". But if you add an additional sentence after that, it will sound a bit different (but still weird).",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44814643,
    "by": "gunalx",
    "timeISO": "2025-08-06T17:01:38.000Z",
    "textPlain": "Would love to se something like this trained for multilingual purposes. It seems kinda like the same tier as piper, but a bit faster.",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44807590,
    "by": "wewewedxfgdf",
    "timeISO": "2025-08-06T04:19:01.000Z",
    "textPlain": "Chrome does TTS too.https://codepen.io/logicalmadboy/pen/RwpqMRV",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44810498,
    "by": "binary132",
    "timeISO": "2025-08-06T11:14:52.000Z",
    "textPlain": "I’m new to TTS models but is this something I can plug into my own engine like with LLMs, or does it require the Python stack it ships with?",
    "parent": 44807868,
    "depth": 1
  },
  {
    "id": 44811150,
    "by": "C-Loftus",
    "timeISO": "2025-08-06T12:36:57.000Z",
    "textPlain": "Awesome work! Often times in the TTS space, human-similarity is given way too much emphasis at the expense of hurting user access. Frankly as long as a voice is clear and you listen to it for a while, the brain filters out most quirks you would perceive on the first pass. Hence why many blind folks still are perfectly fine using espeak-ng. The other properties like speed of generation and size make it worth it.I've been using a custom AI audiobook generation program [0] with piper for quite a while now and am very excited to look at integrating kitten. Historically piper has been the only good option for a free CPU-only local model so I am super happy to see more competition in the space. Easy installation is a big deal, since piper historically has had issues with that. (Hence why I had to add auto installation support in [0])[0] https://github.com/C-Loftus/QuickPiperAudiobook",
    "parent": 44807868,
    "depth": 1
  }
]