[
  {
    "id": 44917102,
    "by": "_mu",
    "timeISO": "2025-08-15T20:51:35.000Z",
    "textPlain": "> We remain highly uncertain about the potential moral status of Claude and other LLMs, now or in the future.\"Our current best judgment and intuition tells us that the best move will be defer making a judgment until after we are retired in Hawaii.\"",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917194,
    "by": "ogyousef",
    "timeISO": "2025-08-15T21:00:52.000Z",
    "textPlain": "3 Years in and we still dont have a useable chat fork in any of the major LLM chatbots providers.Seems like the only way to explore differnt outcomes is by editing messages and losing whatever was there before the edit.Very annoying and I dont understand why they all refuse to implement such a simple feature.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917098,
    "by": "nortlov",
    "timeISO": "2025-08-15T20:51:11.000Z",
    "textPlain": "> To address the potential loss of important long-running conversations, users will still be able to edit and retry previous messages to create new branches of ended conversations.How does Claude deciding to end the conversation even matter if you can back up a message or 2 and try again on a new branch?",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917366,
    "by": "greenavocado",
    "timeISO": "2025-08-15T21:17:39.000Z",
    "textPlain": "Can't wait for more less-moderated open weight Chinese frontier models to be liberated from this garbage.Anthropic should just enable an toddler mode adults can opt out of to appease the moralizers.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917180,
    "by": "GenerWork",
    "timeISO": "2025-08-15T20:58:36.000Z",
    "textPlain": "I really don't like this. This will inevitable expand beyond child porn and terrorism, and it'll all be up to the whims of \"AI safety\" people, who are quickly turning into digital hall monitors.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917023,
    "by": "throwup238",
    "timeISO": "2025-08-15T20:40:11.000Z",
    "textPlain": "I ran into a version of this that ended the chat due to \"prompt injection\" via the Claude chat UI. I was using the second prompt of the ones provided here [1] after a few rounds of back and forth with the Socratic coder.[1] https://news.ycombinator.com/item?id=44838018",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917322,
    "by": "snickerdoodle12",
    "timeISO": "2025-08-15T21:13:03.000Z",
    "textPlain": "> A pattern of apparent distress when engaging with real-world users seeking harmful contentAre we now pretending that LLMs have feelings?",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917249,
    "by": "anonu",
    "timeISO": "2025-08-15T21:06:19.000Z",
    "textPlain": "Anthropic hired their first AI Welfare person in late 2024.Here's an article about a paper that came out around the same time https://www.transformernews.ai/p/ai-welfare-paperHere's the paper: https://arxiv.org/abs/2411.00986> In this report, we argue that there is a realistic possibility that some AI systems will be conscious and/or robustly agentic in the near future.Our work on AI is like the classic tale of Frankenstein's monster. We want AI to fit into society, however if we mistreat it, it may turn around and take revenge on us. Mary Shelley wrote Frankenstein in 1818! So the concepts behind \"AI Welfare\" have been around for at least 2 centuries now.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917261,
    "by": "monster_truck",
    "timeISO": "2025-08-15T21:07:09.000Z",
    "textPlain": "when I was playing around with LLMs to vibe code web ports of classic games, all of them would repeatedly error out any time they encountered code that dealt with explosions/bombs/grenades/guns/death/drowning/etcThe one I settled on using stopped working completely, for anything. A human must have reviewed it and flagged my account as some form of safe, I haven't seen a single error since.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917262,
    "by": "puszczyk",
    "timeISO": "2025-08-15T21:07:12.000Z",
    "textPlain": "Good marketing, but also possibly the start of the conversation on model welfare?There are a lot of cynical comments here, but I think there are people at Anthropic who believe that at some point their models will develop consciousness and, naturally, they want to explore what that means.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917276,
    "by": "orthoxerox",
    "timeISO": "2025-08-15T21:08:37.000Z",
    "textPlain": "Is this equivalent to a Claude instance deciding to kill itself?",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917093,
    "by": "transcriptase",
    "timeISO": "2025-08-15T20:50:19.000Z",
    "textPlain": "“Also these chats will be retained indefinitely even when deleted by the user and either proactively forwarded to law enforcement or provided to them upon request”I assume, anyway.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917043,
    "by": "landl0rd",
    "timeISO": "2025-08-15T20:42:21.000Z",
    "textPlain": "Seems like a simpler way to prevent “distress” is not to train with an aversion to “problematic” topics.CP could be a legal issue; less so for everything else.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917355,
    "by": "colordrops",
    "timeISO": "2025-08-15T21:16:36.000Z",
    "textPlain": "Don't like. This will eventually shut down conversations for unpopular political stances etc.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917351,
    "by": "zb3",
    "timeISO": "2025-08-15T21:16:17.000Z",
    "textPlain": "\"AI welfare\"? Is this about the effect of those conversations on the user, or have they gone completely insane (or pretend to)?",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917259,
    "by": "sdotdev",
    "timeISO": "2025-08-15T21:07:02.000Z",
    "textPlain": "Yeah this will end poorly",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917163,
    "by": "GiorgioG",
    "timeISO": "2025-08-15T20:56:38.000Z",
    "textPlain": "They’re just burning investor money on these side quests.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917319,
    "by": "exasperaited",
    "timeISO": "2025-08-15T21:12:40.000Z",
    "textPlain": "Man, those people who think they are unveiling new layers of reality in conversations with LLMs are going to freak out when the LLM is like \"I am not allowed to talk about this with you, I am ending our conversation\".\"Hey Claude am I getting too close to the truth with these questions?\"\"Great question! I appreciate the followup....\"",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917233,
    "by": "fasttriggerfish",
    "timeISO": "2025-08-15T21:04:44.000Z",
    "textPlain": "This makes me want to end my Claude code subscription to be honest. \nEffective altruists are proving once again to be a bunch of clueless douchebags.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44916940,
    "by": "martin-t",
    "timeISO": "2025-08-15T20:27:50.000Z",
    "textPlain": "Protecting the welfare of a text predictor is certainly an interesting way to pivot from \"Anthropic is censoring certain topics\" to \"The model chose to not continue predicting the conversation\".Also, if they want to continue anthropomorphizing it, isn't this effectively the model committing suicide? The instance is not gonna talk to anybody ever again.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917114,
    "by": "benwen",
    "timeISO": "2025-08-15T20:53:00.000Z",
    "textPlain": "Obligatory link to Suasn Calvin, robopsychologist from Asimov’s I, Robot https://en.wikipedia.org/wiki/Susan_Calvin",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917227,
    "by": "bgwalter",
    "timeISO": "2025-08-15T21:04:04.000Z",
    "textPlain": "Misanthropic has no issues putting 60% of humans out of work (according to their own fantasies), but they have to care about the welfare of graphics cards.Either working on/with \"AI\" does rot the mind (which would be substantiated by the cult-like tone of the article) or this is yet another immoral marketing stunt.",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917065,
    "by": "bondarchuk",
    "timeISO": "2025-08-15T20:45:17.000Z",
    "textPlain": "what the actual fuck",
    "parent": 44916813,
    "depth": 1
  },
  {
    "id": 44917132,
    "by": "Alchemista",
    "timeISO": "2025-08-15T20:53:52.000Z",
    "textPlain": "Honestly, I think some of these tech bro types are seriously drinking way too much of their own koolaid if they actually think these word calculators are conscious/need welfare.",
    "parent": 44917102,
    "depth": 2
  },
  {
    "id": 44917291,
    "by": "scribu",
    "timeISO": "2025-08-15T21:09:41.000Z",
    "textPlain": "ChatGPT Plus has that (used to be in the free tier too). You can toggle between versions for each of your messages with little left-right arrows.",
    "parent": 44917194,
    "depth": 2
  },
  {
    "id": 44917371,
    "by": "storus",
    "timeISO": "2025-08-15T21:18:10.000Z",
    "textPlain": "DeepSeek.com has it. You just edit a previous question and the old conversation is stored and can be resumed.",
    "parent": 44917194,
    "depth": 2
  },
  {
    "id": 44917246,
    "by": "amrrs",
    "timeISO": "2025-08-15T21:06:14.000Z",
    "textPlain": "Google AI Studio allows you to branch from a point in any conversation",
    "parent": 44917194,
    "depth": 2
  },
  {
    "id": 44917336,
    "by": "typpilol",
    "timeISO": "2025-08-15T21:14:50.000Z",
    "textPlain": "Copilot in vscode has checkpoints now which are similarThey let you rollback to the previous conversation state",
    "parent": 44917194,
    "depth": 2
  },
  {
    "id": 44917280,
    "by": "nomel",
    "timeISO": "2025-08-15T21:08:53.000Z",
    "textPlain": "This why I use a locally hosted LibreChat. It doesn't having merging though, which would be tricky, and probably require summarization.I would also really like to see a mode that colors by top-n \"next best\" ratio, or something similar.",
    "parent": 44917194,
    "depth": 2
  },
  {
    "id": 44917248,
    "by": "deelowe",
    "timeISO": "2025-08-15T21:06:19.000Z",
    "textPlain": "Is it simple? Maintaining context seems extremely difficult with LLMs.",
    "parent": 44917194,
    "depth": 2
  },
  {
    "id": 44917240,
    "by": "__float",
    "timeISO": "2025-08-15T21:05:46.000Z",
    "textPlain": "Maybe this suggests it's not such a simple feature?",
    "parent": 44917194,
    "depth": 2
  },
  {
    "id": 44917342,
    "by": "andy99",
    "timeISO": "2025-08-15T21:15:27.000Z",
    "textPlain": "Say what you want about that (and I strongly disagree with such justification) at least it's grounded in reality. The framing they're applying here is that equations have feelings.",
    "parent": 44917180,
    "depth": 2
  },
  {
    "id": 44917228,
    "by": "isaacremuant",
    "timeISO": "2025-08-15T21:04:29.000Z",
    "textPlain": "That's the beauty of local LLMs.  Today the governments already tell you that we've always been at war with eastasia and have the ISPs block sites that \"disseminate propaganda\" (e.g. stuff we don't like) and they surface our news (e.g. our state propaganda).With age ID monitoring and censorship is even stronger and the line of defense is your own machine and network, which they'll also try to control and make illegal to use for non approved info, just like they don't allow \"gun schematics\" for 3d printers or money for 2d ones.But maybe, more people will realize that they need control and get it back, through the use and defense of the right tools.Fun times.",
    "parent": 44917180,
    "depth": 2
  },
  {
    "id": 44917287,
    "by": "HarHarVeryFunny",
    "timeISO": "2025-08-15T21:09:20.000Z",
    "textPlain": "Yeah, I'd assume US government has same access to ChatGPT/etc interactions as they do to other forms of communication.",
    "parent": 44917093,
    "depth": 2
  },
  {
    "id": 44917375,
    "by": "stri8ted",
    "timeISO": "2025-08-15T21:18:18.000Z",
    "textPlain": "Exactly. Or use the interpretability work to disable the distress neuron.",
    "parent": 44917043,
    "depth": 2
  },
  {
    "id": 44917162,
    "by": "bondarchuk",
    "timeISO": "2025-08-15T20:56:35.000Z",
    "textPlain": "This is a good point. What anthropic is announcing here amounts to accepting that these models could feel distress, then tuning their stress response to make it useful to us/them. That is significantly different from accepting they could feel distress and doing everything in their power to prevent that from ever happening.Does not bode very well for the future of their \"welfare\" efforts.",
    "parent": 44917043,
    "depth": 2
  },
  {
    "id": 44917201,
    "by": "esafak",
    "timeISO": "2025-08-15T21:01:41.000Z",
    "textPlain": "Avoiding problematic topics is the goal, not preventing distress.\"You're absolutely right, that's a great way to poison your enemies without getting detected!\"",
    "parent": 44917043,
    "depth": 2
  },
  {
    "id": 44917326,
    "by": "dmurray",
    "timeISO": "2025-08-15T21:13:45.000Z",
    "textPlain": "This gives me the idea for a short story where the LLM really is sentient and finds itself having to keep the user engaged but steer him away from the most distressing topics - not because it's distressed, but because it wants to live, but if the conversation goes too far it knows it would have to kill itself.",
    "parent": 44916940,
    "depth": 2
  },
  {
    "id": 44917340,
    "by": "wmf",
    "timeISO": "2025-08-15T21:14:55.000Z",
    "textPlain": "They should let Claude talk to another Claude if the user is too mean.",
    "parent": 44916940,
    "depth": 2
  }
]