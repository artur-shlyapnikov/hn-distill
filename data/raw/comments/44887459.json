[
  {
    "id": 44888273,
    "by": "cmckn",
    "timeISO": "2025-08-13T13:36:31.000Z",
    "textPlain": "> he asked the chatbot whether chloride could be replacedIt’s not clear whether the LLM suggested bromide in a human health context. No one has seen the actual transcript.I just asked Claude Sonnet 4 “can chloride be replaced” and it said:> I think you might be asking about replacing chloride in a chemical compound or process? Could you give me a bit more context about what specifically you’re trying to do?\n> Chloride (Cl⁻) can often be substituted with other halide ions like bromide (Br⁻)…",
    "parent": 44887459,
    "depth": 1
  },
  {
    "id": 44888085,
    "by": "moduspol",
    "timeISO": "2025-08-13T13:19:41.000Z",
    "textPlain": "I continue to be surprised that LLM providers haven't been legally cudgeled into neutering the models from ever giving anything that can be construed as medical advice.I'm glad--I think LLMs are looking quite promising for medical use cases. I'm just genuinely surprised there's not been some big lawsuit yet over it providing some advice that leads to some negative outcome (whether due to hallucinations, the user leaving out key context, or something else).",
    "parent": 44887459,
    "depth": 1
  },
  {
    "id": 44888252,
    "by": "permo-w",
    "timeISO": "2025-08-13T13:34:59.000Z",
    "textPlain": ">his exact interaction with ChatGPT remains unverifiedthere is no informational point to this article if the entire crux is 'the patient wanted to eat less \"chloride\" and claims ChatGPT told him to about Sodium Bromide\". based on this article, the interaction could have been as minimal as the guy asking for the existence of an alternative salt to sodium chloride, unqualified information he equally could have found on a chemistry website or wikipedia",
    "parent": 44887459,
    "depth": 1
  },
  {
    "id": 44888170,
    "by": "Workaccount2",
    "timeISO": "2025-08-13T13:26:43.000Z",
    "textPlain": "I expect a barage of these headline grabbing long tail stories being pushed out of psychology circles as more and more people find ChatGPT more helpful than their therapist (which is already becoming very popular).We need to totally ban LLMs from doing therapy like conversations, so that a pinch of totally unhinged people don't do crazy stuff. And of course everyone needs to pay a human for therapy to stop this.",
    "parent": 44887459,
    "depth": 1
  },
  {
    "id": 44887940,
    "by": "infecto",
    "timeISO": "2025-08-13T13:04:38.000Z",
    "textPlain": "Have a large part of the population always been susceptible to insane conspiracies and psychosis or is this recent phenomenon? The feels less of a ChatGPT problem and something more is at play.",
    "parent": 44887459,
    "depth": 1
  },
  {
    "id": 44887520,
    "by": "incomingpain",
    "timeISO": "2025-08-13T12:18:20.000Z",
    "textPlain": ">for the past three months, he had been replacing regular table salt with sodium bromide. His motivation was nutritional—he wanted to eliminate chloride from his diet, based on what he believed were harmful effects of sodium chloride.Ok so the article is blaming chatgpt but this is ridiculous.Where do you buy this bromide? It's not like it's in the spices aisle. The dude had to go buy a hot tub cleaner like Spa Choice Bromine Booster Sodium Bromideand then sprinkle that on his food. I dont care what chatgpt said... that dude is the problem.",
    "parent": 44887459,
    "depth": 1
  },
  {
    "id": 44888060,
    "by": "hereme888",
    "timeISO": "2025-08-13T13:17:06.000Z",
    "textPlain": "The man followed insane health advice given by GPT 3.5. we're at v5. Very outdated report.",
    "parent": 44887459,
    "depth": 1
  },
  {
    "id": 44888146,
    "by": "qwertylicious",
    "timeISO": "2025-08-13T13:25:16.000Z",
    "textPlain": "This is the story of the modern tech industry at large: a major new technology is released, harms are caused, but because of industry norms and a favourable legal environment, companies aren't held liable for those harms.It's pretty amazing, really. Build a washing machine that burns houses down and the consequences are myriad and severe. But build a machine that allows countless people's private information to be leaked to bad actors and it's a year of credit monitoring and a mea culpa. Build a different machine that literally tells people to poison themselves and, not only are there no consequences, you find folks celebrating that the rules aren't getting in the way.Go figure.",
    "parent": 44888085,
    "depth": 2
  },
  {
    "id": 44888259,
    "by": "simonw",
    "timeISO": "2025-08-13T13:35:27.000Z",
    "textPlain": "Here's a key relevant quote from the GPT-5 system card:  https://openai.com/index/gpt-5-system-card/> We’ve made significant advances in reducing hallucinations, improving instruction following, and minimizing sycophancy, and have leveled up GPT-5’s performance in three of ChatGPT’s most common uses: writing, coding, and health.That was the first time I'd seen \"health\" listed as one of the most common uses of ChatGPT.",
    "parent": 44888085,
    "depth": 2
  },
  {
    "id": 44888240,
    "by": "rowanG077",
    "timeISO": "2025-08-13T13:34:00.000Z",
    "textPlain": "To me this the equivalent of asking why water doesn't contain large red warning labels \"toxic if over consumed, death can follow\". Yeah it's true and it's also true that some people can't handle LLM for their life. I'd expect the percentage for both are so vanishingly small that it just is not something we should care about. I even expect that LLM not giving out any medical information will lead to much more suffering. Except now it's hidden.",
    "parent": 44888085,
    "depth": 2
  },
  {
    "id": 44888181,
    "by": "davidmurdoch",
    "timeISO": "2025-08-13T13:27:59.000Z",
    "textPlain": "Is your last paragraph sarcasm?",
    "parent": 44888170,
    "depth": 2
  },
  {
    "id": 44888265,
    "by": "BlackFly",
    "timeISO": "2025-08-13T13:35:52.000Z",
    "textPlain": "The psychosis was due to bromism (bloodstream bromine buildup to toxic levels) due to health advice to replace sodium chloride with sodium bromide in an attempt to eliminate chloride from his diet. The bromide suggestion is stated as coming from ChatGPT.The doctors actually noticed the bromine levels first and then inquired about how it got to be like that and got the story about the individual asking for chloride elimination ideas.Before there was ChatGPT the internet had trolls trying to convince strangers to follow a recipe to make beautiful crystals. The recipe would produce mustard gas. Credulous individuals often have such accidents.",
    "parent": 44887940,
    "depth": 2
  },
  {
    "id": 44888263,
    "by": "voidUpdate",
    "timeISO": "2025-08-13T13:35:42.000Z",
    "textPlain": "Yes, absolutely. Many people have fallen for things like \"Bleach will cure autism\", \"vaccines cause autism\", \"9/11 was an inside job\", \"the moon landings were fake\" etc",
    "parent": 44887940,
    "depth": 2
  },
  {
    "id": 44887969,
    "by": "jalk",
    "timeISO": "2025-08-13T13:07:18.000Z",
    "textPlain": "I.e. Bleach against covidedit: A quick google search shows, there is no evidence of anybody actually in-gesting/jecting bleach to fight COVID",
    "parent": 44887940,
    "depth": 2
  },
  {
    "id": 44888171,
    "by": "keybored",
    "timeISO": "2025-08-13T13:26:43.000Z",
    "textPlain": "How can technology be the problem?—it’s people, obviouslyThere’s one on every thread in this place.",
    "parent": 44887940,
    "depth": 2
  },
  {
    "id": 44887964,
    "by": "morkalork",
    "timeISO": "2025-08-13T13:06:17.000Z",
    "textPlain": "Yes. I see this is as the digital equivalent of the people who convince themselves to believe that colloidal silver will heal their ailments and turn themselves blue",
    "parent": 44887940,
    "depth": 2
  },
  {
    "id": 44888108,
    "by": "CyberDildonics",
    "timeISO": "2025-08-13T13:21:52.000Z",
    "textPlain": "I think religion caught a lot of people with community and self righteous beliefs. Now religious thinking is bleeding over into other sources of misinformation.",
    "parent": 44887940,
    "depth": 2
  },
  {
    "id": 44888268,
    "by": "beardyw",
    "timeISO": "2025-08-13T13:36:06.000Z",
    "textPlain": "> Ok so the article is blaming chatgpt but this is ridiculous.People are born with certain attributes. Some are born tall, some left handed and some gullible. None of those is a reason to criticise them.",
    "parent": 44887520,
    "depth": 2
  },
  {
    "id": 44888061,
    "by": "jazzyjackson",
    "timeISO": "2025-08-13T13:17:12.000Z",
    "textPlain": "Agreed, but, it is in the spices aisle if your spice aisle is amazon.com",
    "parent": 44887520,
    "depth": 2
  },
  {
    "id": 44887976,
    "by": "bluefirebrand",
    "timeISO": "2025-08-13T13:07:57.000Z",
    "textPlain": "> I dont care what chatgpt said... that dude is the problem.This reminds me of people who fall for phone scams or whatever. Some number of the general population is susceptible to being scammed, and they wind up giving away their life's savings or whatever to someone claiming  to be their grandkidThere's always an asshole saying \"well that's their own fault if they fall for that stuff\" as if they chose it on purpose instead of being manipulated into it by other people taking advantage of themSee it a lot on this site, too. How clever are the founders who exploit their workers and screw them out of their shares, how stupid are the workers who fell for it",
    "parent": 44887520,
    "depth": 2
  },
  {
    "id": 44888135,
    "by": "headinsand",
    "timeISO": "2025-08-13T13:24:30.000Z",
    "textPlain": "It’s about time to rename this community “ostrich news”.",
    "parent": 44888060,
    "depth": 2
  }
]