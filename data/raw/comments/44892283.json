[
  {
    "id": 44921941,
    "by": "keiferski",
    "timeISO": "2025-08-16T10:18:23.000Z",
    "textPlain": "There’s a simple flaw in this reasoning:Just because X can be replaced by Y today doesn’t imply that it can do so in a Future where we are aware of Y, and factor it into the background assumptions about the task.In more concrete terms: if “not being powered by AI” becomes a competitive advantage, then AI won’t be meaningfully replacing anything in that market.You can already see this with YouTube: AI-generated videos are a mild amusement, not a replacement for video creators, because made by AI is becoming a negative label in a world where the presence of AI video is widely known.Of course this doesn’t apply to every job, and indeed many jobs have already been “replaced” by AI. But any analysis which isn’t reflectively factoring in the reception of AI into the background is too simplistic.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919588,
    "by": "btilly",
    "timeISO": "2025-08-16T02:26:42.000Z",
    "textPlain": "In every technology wave so far, we've disrupted many existing jobs. However we've also opened up new kinds of jobs. And, because it is easier to retrain humans than build machines for those jobs, we wound up with more and better jobs.This is the first technology wave that doesn't just displace humans, but which can be trained to the new job opportunities more easily than humans can. Right now it can't replace humans for a lot of important things. But as its capabilities improve, what do displaced humans transition to?I don't think that we have a good answer to that. And we may need it sooner rather than later. I'd be more optimistic if I trusted our leadership more. But wise political leadership is not exactly a strong point for our country right now.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919860,
    "by": "_jab",
    "timeISO": "2025-08-16T03:26:25.000Z",
    "textPlain": "I'm skeptical of arguments like this. If we look at most impactful technologies since the year 2000, AI is not even in my top 3. Social networking, mobile computing, and cloud computing have all done more to alter society and daily life than has AI.And yes, I recognize that AI has already created profound change, in that every software engineer now depends heavily on copilots, in that education faces a major integrity challenge, and in that search has been completely changed. I just don't think those changes are on the same level as the normalization of cutting-edge computers in everyone's pockets, as our personal relationships becoming increasingly online, nor as the enablement for startups to scale without having to maintain physical compute infrastructure.To me, the treating of AI as \"different\" is still unsubstantiated. Could we get there? Absolutely. We just haven't yet. But some people start to talk about it almost in a way that's reminiscent of Pascal's Wager, as if the slight chance of a godly reward from producing AI means it is rational to devote our all to it. But I'm still holding my breath.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920295,
    "by": "itsalotoffun",
    "timeISO": "2025-08-16T04:54:31.000Z",
    "textPlain": "> The future may reduce the economic prosperity and push humanity to switch to some different economic system (maybe a better system). Markets don’t want to accept that. [Emphasis added]What a silly premise. Markets don't care. All markets do is express the collective opinion; in the short term as a voting machine, in the long term as a weighing machine.Seeing a real uptick of socio-policital prognostication from extremely smart, soaked-in-AI, tech people (like you Salvatore!), casting heavy doom-laden gestures towards the future. You're not even wrong! But this \"I see something you all clearly don't\" narrative, wafer thin on real analysis, packed with \"the feels\", coated with what-ifs.. it's sloppy thinking and I hold you to a higher standard antirez.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920532,
    "by": "econ",
    "timeISO": "2025-08-16T05:43:53.000Z",
    "textPlain": "For me it maps elegantly on previous happenings.When the radio came people almost instantly stopped singing and playing instruments. Many might not be aware of it but for thousands of years singing was a normal expression of a good mood and learning to play an instrument was a gateway to lifting the mood. Dancing is still in working order but it lacks the emotional depth that provided a window into the soul of those you live and work with.A simpler example is the calculator. People stopped doing it by hand and forgot how.Most desk work is going to get obliterated. We are going to forget how.The underlings on the work floor currently know little to nothing about management. If they can query an AI in private it will point out why their idea is stupid or it will refine it into something sensible enough to try. Eventually you say the magic words and the code to make it so happens. If it works you put it live. No real thinking required.Early on you probably get large AI cleanup crews to fix the hallucinations (with better prompts)",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921872,
    "by": "tobyhinloopen",
    "timeISO": "2025-08-16T10:01:15.000Z",
    "textPlain": "It's not a matter of \"IF\" LLM/AI will replace a huge amount of people, but \"WHEN\". Consider the current amount of somewhat low-skilled administrative jobs - these can be replaced with the LLM/AI's of today. Not completely, but 4 low-skill workers can be replaced with 1 supervisor, controlling the AI agent(s).I'd guess, within a few years, 5 to 10% of the total working population will be unemployable due to no fault of their own, because they have relevant skill left, and they are incapable of learning anything that cannot be done by AI.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919650,
    "by": "ahurmazda",
    "timeISO": "2025-08-16T02:41:07.000Z",
    "textPlain": "When I hear folks glazing some kinda impending jobless utopia , I think of the intervening years. I shudder. As they say, \"An empty stomach knows no morality.\"",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920174,
    "by": "Davidzheng",
    "timeISO": "2025-08-16T04:27:13.000Z",
    "textPlain": "I actually find it hard to understand how the market is supposed to react if the AI capabilities does surpass all humans in all domains. It's first of all not clear such a scenario leads to runaway wealth for a few, even though with no outside events that may be the outcome. However, such scenarios are so unsustainable and catastrophic it's hard to imagine there are no catastrophic reactions to it. How is the market supposed to react if there's a large chance of market collapse and also a large chance of runaway wealth creation? Besides the point that in an economy where AI surpass humans the demands of the market will shift drastically too. Which I also think is underrepresented in predictions, which is the induced demand of AI-replaced labor and the potential for entire industries to be decimated by secondary effects instead of direct AI competition/replacement at labor scale.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919974,
    "by": "atleastoptimal",
    "timeISO": "2025-08-16T03:51:04.000Z",
    "textPlain": "This is an accurate assessment. I do feel that there is a routine bias on HN to underplay AI. I think it's people not wanting to lose control or relative status in the world.AI is an existential threat to the unique utility of humans, which has been the last line of defense against absolute despotism (i.e. a tyrannical government will not kill all its citizens because it still needs them to perform jobs. If humans aren't needed to sustain productivity, humans have no leverage against things becoming significantly worse for them, gradually or all at once).",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919671,
    "by": "aurareturn",
    "timeISO": "2025-08-16T02:45:20.000Z",
    "textPlain": "We are not there, yet, but if AI could replace a sizable amount of workers, the economic system will be put to a very hard test. Moreover, companies could be less willing to pay for services that their internal AIs can handle or build from scratch.\n\nThere will be fewer very large companies in terms of human size. There will be many more companies that are much smaller because you don't need as many workers to do the same job.Instead of needing 1000 engineers to build a new product, you'll need 100 now. Those 900 engineers will be working for 9 new companies that weren't viable before because the cost was too big but is now viable. IE. those 9 new companies could never be profitable if it required 1000 engineers each but can totally sustain itself with 100 engineers each.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921060,
    "by": "mycentstoo",
    "timeISO": "2025-08-16T07:24:11.000Z",
    "textPlain": "I am just not having this experience of AI being terribly useful. I don’t program as much in my role but I’ve found it’s a giant time sink. I recognize that many people are finding it incredibly helpful but when I get deeper into a particular issue or topic, it falls very flat.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921803,
    "by": "howtofly",
    "timeISO": "2025-08-16T09:45:50.000Z",
    "textPlain": "> The future may reduce the economic prosperity and push humanity to switch to some different economic system (maybe a better system).Humans never truly produce anything; they only generate various forms of waste (resulting from consumption). Human technology merely enables the extraction of natural resources across magnitudes, without actually creating any resources. Given its enormous energy consumption, I strongly doubt that AI will contribute to a better economic system.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919764,
    "by": "intended",
    "timeISO": "2025-08-16T03:08:06.000Z",
    "textPlain": "Could, if, and maybe.When we discuss how LLMs failed or succeeded, as a norm, we should start including- the language/framework\n- task, \n- our experience levels (highly familiar, moderately familiar, I think I suck, unfamiliar)Right now, we know both - Claude is magic, and LLMs are useless, but never how we move between these two states.This level of uncertainty, when economy making quantities of wealth are being moved, is “unhelpful”.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920778,
    "by": "andrewmutz",
    "timeISO": "2025-08-16T06:34:11.000Z",
    "textPlain": "Reading smart software people talk about AI in 2025 is basically just reading variations on the lump of labor fallacy.If you want to understand what AI can do, listen to computer scientists.  If you want to understand it’s likely impact on society, listen to economists.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921868,
    "by": "yubblegum",
    "timeISO": "2025-08-16T09:59:58.000Z",
    "textPlain": "Clear long term winners are energy producers. AI can replace everything including hardware design & production but it can not produce energy out of thin air.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919789,
    "by": "deepfriedbits",
    "timeISO": "2025-08-16T03:12:10.000Z",
    "textPlain": "I am a relentlessly optimistic person and this is the first technology that I've seen that worries me in the decades I've been in the biz.It's a wonderful breakthrough, nearly indistinguishable from magic, but we're going to have to figure something out – whether that's Universal Basic Income (UBI) or something along those lines, otherwise, the loss of jobs that is coming will lead to societal unrest or worse.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921472,
    "by": "xg15",
    "timeISO": "2025-08-16T08:43:57.000Z",
    "textPlain": "> Nor is it possible to imagine a system where a few mega companies are the only providers of intelligenceWhy not? This seems to be exactly where we're headed right now, and the current administration seems to be perfectly fine with that trend.If you follow the current logic of AI proponents, you get essentially:(1) Almost all white-collar jobs will be done better or at least faster by AI.(2) The \"repugnant conclusion\": AI gets better if and only if you throw more compute and training data at it. The improvements of all other approaches will be tiny in comparison.(3) The amount of capital needed to play the \"more compute/more training data\" game is already insanely high and will only grow further. So only the largest megacorps will be even able to take part in the competition.If you combine (1) with (3), this means that, over time, the economic choice for almost any white-collar job would be to outsource it to the data centers of the few remaining megacorps.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920722,
    "by": "codr7",
    "timeISO": "2025-08-16T06:20:22.000Z",
    "textPlain": "The biggest difference to me is that it seems to change people in bad ways, just from interacting with it.Language is a very powerful tool for transformation, we already knew this.Letting it loose on this scale without someone behind the wheel is begging for trouble imo.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921149,
    "by": "jrvarela56",
    "timeISO": "2025-08-16T07:40:22.000Z",
    "textPlain": "This whole ‘what are we going to do’ I think is way out of proportion even if we do end up with agi.Let’s say whatever the machines do better than humans, gets done by machines. Suddenly the bottleneck is going to shift to those things where humans are better. We’ll do that and the machines will try to replace that labor too. And then again, and again.Throughout this process society becomes wealthier, TVs get cheaper, we colonize Mars, etc. The force that keeps this going is human insatisfaction: once we get these things we’ll want whatever it is we don’t have.Maybe that’s the problem we should focus on solving…",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919713,
    "by": "solarkraft",
    "timeISO": "2025-08-16T02:56:12.000Z",
    "textPlain": "> After all, a plateau of the current systems is possible and very credible, but it would likely stimulate, at this point, massive research efforts in the next step of architectures.A lot of AI’s potential hasn’t even been realized yet. There’s a long tail of integrations and solution building still ahead. A lot of creative applications haven’t been realized yet - arguably for the better, but it will be tried and some will be economical.That’s a case for a moderate economic upturn though.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920254,
    "by": "s_ting765",
    "timeISO": "2025-08-16T04:44:08.000Z",
    "textPlain": "I find it funny that almost every talking point made about AI is done in future tense. Most of the time without any presentation of evidence supporting those predictions.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919716,
    "by": "mxwsn",
    "timeISO": "2025-08-16T02:57:03.000Z",
    "textPlain": "AI with ability but without responsibility is not enough for dramatic socioeconomic change, I think. For now, the critical unique power of human workers is that you can hold them responsible for things.edit: ability without accountability is the catchier motto :)",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920095,
    "by": "tokioyoyo",
    "timeISO": "2025-08-16T04:11:49.000Z",
    "textPlain": "One thing that doesn’t seem to be discussed with the whole “tech revolution just creates more jobs” angle is that, in the near future, there are no real incentives for that. If we’re going down the route of declining birth rates, it’s implied we’ll also need less jobs.From one perspective, it’s good that we’re trying to over-automate now, so we can sustain ourselves in old age. But decreasing population also implies that we don’t need to create more jobs. I’m most likely wrong, but it just feels off this time around.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920787,
    "by": "eternauta3k",
    "timeISO": "2025-08-16T06:36:06.000Z",
    "textPlain": "At some point far in the future, we don't need an economy: everyone does everything they need by themselves, helped by AI and replicators.But realistically, you're not going to have a personal foundry anytime soon.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921048,
    "by": "yard2010",
    "timeISO": "2025-08-16T07:21:51.000Z",
    "textPlain": "I think so too - the latest AI changes mark the new \"automate everything\" era. When everything is automated, everything costs basically zero, as this will eliminate the most expensive part of every business - human labor. No one will make money from all the automated stuff, but no one would need the money anyway. This will create a society in which money is not the only value pursued. Instead of trying to chase papers, people would do what they are intended to - create art and celebrate life. And maybe fight each other for no reason.I'm flying, ofc, this is just a weird theory I had in the back of my head for the past 20 years, and it seems like we're getting there.Antirez you are the best",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920612,
    "by": "Waterluvian",
    "timeISO": "2025-08-16T05:59:44.000Z",
    "textPlain": "The thing that blows me away is that I woke up one day and was confronted with a chat bot that could communicate in near perfect English.I dunno why exactly but that’s what felt the most stunning about this whole era. It can screw up the number of fingers in an image or the details of a recipe or misidentify elements of an image, etc. but I’ve never seen it make a typo or use improper grammar or whatnot.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920954,
    "by": "cjfd",
    "timeISO": "2025-08-16T07:02:22.000Z",
    "textPlain": "If we accept the possibility that AI is going to be more intelligent than humans the outcome is obvious. Humans will no longer be needed and either go extinct or maybe be kept by the AI as we now keep pets or zoo animals.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921854,
    "by": "yubblegum",
    "timeISO": "2025-08-16T09:56:19.000Z",
    "textPlain": "Butlerian Jihad it is then.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920761,
    "by": "fraboniface",
    "timeISO": "2025-08-16T06:30:16.000Z",
    "textPlain": "On this, read Daniel Susskind - A world without work (2020). He says exactly this: the new tasks created by AI can in good part themselves be done by AI, if not as soon as they appear then a few years of improvement later. This will inevitably affect the job market and the relative importance of capital and labor in the economy. Unchecked, this will worsen inequalities and create social unrest. His solution will not please everyone: Big State. Higher taxes and higher redistribution, in particular in the form of conditional basic income (he says universal isn't practically feasible, like what do you do with new migrants).",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919830,
    "by": "AdieuToLogic",
    "timeISO": "2025-08-16T03:21:31.000Z",
    "textPlain": "> Since LLMs and in general deep models are poorly understood ...This is demonstrably wrong.  An easy refutation to cite is:https://medium.com/@akshatsanghi22/how-to-build-your-own-lar...As to the rest of this pontification, well...  It has almost triple the number of qualifiers (5 if's, 4 could's, and 5 will's) than paragraphs (5).",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920554,
    "by": "gamerDude",
    "timeISO": "2025-08-16T05:48:51.000Z",
    "textPlain": "I don't think I agree. I think it's the same and there is great potential for totally new things to appear and for us to work on.For example, one path may be: AI, Robotics, space travel all move forward in leaps and bounds.Then there could be tons of work in creation from material things from people who didn't have the skills before and physical goods gets a huge boost. We travel through space and colonize new planets, dealing with new challenges and environments that we haven't dealt with before.Another path: most people get rest and relaxation as the default life path, and the rest get to pursue their hobbies as much as they want since the AI and robots handle all the day to day.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919935,
    "by": "rifty",
    "timeISO": "2025-08-16T03:44:15.000Z",
    "textPlain": "Every technology tends to replace many more jobs in a given role than which ever existed inducing more demand on its precursors. If the only potential application of this was just language, the historic trend that humans would just fill new roles would hold true. But if we do the same with motor movements with a generalized form factor this is really where the problem emerges. As companies drop more employees moving towards fully automated closed loop production their consumer market fails faster than they can reach a zero cost.Nonetheless I do still believe humans will continue to be the more cost efficient way to come up with and guide new ideas. Many human performed services will remain desirable because of its virtue and our sense of emotion and taste for a moment that other humans are feeling too. But how much of the populous does that engage? I couldn't guess right now. Though if I was to imagine what might make things turn out better it would be that AI is personally ownable, and that everyone owns, at least in title, some energy production which they can do things with.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921791,
    "by": "0points",
    "timeISO": "2025-08-16T09:43:31.000Z",
    "textPlain": "antirez should retire, his recent nonsense AI take is shadowing his merits as a competent programmer.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920099,
    "by": "pton_xd",
    "timeISO": "2025-08-16T04:12:51.000Z",
    "textPlain": "AI is only different if it reaches a hard takeoff state and becomes self-aware, self-motivated, and self-improving. Until then it's an amazing productivity tool, but only that. And even then we're still decades away from the impact being fully realized in society. Same as the internet.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919832,
    "by": "silisili",
    "timeISO": "2025-08-16T03:21:46.000Z",
    "textPlain": "> Moreover, companies could be less willing to pay for services that their internal AIs can handle or build from scratch.Companies have to be a bit more farsighted than this thinking.  Assuming LLMs reach this peak...if say, MS says they can save money because they don't need XYZ  anymore because AI can do it, XYZ can decide they don't need Office anymore because AI can do it.There's absolutely no moat anymore.  Human capital and the shear volume of code are the current moat.  An all capable AI completely eliminates both.It's a bit scary to say \"what then?\"  How do you make money in a world where everyone can more or less do everything themselves?  Perhaps like 15 Million Merits, we all just live in pods and pedal bikes all day to power the AI(s).",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920187,
    "by": "Ericson2314",
    "timeISO": "2025-08-16T04:30:18.000Z",
    "textPlain": "The right way to think about \"jobs\" is that we could have given ourselves more leisure on the basis of previous technological progress than we actually did.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919851,
    "by": "eviks",
    "timeISO": "2025-08-16T03:24:59.000Z",
    "textPlain": "> AI systems continue to impress with their ability to replicate certain human skills. Even if imperfect, such systems were a few years ago science fiction.In which science fiction were the dreamt up robots as bad?",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919748,
    "by": "throwaway20174",
    "timeISO": "2025-08-16T03:04:33.000Z",
    "textPlain": "Humans have a proven history of re-inventing economic systems, so if AI ends up thinking better than we do (yet unproven this is possible), then we should have superior future systems.But the question is a system optimized for what? That emphasizes huge rewards for the few, and that requires the poverty of some (or many). Or a more fair system. Not different from the challenges of today.I'm skeptical even a very intelligent machine will change the landscape of our dificult decisions, but will accelerate which direction we decide (or is decided for us), that we go.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920379,
    "by": "Sateeshm",
    "timeISO": "2025-08-16T05:13:22.000Z",
    "textPlain": "We are too far from exploring alternate economies. LLMs will not push us there, atleast not in their current state.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921212,
    "by": "sawyna",
    "timeISO": "2025-08-16T07:53:31.000Z",
    "textPlain": "Unpopular opinion: Let us say AI achieves general intelligence levels. We tend to think of current economy, jobs, research as a closed system, but indeed it is a very open system.Humans want to go to space, start living on other planets, travel beyond solar system, figure out how to live longer and so on. The list is endless. Without AI, these things would take a very long time. I believe AI will accelerate all these things.Humans are always ambitious. That ambition will push us to use AI more than it's capabilities. The AI will get better at these new things and the cycle repeats. There's so much humans know and so much more that we don't know.I'm less worried about general intelligence. Rather in more worried about how humans are going to govern themselves. That's going to decide whether we will do great things or end humanity. Over the last 100 years, we start thinking more about \"how\" to do something rather than the \"why\". Because \"how\" is becoming more and more easier. Today it's much more easier and tomorrow even more. So nobody's got the time to ask \"why\" we are doing something, just \"how\" to do something. With AI I can do more. That means everyone can do more. That means governments can do so much more. Large scale things in a short period. If those things are wrong or have irreversible consequences, we are screwed.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920237,
    "by": "vivzkestrel",
    "timeISO": "2025-08-16T04:41:28.000Z",
    "textPlain": "I ll happily believe it the day something doesnt adhere to the Gartner cycle, until then it is just another bubble like dotcom, chatbots, crypto and the 456345646 things that came before it",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920483,
    "by": "strogonoff",
    "timeISO": "2025-08-16T05:37:12.000Z",
    "textPlain": "As any other technology, at the end of the day LLMs are used by humans for humans’ selfish, driven by mental issues and trauma and overcompensation, maybe even paved with good intentions but leading you know where, short-sighted goals. If we were to believe that LLMs are going to somehow become extremely powerful, then we should be concerned, as it is difficult to imagine how that can lead to an optimal outcome organically.From the beginning, corporations and their collaborators at the forefront of this technology tainted it by ignoring the concept of intellectual property ownership (which had been with us in many forms for hundreds if not thousands of years) in the name of personal short-term gain and shareholder interest or some “the ends justify the means” utilitarian calculus.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921041,
    "by": "grumpy-de-sre",
    "timeISO": "2025-08-16T07:20:54.000Z",
    "textPlain": "Honestly the long-term consequences of Baumol's disease scare me more than some AI driven job disruption dystopia.If we want to continue on the path of increased human development we desperately need to lift the productivity of a whole bunch of labor intensive sectors.We're going to need to seriously think about how to redistribute the gains, but that's an issue regardless of AI (things like effective tax policy).",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44921675,
    "by": "yapyap",
    "timeISO": "2025-08-16T09:22:35.000Z",
    "textPlain": "Well this is a pseudo-smart article if I’ve ever seen one.“It was not even clear that we were so near to create machines that could understand the human language, write programs, and find bugs in a complex code base”The author is critical of the professionals in AI saying “ even the most prominent experts in the field failed miserably again and again to modulate the expectations” yet without a care sets the expectation of LLMs understanding human language in the first paragraph.Also it’s a lot of if this then that, the summary of it would be: if AI can continue to grow it might become all encompassing.To me it reads like a baseless article written by someone blinded by their love for AI to see what a good blogpost is but not yet blinded enough to claim ‘AGI is right around the corner’. Pretty baseless but safe enough to have it rest on conditionals.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919986,
    "by": "voidhorse",
    "timeISO": "2025-08-16T03:54:04.000Z",
    "textPlain": "I agree with the general observation, and I've been of this mind since 2023 (if AI really gets as good as the boosters claim, we will need a new economic system). I usually like Antirez's writing, but this post was a whole lot of...idk nothing? I don't feel like this post said anything interesting, and it was kind incoherent at moments. I think in some respects it's a function of the technology and situation we're in—the current wave of \"AI\" is still a lot of empty promises and underdelivery. Yes, it is getting better, and yes people are getting clever by letting LLMs use tools, but these things still aren't intelligent insofar as they do not reason. Until we achieve that, I'm not sure there's really as much to fear as everyone thinks.We still need humans in the loop as of now. These tools are still very far from being good enough to fully autonomously manage each other and manage systems, and, arguably, because the systems we build are for humans we will always need humans to understand them to some extent. LLMs can replace labor, but they cannot replace human intent and teleology. One day maybe they will achieve intentions of their own, but that is an entirely different ballgame. The economy ultimately is a battle of intentions, resources, and ends. And the human beings will still be a part of this picture until all labor can be fully automated across the entire suite of human needs.We should also bear in mind our own bias as \"knowledge workers\". Manual laborers arguably already had their analogous moment. The encoding kept on humming. There isn't anything particularly special about \"white collar\" work in that regard. The same thing may happen. A new industry requiring new skills might emerge in the fallout of white collar automation. Not to mention, LLMs only work in the digital realm. handicraft artisanry is still a thing and is still, appreciated, albeit in much smaller markets.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920730,
    "by": "ausbah",
    "timeISO": "2025-08-16T06:22:03.000Z",
    "textPlain": "i don’t this article really says anything that hasn’t been already said for the past two years. “if AI actually take jobs, it will be a near-apocalyptic system shock if there aren’t news jobs to replace them”. i still think it’s at best too soon to say if jobs have permanently been lostthey are tremendous tools but seems like they make a near equal amount of work from the stuff the save time on",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920800,
    "by": "Rob_Polding",
    "timeISO": "2025-08-16T06:38:40.000Z",
    "textPlain": "GenAI is a bubble, but that’s not the same as the broader field of AI, which is completely different. We will probably not even be using chat bots in a few years, better interfaces will be developed with real intelligence, not just predictive statistics.",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920360,
    "by": "tgbugs",
    "timeISO": "2025-08-16T05:10:19.000Z",
    "textPlain": "I think there is an unspoken implication built into the assumption that AI will be able to replace a wide variety of existing jobs, and that is that those current jobs are not being done efficiently. This is sometimes articulated as bullshit jobs, etc. and if AI takes over those the immediate next thing that will happen is that AI will look around ask why _anyone_ was doing that job in the first place. The answer was articulated 70 years ago in [0].The only question is how much fat there is to trim as the middle management is wiped out because the algorithms have determined that they are completely useless and mostly only increase cost over time.Now, all the AI companies think that they are going to be deriving revenue from that fat, but those revenue streams are going to disappear entirely because a huge number of purely politic positions inside corporations will vanish, because if they do not the corporation will go bankrupt competing with other companies that have already cut the fat. There won't be additional revenue streams that get spent on the bullshit. The good news is that labor can go somewhere else, and we will need it due to a shrinking global population, but the cushy bullshit management job is likely disappear.At some point AI agents will cease to be sycophantic and when fed the priors for the current situation that a company is in will simply tell it like it is, and might even be smart enough to get the executives to achieve the goal they actually stated instead of simply puffing up their internal political position, which might include a rather surprising set of actions that could even lead to the executive being fired if the AI determines that they are getting in the way of the goal [1].Fun times ahead.0. https://web.archive.org/web/20180705215319/https://www.econo...\n1. https://en.wikipedia.org/wiki/The_Evitable_Conflict",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44919486,
    "by": "BoorishBears",
    "timeISO": "2025-08-16T02:07:12.000Z",
    "textPlain": "I don't get how post GPT-5's launch we're still getting articles where the punchline is \"what if these things replace a BUNCH of humans\".",
    "parent": 44892283,
    "depth": 1
  },
  {
    "id": 44920635,
    "by": "iLoveOncall",
    "timeISO": "2025-08-16T06:05:11.000Z",
    "textPlain": "> However, if AI avoids plateauing long enoughI'm not sure how someone can seriously write this after the release of GPT-5.Models have started to plateau since ChatGPT came out (3 years ago) and GPT-5 has been the final nail in this coffin.",
    "parent": 44892283,
    "depth": 1
  }
]