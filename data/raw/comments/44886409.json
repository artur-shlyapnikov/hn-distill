[
  {
    "id": 44888825,
    "by": "rossdavidh",
    "timeISO": "2025-08-13T14:21:56.000Z",
    "textPlain": "What happens is they go out of business: \"these firms spent five hundred and sixty billion dollars on A.I.-related capital expenditures in the past eighteen months, while their A.I. revenues were only about thirty-five billion.\"DeepSeek (and the like) will prevent the kind of price increases necessary for them to pay back hundreds of billions of dollars already spent, much less pay for more.  If they don't find a way to make LLMs do significantly more than they do thus far, and a market willing to pay hundreds of billions of dollars for them to do it, and some kind of \"moat\" to prevent DeepSeek and the like from undercutting them, they will collapse under the weight of their own expenses.",
    "parent": 44886409,
    "depth": 1
  },
  {
    "id": 44888725,
    "by": "brainwipe",
    "timeISO": "2025-08-13T14:14:28.000Z",
    "textPlain": "The title is irritating, conflating AI with LLMs. LLMs are a subset of AI. I expect future systems will be mobs of expert AI agents rather than relying on LLMs to do everything. An LLM will likely be in the mix for at least the natural language processing but I wouldn't bet the farm on them alone.",
    "parent": 44886409,
    "depth": 1
  },
  {
    "id": 44888818,
    "by": "EcommerceFlow",
    "timeISO": "2025-08-13T14:21:11.000Z",
    "textPlain": "OpenAi has 700+ million users. Sam recently said only 7% of Plus users were using thinking (o3)!!! That means 93% of their users were using nothing but 4o!Clearly the OpenAi leadership saw these stats and understood the main initial goal of GPT5 is to introduce this auto-router, and not go all in on intelligence for the 3-7% who care to use it.",
    "parent": 44886409,
    "depth": 1
  },
  {
    "id": 44888498,
    "by": "qcnguy",
    "timeISO": "2025-08-13T13:55:17.000Z",
    "textPlain": "> You didn’t need a bar chart to recognize that GPT-4 had leaped ahead of anything that had come before.You did though. I remember when GPT-4 was announced, OpenAI downplayed it and Altman said the difference was subtle and wouldn't be immediately apparent. For a lot of the stuff ChatGPT was being used for the gap between 3 and 4 wasn't going to really leap out at you.https://fortune.com/2023/03/14/openai-releases-gpt-4-improve...In the lead up to the announcement, Altman has set the bar low by suggesting people will be disappointed and telling his Twitter followers that “we really appreciate feedback on its shortcomings.”OpenAI described the distinction between GPT-3.5—the previous version of the technology—and GPT 4, as subtle in situations when users are having a “casual conversation” with the technology. “The difference comes out when the complexity of the task reaches a sufficient threshold—GPT-4 is more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5,” a research blog post read.In the years since we got a lot more demanding of our models. Back then people were happy if they got models to write a small simple function and it worked. Now they expect models to manipulate large production codebases and get it right first time. So, the difference between GPT-3 and GPT-4 would be more apparent. But at the time, the reaction was somewhat muted.",
    "parent": 44886409,
    "depth": 1
  },
  {
    "id": 44888763,
    "by": "bbqfog",
    "timeISO": "2025-08-13T14:17:10.000Z",
    "textPlain": "AI is so new and so powerful, that we don't really know how to use it yet. The next step is orchestration. LLMs are already powerful but they need to be scaled horizontally. \"One shotting\" something with a single call to an LLM should never be expected to work. That's not how the human brain works. We iterate, we collaborate with others, we reflect... We've already unlocked the hard and \"mysterious\" part, now we just need time to orchestrate and network it.",
    "parent": 44886409,
    "depth": 1
  },
  {
    "id": 44886493,
    "by": "latexr",
    "timeISO": "2025-08-13T09:54:11.000Z",
    "textPlain": "https://archive.ph/20250813061454/https://www.newyorker.com/...",
    "parent": 44886409,
    "depth": 1
  },
  {
    "id": 44887658,
    "by": "fuzzfactor",
    "timeISO": "2025-08-13T12:32:14.000Z",
    "textPlain": ">What If A.I. Doesn't Get Better Than This?What if it does?There's a certain type of fear . . .  \"It's the fear . . . they're gonna take my job away . . . \"\n\n  It's the fear . . . I'll be working here the rest of my days . . . \"\n\n-- David FahlSame fear, different day.",
    "parent": 44886409,
    "depth": 1
  },
  {
    "id": 44888814,
    "by": "DanHulton",
    "timeISO": "2025-08-13T14:20:57.000Z",
    "textPlain": "That battle was long-ago lost when the leading LLM companies and organizations insisted on referring to their products and models solely as \"AI\", not the more-specific \"LLMs\".  Implementers of that technology followed suit, and that's just what it means now.You can't blame the New Yorker for using the term in its modern, common parlance.",
    "parent": 44888725,
    "depth": 2
  },
  {
    "id": 44888777,
    "by": "DanielHB",
    "timeISO": "2025-08-13T14:18:10.000Z",
    "textPlain": "The computing power alone of all these gpus would bring a revolution in simulation software. I mean 0 AI/machine-learning, just being able to simulate much more things than we can.Most industry-specific simulation software is REALLY crap, most from the 90s and 80s and barely evolved since then. Many stuck on single core CPUs.",
    "parent": 44888725,
    "depth": 2
  },
  {
    "id": 44888834,
    "by": "lokar",
    "timeISO": "2025-08-13T14:22:47.000Z",
    "textPlain": "A* search, literally textbook AI, is still doing great work.",
    "parent": 44888725,
    "depth": 2
  },
  {
    "id": 44888853,
    "by": "SideburnsOfDoom",
    "timeISO": "2025-08-13T14:24:03.000Z",
    "textPlain": "[delayed]",
    "parent": 44888818,
    "depth": 2
  },
  {
    "id": 44888619,
    "by": "supriyo-biswas",
    "timeISO": "2025-08-13T14:05:16.000Z",
    "textPlain": "> Back then people were happy if they got models to write a small simple function and it worked. Now they expect models to manipulate large production codebases and get it right first time.This push is mostly coming from the C-level and the hustler types, both of which need this to work out in order for their employeeless corporation fantasy to work out.",
    "parent": 44888498,
    "depth": 2
  },
  {
    "id": 44888436,
    "by": "Ekshef",
    "timeISO": "2025-08-13T13:49:36.000Z",
    "textPlain": "Thank you for that!",
    "parent": 44886493,
    "depth": 2
  },
  {
    "id": 44888839,
    "by": "lenerdenator",
    "timeISO": "2025-08-13T14:23:03.000Z",
    "textPlain": "Nah, I'm not afraid of working here the rest of my days. Consistent paycheck, benefits, challenging-but-rewarding work.If you provide people with that they typically shut up and stay out of the way. Everyone should be more afraid of the former than the latter.",
    "parent": 44887658,
    "depth": 2
  },
  {
    "id": 44888693,
    "by": "piskov",
    "timeISO": "2025-08-13T14:11:28.000Z",
    "textPlain": "Because every s-curve looks like an exponent for those in the start.I mean look at the first plane, then first air-jets: it’s understandable to assume we would travel the galaxy in something like 2050.Meanwhile planes are basically the same last 60 years.LLMs are great but I firmly believe that in 2100 all is basically the same as in 2020: no free energy (fusion), no AGI.",
    "parent": 44887658,
    "depth": 2
  }
]