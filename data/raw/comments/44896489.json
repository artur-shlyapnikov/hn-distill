[
  {
    "id": 44899400,
    "by": "elpocko",
    "timeISO": "2025-08-14T12:03:09.000Z",
    "textPlain": ">block-level deduplication (saves 30-40% on typical codebases)How is savings of 40% on a typical codebase possible with block-level deduplication? What kind of blocks are you talking about? Blocks as in the filesystem?",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44897346,
    "by": "retreatguru",
    "timeISO": "2025-08-14T06:31:14.000Z",
    "textPlain": "How do you use this in your workflow? Please give some examples because it’s not clear to me what this is for.",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44899933,
    "by": "skyzouwdev",
    "timeISO": "2025-08-14T13:08:15.000Z",
    "textPlain": "That sounds like a practical take on LLM memory — especially the block-level deduplication part.Most “memory” layers I’ve seen for AI are either overly complex or end up ballooning storage costs over time, so a content-addressed approach makes a lot of sense.Also curious — have you benchmarked retrieval speed compared to more traditional vector DB setups? That could be a big selling point for devs running local research workflow",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44898338,
    "by": "rkunnamp",
    "timeISO": "2025-08-14T09:03:41.000Z",
    "textPlain": "Thank you for sharing this. Sorry for a possible noob question. How are embedding generated? Does it use a hosted embedding model? (I was trying to understand how is semantic search implemented)",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44899250,
    "by": "jerpint",
    "timeISO": "2025-08-14T11:42:51.000Z",
    "textPlain": "I also developed yet another memory system !https://github.com/jerpint/context-llemurAlthough I developed it explicitly without search, and catered it to the latest agents which are all really good at searching and reading files. Instead you and LLMs cater your context to be easily searchable (folders and files). It’s meant for dev workflows (i.e a projects context, a user context)I made a video showing how easy it is to pull in context to whatever IDE/desktop app/CLI tool you usehttps://m.youtube.com/watch?v=DgqlUpnC3uw",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44899680,
    "by": "A4ET8a8uTh0_v2",
    "timeISO": "2025-08-14T12:37:55.000Z",
    "textPlain": "I like it and I will be perusing your code for what could be used in my 'not yet working' variant.",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44899966,
    "by": "izabera",
    "timeISO": "2025-08-14T13:11:15.000Z",
    "textPlain": "not trying to be a hater but how is 100mb/s high performance in 2025?  that's as performant as a 20 years old hdd",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44898964,
    "by": "huqedato",
    "timeISO": "2025-08-14T10:57:06.000Z",
    "textPlain": "In my RAG I use qdrant w/ Redis. Very successfully. I don't really see the use of \"another memory system for LLM\", perhaps I'm missing something.",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44897335,
    "by": "sitkack",
    "timeISO": "2025-08-14T06:29:57.000Z",
    "textPlain": "How would you use the built in functionality to enable graph functionality? Metadata or another document used as the link or collection of links?",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44897455,
    "by": "yard2010",
    "timeISO": "2025-08-14T06:49:44.000Z",
    "textPlain": "I'm puzzled - where are the header files?",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44897383,
    "by": "ActorNightly",
    "timeISO": "2025-08-14T06:37:23.000Z",
    "textPlain": ">MCP server (requires Boost)I see stuff like this, and I really have to wonder if people just write software with bloat for the sake of using a particular library.",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44897633,
    "by": "vira28",
    "timeISO": "2025-08-14T07:16:22.000Z",
    "textPlain": "How does this compare to Letta?",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44897286,
    "by": "JSR_FDED",
    "timeISO": "2025-08-14T06:20:43.000Z",
    "textPlain": "Thanks, I learned a lot from this.",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44896969,
    "by": "marcofiocco",
    "timeISO": "2025-08-14T05:16:42.000Z",
    "textPlain": "What about versioning of files?",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44896869,
    "by": "mempko",
    "timeISO": "2025-08-14T04:57:04.000Z",
    "textPlain": "Wicked cool. Useful for single users. Any plans to build support for multiple users? Would be useful for an LLM project that requires per user sandboxing.",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44896675,
    "by": "winterrx",
    "timeISO": "2025-08-14T04:13:09.000Z",
    "textPlain": "The domain listed on the GitHub repo redirects too many times.",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44897105,
    "by": "yawerali",
    "timeISO": "2025-08-14T05:41:58.000Z",
    "textPlain": "Hader",
    "parent": 44896489,
    "depth": 1
  },
  {
    "id": 44898795,
    "by": "sync",
    "timeISO": "2025-08-14T10:26:53.000Z",
    "textPlain": "It, uh... generates mock embeddings? https://github.com/trvon/yams/blob/c89798d6d2de89caacdbe50d2...(seems like there's some vague future plans for models like all-MiniLM-L6-v2, all-mpnet-base-v2)",
    "parent": 44898338,
    "depth": 2
  },
  {
    "id": 44900730,
    "by": "blackmanta",
    "timeISO": "2025-08-14T14:21:34.000Z",
    "textPlain": "The system is honestly tuned for storage efficiency not speed but these configurations are tunable and you can use the benchmarks as a reference for tuning. https://github.com/trvon/yams/blob/main/docs/benchmarks/perf...",
    "parent": 44899966,
    "depth": 2
  },
  {
    "id": 44898505,
    "by": "paffdragon",
    "timeISO": "2025-08-14T09:33:21.000Z",
    "textPlain": "You mean these? https://github.com/trvon/yams/tree/main/include/yams",
    "parent": 44897455,
    "depth": 2
  },
  {
    "id": 44897695,
    "by": "SJC_Hacker",
    "timeISO": "2025-08-14T07:25:50.000Z",
    "textPlain": "Blame the committee for refusing to include basic functionality like regular expressions , networking and threads as part of the STL",
    "parent": 44897383,
    "depth": 2
  },
  {
    "id": 44899361,
    "by": "airstrike",
    "timeISO": "2025-08-14T11:58:38.000Z",
    "textPlain": "This feels like a shallow dismissal, which is frowned upon per the HN guidelines",
    "parent": 44897383,
    "depth": 2
  },
  {
    "id": 44897969,
    "by": "menaerus",
    "timeISO": "2025-08-14T08:07:39.000Z",
    "textPlain": "The reason for depending on Boost in this repo is just few search characters away - he needs HTTP/WebSocket implementation and Boost.Beast provides it. The actual bloat here in this repo is conan.",
    "parent": 44897383,
    "depth": 2
  },
  {
    "id": 44898042,
    "by": "noodletheworld",
    "timeISO": "2025-08-14T08:17:46.000Z",
    "textPlain": "? Are you complaining about MCP or boost?It’s an optional component.What do you want the OP to do?MCP may not be strictly necessary but it’s straight in line with the intent of the library.Are you going to take shots at llama.cpp for having an http server and a template library next?Come on. This uses conan, it has a decent cmake file. The code is ok.This is pretty good work. Dont be a dick. (Yeah, ill eat the down votes, it deserves to be said)",
    "parent": 44897383,
    "depth": 2
  },
  {
    "id": 44897562,
    "by": "pessimizer",
    "timeISO": "2025-08-14T07:06:33.000Z",
    "textPlain": "Boost is a nearly 30 year old open source library that provides stuff for C++ that most standard libraries for other languages already have out of the box. You seem to think that it is hipster bullshit rather than almost a dinosaur itself.",
    "parent": 44897383,
    "depth": 2
  },
  {
    "id": 44897012,
    "by": "blackmanta",
    "timeISO": "2025-08-14T05:25:56.000Z",
    "textPlain": "The tool has built-in versioning. Each file gets a unique SHA-256 hash on storage (automatic versioning), you can update metadata to track version info, and use collections/snapshots to group versions together. I have been using the metadata to track progress and link code snippets.",
    "parent": 44896969,
    "depth": 2
  },
  {
    "id": 44896802,
    "by": "blackmanta",
    "timeISO": "2025-08-14T04:43:23.000Z",
    "textPlain": "That should be fixed now. It was a misconfiguration of CloudFlare SSL with GitHub Pages.",
    "parent": 44896675,
    "depth": 2
  }
]