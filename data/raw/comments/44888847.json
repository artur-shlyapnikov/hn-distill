[
  {
    "id": 44888848,
    "by": "richardblythman",
    "timeISO": "2025-08-13T14:23:56.000Z",
    "textPlain": "If coding agents are the new entry point to your library, how sure are you that they’re using it well?I asked this question to about 50 library maintainers and dev tool builders, and the majority didn't really know.Existing code generation benchmarks focus mainly on self-contained code snippets and compare models not agents. Almost none focus on library-specific generation.So we built a simple app to test how well coding agents interact with libraries:\n • Takes your library’s docs\n • Automatically extracts usage examples\n • Tasks AI agents (like Claude Code) with generating those examples from scratch\n • Logs mistakes and analyzes performanceWe’re testing libraries now, but it’s early days. If you're interested: Input your library, see what breaks, spot patterns, and share the results below.We plan to expand to more coding agents, more library-specific tasks, and new metrics. Let us know what we should prioritize next.",
    "parent": 44888847,
    "depth": 1
  },
  {
    "id": 44889489,
    "by": "dotancohen",
    "timeISO": "2025-08-13T15:10:21.000Z",
    "textPlain": "Note that this comment is not hijacking. The author of this comment is also the author of the post.",
    "parent": 44888848,
    "depth": 2
  }
]