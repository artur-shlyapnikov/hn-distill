[
  {
    "id": 44851706,
    "by": "Uehreka",
    "timeISO": "2025-08-10T00:32:06.000Z",
    "textPlain": "This is a genre of article I find particularly annoying. Instead of writing an essay on why he personally thinks GPT-5 is bad based on his own analysis, the author just gathers up a bunch of social media reactions and tells us about them, characterizing every criticism as “devastating” or a “slam”, and then hopes that the combined weight of these overtorqued summaries will convince us to see things his way.It’s both too slanted to be journalism, but not original enough to be analysis.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851866,
    "by": "chmod775",
    "timeISO": "2025-08-10T00:56:43.000Z",
    "textPlain": "At this point the single biggest improvement that could be made to GPTs is making them able to say \"I don't know\" when they honestly don't.Just today I was playing around with modding Cyberpunk 2077 and was looking for a way to programmatically spawn NPCs in redscript. It was hard to figure out, but I managed. ChatGPT 5 just hallucinated some APIs even after doing \"research\" and repeatedly being called out.After 30 minutes of ChatGPT wasting my time I accepted that I'm on my own. It could've been 1 minute.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851647,
    "by": "mikert89",
    "timeISO": "2025-08-10T00:22:36.000Z",
    "textPlain": "I still think GPT5 is really a cost cutting measure, with a company that is trying to grow to 1 billion users on a product that needs GPUs.I dont see anyone talking about GPT 5 Pro, which I personally tested against:- Grok 4 Heavy- Opus 4.1It was far better than both of those, and is completely state of the art.The real story is running these models at true performance max likely could go into the thousands per month per user. And so we are being constrained. OpenAI isnt going for that market segment, they are going for growth to take on Google.This article doesnt have one reference to the Pro model. Completely invalidates this guys opinion",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851662,
    "by": "mentalgear",
    "timeISO": "2025-08-10T00:26:19.000Z",
    "textPlain": "The AI community requires more independent experts like Marcus to maintain integrity and transparency, ensuring that the field does not succumb to hyperbole as well as shifting standards such as \"internally achieved AGI\", etc.Regardless of personal opinions about his style, Marcus has been proven correct on several fronts, including the diminishing returns of scaling laws and the lack of true reasoning (out of distribution generalizability) in LLM-type AI.These are issues that the industry initially denied, only to (years) later acknowledge them as their \"own recent discoveries\" as soon as they had something new to sell (chain-of-thought approach, RL-based LLM, tbc.).",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851834,
    "by": "computegabe",
    "timeISO": "2025-08-10T00:51:34.000Z",
    "textPlain": "OpenAI could create the best model ever made, call it GPT-5, and it still would've failed to meet the expectations of the people for \"GPT-5\" after the meme community hyped it up and OpenAI embraced the memes and hype. If anything, OpenAI should have rejected the memes and embraced gradual improvements, but that wouldn't hold up well for their investors, the narrative, or even perhaps the AI ecosystem. We are at the peak.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44852133,
    "by": "reilly3000",
    "timeISO": "2025-08-10T01:50:10.000Z",
    "textPlain": "I feel his need to be right distracts from the fact that he is. It’s interesting to think about what a hybrid symbolic/transformer system could be. In a linked post he showed that by effectively delegating math to Python is what made Grok 4 so successful at math. I’d personally like to see more of what a symbolic first system would look like, effectively hard math with monads for where inference is needed.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851724,
    "by": "calrain",
    "timeISO": "2025-08-10T00:35:15.000Z",
    "textPlain": "I'm having some unique problems with GPT-5 that I've not seen with GPT-4.It seems to lose the thread of the conversation quite abruptly, not really knowing how to answer the next comment in a thread of comments.It's like there is some context cleanup process going on and it's not summarizing the highlights of the conversation to that point.If that is so, then it seems to also have a very small context, because it seems to happen regularly.Asking it to 'Please review the recent conversation before continuing' prompt seems to help it a bit.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851862,
    "by": "starchild3001",
    "timeISO": "2025-08-10T00:56:10.000Z",
    "textPlain": "I asked GPT-5 and Gemini 2.5 Pro what they think about Gary Marcus's article. I believe Gemini won by this paragraph:It seems Sam Altman's Death Star had a critical design flaw after all, and Gary Marcus is taking a well-earned victory lap around the wreckage. This piece masterfully skewers the colossal hype balloon surrounding GPT-5, reframing its underwhelming debut not as a simple fumble, but as a predictable, principled failure of the entire \"scaling is all you need\" philosophy. By weaving together viral dunks on bike-drawing AIs, damning new research on generalization failures, and the schadenfreude of \"Gary Marcus Day,\" the article makes a compelling case that the industry's half-a-trillion-dollar bet on bigger models has hit a gilded, hallucinatory wall. Beyond the delicious takedown of one company's hubris, the post serves as a crucial call to action, urging the field to stop chasing the mirage of AGI through brute force and instead invest in the harder, less glamorous work of building systems that can actually reason, understand, and generalize—perhaps finally giving neurosymbolic AI the chance Altman's cocky tweet so perfectly, and accidentally, foreshadowed for the Rebel Alliance.My take on GPT-5? Latency is a huge part of the LLM experience. Smart model routing can be a big leap forward in reducing wait times and improving usability. For example, I love Gemini 2.5 Pro, but it’s painfully slow (sorry, GDM!). I also love the snappy response-time of 4o. The most ideal? Combine them in a single prompt with great model routing. Is GPT-5’s router up to the task? We soon shall see.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851822,
    "by": "SerCe",
    "timeISO": "2025-08-10T00:49:30.000Z",
    "textPlain": "Here are my reasons why this \"upgrade\" is, in experience, a huge downgrade for Plus users:* The quality of responses from GPT-5 compared to O3 is lacking. It does very few rounds of thinking and doesn't use web search as O3 used to. I've tried selecting \"thinking\", instructing explicitly, nothing helps. For now, I have to use Gemini to get similar quality of outputs.* Somehow, custom GPTs [1] are now broken as well. My custom grammar-checking GPT is ignoring all instructions, regardless of the selected model.* Deep research (I'm well within the limit still) is broken. Selecting it as an option doesn't help, the model just keeps responding as usual, even if it's explicitly instructed to use deep research.[1]: https://openai.com/index/introducing-gpts/",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851793,
    "by": "rpmisms",
    "timeISO": "2025-08-10T00:43:48.000Z",
    "textPlain": "There is no training data left. Every refinement in AI from here on will come from architectural changes. All models basically have reached a local maximum on new information.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851780,
    "by": "Havoc",
    "timeISO": "2025-08-10T00:41:50.000Z",
    "textPlain": "He just sounds bitter with a weird grudge against AltmanGpt5 was an incremental improvement. That’s fine. Was hyped hard but what did you expect? It’s part of the game",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851815,
    "by": "hexage1814",
    "timeISO": "2025-08-10T00:47:52.000Z",
    "textPlain": "Gary Marcus would have wrote this article in all possible scenarios, unless ChatGPT 5 was literally AGI (maybe even it were, he would still have found something to attack). There is valid criticism, and there is just being a contrarian for the sake of being a contrarian.The whole thing feels less like “Hey, this is why I think the model is bad” and more like the kind of sensationalist headline you’d read in a really trashy tabloid, something like: “ChatGPT 5 is Hot Garbage, Totally Fails, Sam Altman Crushed Beneath His Own Failure.”Also, I have no idea why people give so much attention to what this guy has to say.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851712,
    "by": "emilsedgh",
    "timeISO": "2025-08-10T00:33:31.000Z",
    "textPlain": "People on our circles are obsessed with model performance. OpenAI's lead is not there and hasn't been there for some time.They do, however, have a major lead in terms of consumer adoption. To normal people who use llm's, ChatGPT is _the_ model.This gives them a lot of opportunities. I don't know what's taking them so long to launch their own _real_ app store, but that's the game they are ahead of everyone else because of the consumer adoption.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851930,
    "by": "TulliusCicero",
    "timeISO": "2025-08-10T01:09:23.000Z",
    "textPlain": "> Driverless cars that still are only available in couple percent of the world’s cities.Okay, this one is a really bad attempted point.Sure, self driving cars took longer than expected, have been harder to get right than expected. But at this point, Waymo is steadily ramping up how quickly they open up in new cities, and in existing cities like SF they at least have a substantial market share in the ride-sharing/taxi business.Basically, the tech is still relatively early in its adoption curve, but it's far enough in now to obviously not be \"bullshit\", at the very least.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851757,
    "by": "kylecazar",
    "timeISO": "2025-08-10T00:39:15.000Z",
    "textPlain": "\"People had grown to expect miracles, but GPT-5 is just the latest incremental advance.\"This is really the only part of the article I think was worth writing.-People should expect an incremental advance-Providers should not promise miraclesManaging expectations is important. The incremental advances are still advances, though, even if I don't think \"AGI\" is just further down on the GPT trajectory.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851722,
    "by": "bawolff",
    "timeISO": "2025-08-10T00:35:09.000Z",
    "textPlain": "So GPT-5 sucks if you were expecting the singularity.I know AI hype is truly insane, but surely nobody actually believed the singularity was upon us?",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851977,
    "by": "strangescript",
    "timeISO": "2025-08-10T01:19:47.000Z",
    "textPlain": "The T1000s are going to be chasing Gary down and he is going to look over his shoulder and explain to them they aren't really AGI",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851904,
    "by": "resters",
    "timeISO": "2025-08-10T01:02:04.000Z",
    "textPlain": "GPT-5 was able to fix a variety of bugs in some code that I'd been working on with Claude 4.1 (which Claude 4.1 had made and was not able to fix), and GPT-5-pro was able to offer some high quality critiques of some research I've been working on -- better and more insightful feedback than previous frontier models.GPT-5 is a welcome addition to the lineup, it won't completely replace other models but it will play a big role in my work moving forward.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851940,
    "by": "throwawayohio",
    "timeISO": "2025-08-10T01:13:28.000Z",
    "textPlain": "I certainly consider myself a skeptic in the current AI craze, but this entire piece (of which I find the technical criticisms interesting) just reads like attack on Altman/OpenAI.Even if you want to make fun of the (alleged) snake oil salesmen of AGI, how are you not going after, like, Zuckerberg/Meta? At least Altman is using other peoples money.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851659,
    "by": "andai",
    "timeISO": "2025-08-10T00:25:25.000Z",
    "textPlain": "Yeah, the sycophancy withdrawal is real. I almost considered telling GPT-5 to act ten years younger, use emoji everywhere, and compliment me at the beginning of every response... but I snapped out of it.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851882,
    "by": "wbharding",
    "timeISO": "2025-08-10T00:58:42.000Z",
    "textPlain": "Show me a Gary Marcus essay, I’ll show you a few new LLM “gotchas” that will be fixed by the next version. Season to taste with self-assured confidence that all these tech goobers really don’t understand how totally overrated AI progress is.So it has been for 10+ years, so it will be at least 5 more.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44852185,
    "by": "periodjet",
    "timeISO": "2025-08-10T02:00:37.000Z",
    "textPlain": "Dude writes like he’s an under-appreciated genius, unfairly unrecognized in his time.His (entirely not-unique) conclusion that the transformer architecture has plateaued is, for the moment, certainly true, but god damn it’s been a while since I’ve encountered an individual quite so lustfully engaged with his own farts.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851935,
    "by": "throwpoaster",
    "timeISO": "2025-08-10T01:10:46.000Z",
    "textPlain": "I recommend people ask the LLMs the hardest questions they can think of and compare their answers. Save these questions as your benchmark.When I ran mine through GPT-5 there was a noticeable degradation in the answers.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851945,
    "by": "mikesabbagh",
    "timeISO": "2025-08-10T01:15:07.000Z",
    "textPlain": "each LLM has its own personality and preferences. I choose different LLM to answer different needs. Claude is good to create a website from scratch, but if I ask it to fix one specific thing, it goes and modify something else too. GPT-5 has more of this. it is harder to control. it even answers me using incomplete sentences, and once used slang. It may be because i use slang and incomplete sentences. \nBut yeah, it is not clear to me when i will go to GPT5 instead of others",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851791,
    "by": "asciii",
    "timeISO": "2025-08-10T00:43:42.000Z",
    "textPlain": "Can someone let me know if they also find the existing UI prompt unbearably slow? At first I thought it was my browsers but I am having the same experience on every machine. It's so bloody slow with loading responses, freezing and even giving me the old browser tab death warning \"Cancel or Wait\"",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851711,
    "by": "chromaton",
    "timeISO": "2025-08-10T00:33:10.000Z",
    "textPlain": "For my benchmarking suite, it turns out that it's about 1/5 the price of Claude Sonnet 4.1, with roughly comparable results.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851831,
    "by": "osigurdson",
    "timeISO": "2025-08-10T00:50:44.000Z",
    "textPlain": "For me, it wasn't that the results were bad it is that it goes into thinking mode all the time making the responses slow. Personally, I think it will get better in time but yeah, the Death Star analogy seems pretty off. Not sure what Sam was thinking there.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851763,
    "by": "adeptima",
    "timeISO": "2025-08-10T00:40:00.000Z",
    "textPlain": "same sentiments with an article author - gpt5 looks like a cost-cut initiative.my personal feeling gpt5-thinking is much faster but doesnt produce the same quality results as o3 which were capable to scan through the code base dump with file names and make correct callsdont feel any changes with https://chatgpt.com/codex/my best experience was to use o3 for task analysis, copy paste the result in https://chatgpt.com/codex/, work outside and vibe code from mobile",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851933,
    "by": "boredemployee",
    "timeISO": "2025-08-10T01:10:11.000Z",
    "textPlain": "Biggest takeaway: even billion dollar companies can mess up big time. I can go back to work in peace now.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851943,
    "by": "bravesoul2",
    "timeISO": "2025-08-10T01:14:20.000Z",
    "textPlain": "OpenAI tech is fine. The real problem is overpromising.Is any other tech scrutinised like this. Next version of postgres aint giving me picosecond reads so Ill trash it. Maybe OK if postgres are claiming it is faster than speed of light perhaps.But I'm meh. Bunch of people seem to be hot taking AI and loving this \"fail\" because as you can see from this submission it gets you a lot of traffic to whatever you are trying to sell (most often ones own career). There also seems to be a community expectation of subsidised services. Move on to Claude because I can get those good tokens cheaper. Its like signing up for every free trial thing and cancelling and then bragging about how can Netflix charge for their service more than $1 a month. I mean thats fine, play the game but at least be honest about it.I think AI will thrive but AI is commoditizing the complement which is overcapitized AI companies with no moat. This plus open models is great for tbe community. We need more power to the people these days. Hope it stays like this.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851888,
    "by": "joshuamoyers",
    "timeISO": "2025-08-10T00:59:42.000Z",
    "textPlain": "> For all that, GPT-5 is not a terrible model. I played with it for about an hour, and it actually got several of my initial queries right (some initial problems with counting “r’s in blueberries had already been corrected, for example). It only fell apart altogether when I experimented with images.Spatial reasoning and world model is one aspect. Posting bicycle part memes does not a bad model make. The reality is its cheaper than Sonnet and maybe around as good at Opus at a decent number of tasks.> And, crucially, the failure to generalize adequately outside distribution tells us why all the dozens of shots on goal at building “GPT-5 level models” keep missing their target. It’s not an accident. That failing is principled.This keeps happening recently. So many people want to take a biblically black and white take on whether LLMs can get to human level intelligence. See recent interview with Yann LeCun (Meta Chief AI Scientist): https://www.youtube.com/watch?v=4__gg83s_DoNobody has any fucking idea. It might be a hybrid or a different architecture than current transformers, but with the rate of progress just within this field, there is absolutely no way you can make a prediction that scaling laws won't just let LLMs outpace the negative hot takes.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851665,
    "by": "petetnt",
    "timeISO": "2025-08-10T00:26:41.000Z",
    "textPlain": "GPT-5 is just OpenAI getting started. Just wait and see what GPT-6 is capable of and imagine that GTP-6 is just OpenAI getting started: if GPT-6 was a high school student, GPT-7 is an expert with masters degree; but GPT-7 is OpenAI getting started",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851739,
    "by": "manishsharan",
    "timeISO": "2025-08-10T00:37:00.000Z",
    "textPlain": "Does anyone else miss o3?I swear I had an understanding of how to get deep analytical thinking out of o3. I am absolutely struggling to get the same results with GPT-5. The new model feels different and frustrating to use.",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851856,
    "by": "SilverElfin",
    "timeISO": "2025-08-10T00:55:21.000Z",
    "textPlain": "Is it just me or is this sort of a “tear someone down” rant wrapped up as an attempt at something more",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851657,
    "by": "AndrewKemendo",
    "timeISO": "2025-08-10T00:24:53.000Z",
    "textPlain": "Can someone remind me of anything Gary has contributed to AI?Last I saw he hasn’t produced anything but general “pop” books on AI and being associated with MIT, which IMO has zero weight on applied or even at this point theoretical AI, as that is primarily coming out of corporate labs.No new algorithms, frameworks, datasets, products, insights.Why is this guy relevant enough to keep giving him attention, his entire ouvre is just anti-whatever is getting attention in the “AI” landscapeI don’t see him commenting on any other papers and he has no lab or anythingSomeone make it make sense, or is it as simple as “yeah thing makes me feel bad, me repost, me repeat!”",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851651,
    "by": "Aeolun",
    "timeISO": "2025-08-10T00:23:59.000Z",
    "textPlain": "I mean, it’s not that bad. It’s bad at all the same things that other models are bad at. I just have no reason to switch away from Claude to GPT-5",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851743,
    "by": "Madmallard",
    "timeISO": "2025-08-10T00:37:30.000Z",
    "textPlain": "A friend of mine works in AI professionally. He told me months ago that it is basically just all a scam and hype to garner investment money. He said the technology and paradigm itself will never lend toward AGI or anything like that.He sent me all these articles geared toward that end as well.\nhttps://garymarcus.substack.com/p/seven-replies-to-the-viral...\nhttps://substack.com/@cattelainf/note/c-135021342\nhttps://arxiv.org/abs/2002.06177\nhttps://garymarcus.substack.com/p/the-ai-2027-scenario-how-r...\nhttps://garymarcus.substack.com/p/25-ai-predictions-for-2025...",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44852014,
    "by": "linkage",
    "timeISO": "2025-08-10T01:25:50.000Z",
    "textPlain": "> garymarcuslollmao, even",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851656,
    "by": "furyofantares",
    "timeISO": "2025-08-10T00:24:35.000Z",
    "textPlain": "[flagged]",
    "parent": 44851557,
    "depth": 1
  },
  {
    "id": 44851732,
    "by": "johnfn",
    "timeISO": "2025-08-10T00:36:05.000Z",
    "textPlain": "For some reason AI seems to bring out articles that seem to fundamentally lack curiosity - opting instead for gleeful mockery and scorn. I like AI, but I'll happily read thoughtful articles from people who disagree. But not this. This article has no value other than to dunk on the opposition.I tend to think HN's moderation is OK, but I think these sorts of low-curiosity articles need to be off the front page.",
    "parent": 44851706,
    "depth": 2
  }
]