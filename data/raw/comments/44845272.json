[
  {
    "id": 44846669,
    "by": "apitman",
    "timeISO": "2025-08-09T14:18:58.000Z",
    "textPlain": "I really like Jan, especially the organization's principles: https://jan.ai/Main deal breaker for me when I tried it was I couldn't talk to multiple models at once, even if they were remote models on OpenRouter. If I ask a question in one chat, then switch to another chat and ask a question, it will block until the first one is done.Also Tauri apps feel pretty clunky on Linux for me.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44845613,
    "by": "roscas",
    "timeISO": "2025-08-09T11:15:12.000Z",
    "textPlain": "Tried to run Jan but it does not start llama server. It also tries to allocate 30gb that is the size of the model but my vram is only 10gb and machine is 32gb, so it does not make sense. Ollama works perfect with 30b models.\nAnother thing that is not good is that it make constant connections to github and other sites.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44848144,
    "by": "jwildeboer",
    "timeISO": "2025-08-09T17:00:30.000Z",
    "textPlain": "My name is Jan and I am not an AI thingy. Just FTR. :)",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846300,
    "by": "mathfailure",
    "timeISO": "2025-08-09T13:28:56.000Z",
    "textPlain": "Is this an alternative to OpenWebUI?",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44847724,
    "by": "klausa",
    "timeISO": "2025-08-09T16:15:17.000Z",
    "textPlain": "So this is how women named Siri felt in 2011.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44847197,
    "by": "reader9274",
    "timeISO": "2025-08-09T15:17:39.000Z",
    "textPlain": "Tried to run the gpt-oss:20b in ollama (runs perfectly) and tried to connect ollama to jan but it didn't work.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846208,
    "by": "biinjo",
    "timeISO": "2025-08-09T13:09:58.000Z",
    "textPlain": "Im confused. Isn’t the whole premise of Ollama that its locallt ran? What’s the difference or USP when comparing the two.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846431,
    "by": "semessier",
    "timeISO": "2025-08-09T13:49:14.000Z",
    "textPlain": "still looking for vLLM to support Mac ARM Metal GPUs",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846219,
    "by": "bogdart",
    "timeISO": "2025-08-09T13:14:04.000Z",
    "textPlain": "I tried Jan last year, but the UI was quite buggy. But maybe they fixed it.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44847191,
    "by": "venkyvb",
    "timeISO": "2025-08-09T15:16:19.000Z",
    "textPlain": "How does this compare to LM studio ?",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846161,
    "by": "azyc",
    "timeISO": "2025-08-09T13:00:28.000Z",
    "textPlain": "[dead]",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846805,
    "by": "diggan",
    "timeISO": "2025-08-09T14:35:32.000Z",
    "textPlain": "> Also Tauri apps feel pretty clunky on Linux for me.All of them, or this one specifically? I've developed a bunch of tiny apps for my own usage (on Linux) with Tauri (maybe largest is just 5-6K LoC) and always felt snappy to me, mostly doing all the data processing with Rust then the UI part with ClojureScript+Reagent.",
    "parent": 44846669,
    "depth": 2
  },
  {
    "id": 44847266,
    "by": "_the_inflator",
    "timeISO": "2025-08-09T15:27:24.000Z",
    "textPlain": "Yep. I really see them as an architecture blueprint with a reference implementation and not so much as a one size fits all app.I stumbled upon Jan.ai a couple of months ago when I was considering a similar app approach. I was curious because Jan.ai went way beyond what I considered to be limitations.I haven’t tried Jan.ai yet, I see it as an implementation not a solution.",
    "parent": 44846669,
    "depth": 2
  },
  {
    "id": 44852654,
    "by": "inkyoto",
    "timeISO": "2025-08-10T03:56:38.000Z",
    "textPlain": "> Main deal breaker for me when I tried it was I couldn't talk to multiple models at once […]… which seems particularly strange considering the size of the cloned GitHub repository to be 1.8GiB which swells up to 4.8GiB after running «make build» – I tried to build it locally (which failed anyway).It is startling that a relatively simple UI frontend can add 3Gb+ of build artefacts alone – that is the scale of a Linux kernel build.",
    "parent": 44846669,
    "depth": 2
  },
  {
    "id": 44848388,
    "by": "signbcc",
    "timeISO": "2025-08-09T17:29:57.000Z",
    "textPlain": "> especially the organization's principlesI met the team late last year. They’re based out of Singapore and Vietnam. They ghosted me after promising to have two follow-up meetings, and were unresponsive to any emails, like they just dropped dead.Principles and manifestos are a dime a dozen. It matters if you live by them or just have them as PR pieces. These folks are the latter.",
    "parent": 44846669,
    "depth": 2
  },
  {
    "id": 44846723,
    "by": "c-hendricks",
    "timeISO": "2025-08-09T14:26:13.000Z",
    "textPlain": "Yeah, webkit2gtk is a bit of a drag",
    "parent": 44846669,
    "depth": 2
  },
  {
    "id": 44846363,
    "by": "hoppp",
    "timeISO": "2025-08-09T13:38:01.000Z",
    "textPlain": "It probably loads the entire model into ram at once while ollama solves this and does not, it has a better loading strategy",
    "parent": 44845613,
    "depth": 2
  },
  {
    "id": 44846299,
    "by": "trilogic",
    "timeISO": "2025-08-09T13:28:18.000Z",
    "textPlain": "[flagged]",
    "parent": 44845613,
    "depth": 2
  },
  {
    "id": 44846158,
    "by": "SilverRubicon",
    "timeISO": "2025-08-09T13:00:17.000Z",
    "textPlain": "Did you see the feature list?  It does not deny that makes connections to other sites.- Cloud Integration: Connect to OpenAI, Anthropic, Mistral, Groq, and others- Privacy First: Everything runs locally when you want it to",
    "parent": 44845613,
    "depth": 2
  },
  {
    "id": 44848252,
    "by": "underlines",
    "timeISO": "2025-08-09T17:12:10.000Z",
    "textPlain": "Jan here too, and I work with LLMs full time and I'm a speaker about these topics. Annoying how many times people ask me if Jan.ai is me lol",
    "parent": 44848144,
    "depth": 2
  },
  {
    "id": 44846512,
    "by": "apitman",
    "timeISO": "2025-08-09T13:59:48.000Z",
    "textPlain": "Not exactly. OWUI is a server with a web app frontend. Jan is a desktop app you install. But it does have the ability to run a server for other apps like OWUI to talk to.",
    "parent": 44846300,
    "depth": 2
  },
  {
    "id": 44848451,
    "by": "PeterStuer",
    "timeISO": "2025-08-09T17:38:06.000Z",
    "textPlain": "More an alternative to LM Studio I think from the description.",
    "parent": 44846300,
    "depth": 2
  },
  {
    "id": 44848130,
    "by": "lagniappe",
    "timeISO": "2025-08-09T16:59:29.000Z",
    "textPlain": "Hello Jan ;)",
    "parent": 44847724,
    "depth": 2
  },
  {
    "id": 44848983,
    "by": "accrual",
    "timeISO": "2025-08-09T18:41:50.000Z",
    "textPlain": "I got Jan working with Ollama today. Jan reported it couldn't connect to my Ollama instance on the same host despite it working fine for other apps.I captured loopback and noticed Ollama returning an HTTP 403 forbidden message to Jan.The solution was set environment variables:    OLLAMA_HOST=0.0.0.0\n    OLLAMA_ORIGINS=*\n\nHere's the rest of the steps:- Jan > Settings > Model Providers- Add new provider called \"Ollama\"- Set API key to \"ollama\" and point to http://localhost:11434/v1- Ensure variables above are set- Click \"Refresh\" and the models should loadNote: Even though an API key is not required for local Ollama, Jan apparently doesn't consider it a valid endpoint unless a key is provided. I set mine to \"ollama\" and then it allowed me to start a chat.",
    "parent": 44847197,
    "depth": 2
  },
  {
    "id": 44847517,
    "by": "thehamkercat",
    "timeISO": "2025-08-09T15:56:24.000Z",
    "textPlain": "Exactly: https://github.com/menloresearch/jan/issues/5474Can't make it work with ollama endpointthis seems to be the problem but they're not focusing on it: https://github.com/menloresearch/jan/issues/5474#issuecommen...",
    "parent": 44847197,
    "depth": 2
  },
  {
    "id": 44846210,
    "by": "moron4hire",
    "timeISO": "2025-08-09T13:12:43.000Z",
    "textPlain": "That's not the actual tagline being used in the repo. The repo calls itself an alternative to ChatGPT. Whoever submitted the link changed it.",
    "parent": 44846208,
    "depth": 2
  },
  {
    "id": 44846342,
    "by": "hoppp",
    "timeISO": "2025-08-09T13:34:45.000Z",
    "textPlain": "I think its an alternative because ollama has no UI and its hard to use for non-developers who will never touch the CLI",
    "parent": 44846208,
    "depth": 2
  },
  {
    "id": 44846951,
    "by": "baggiponte",
    "timeISO": "2025-08-09T14:50:50.000Z",
    "textPlain": "Yeah. The docs tell you that you should build it yourself, but…",
    "parent": 44846431,
    "depth": 2
  },
  {
    "id": 44846785,
    "by": "diggan",
    "timeISO": "2025-08-09T14:33:39.000Z",
    "textPlain": "Please do try it out again, if things used to be broken but they no longer are, it's a good signal that they're gaining stability :) And if it's still broken, even better signal that they're not addressing bugs which would be worse.",
    "parent": 44846219,
    "depth": 2
  },
  {
    "id": 44847525,
    "by": "rmonvfer",
    "timeISO": "2025-08-09T15:57:24.000Z",
    "textPlain": "I use both and Jan is basically the OSS version of LM Studio with some added features (e.g, you can use remote providers)I first used Jan some time ago and didn’t really like it but it has improved a lot so I encourage everyone to try it, it’s a great project",
    "parent": 44847191,
    "depth": 2
  },
  {
    "id": 44847538,
    "by": "angelmm",
    "timeISO": "2025-08-09T15:59:12.000Z",
    "textPlain": "For me, the main difference is that LM Studio main app is not OSS. But they are similar in terms of features, although I didn't use LM Studio that much.",
    "parent": 44847191,
    "depth": 2
  }
]