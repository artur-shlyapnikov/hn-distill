[
  {
    "id": 44847197,
    "by": "reader9274",
    "timeISO": "2025-08-09T15:17:39.000Z",
    "textPlain": "Tried to run the gpt-oss:20b in ollama (runs perfectly) and tried to connect ollama to jan but it didn't work.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846669,
    "by": "apitman",
    "timeISO": "2025-08-09T14:18:58.000Z",
    "textPlain": "I really like Jan, especially the organization's principles: https://jan.ai/Main deal breaker for me when I tried it was I couldn't talk to multiple models at once, even if they were remote models on OpenRouter. If I ask a question in one chat, then switch to another chat and ask a question, it will block until the first one is done.Also Tauri apps feel pretty clunky on Linux for me.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44847191,
    "by": "venkyvb",
    "timeISO": "2025-08-09T15:16:19.000Z",
    "textPlain": "How does this compare to LM studio ?",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846208,
    "by": "biinjo",
    "timeISO": "2025-08-09T13:09:58.000Z",
    "textPlain": "Im confused. Isn’t the whole premise of Ollama that its locallt ran? What’s the difference or USP when comparing the two.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44845613,
    "by": "roscas",
    "timeISO": "2025-08-09T11:15:12.000Z",
    "textPlain": "Tried to run Jan but it does not start llama server. It also tries to allocate 30gb that is the size of the model but my vram is only 10gb and machine is 32gb, so it does not make sense. Ollama works perfect with 30b models.\nAnother thing that is not good is that it make constant connections to github and other sites.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846300,
    "by": "mathfailure",
    "timeISO": "2025-08-09T13:28:56.000Z",
    "textPlain": "Is this an alternative to OpenWebUI?",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846431,
    "by": "semessier",
    "timeISO": "2025-08-09T13:49:14.000Z",
    "textPlain": "still looking for vLLM to support Mac ARM Metal GPUs",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846219,
    "by": "bogdart",
    "timeISO": "2025-08-09T13:14:04.000Z",
    "textPlain": "I tried Jan last year, but the UI was quite buggy. But maybe they fixed it.",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846161,
    "by": "azyc",
    "timeISO": "2025-08-09T13:00:28.000Z",
    "textPlain": "[dead]",
    "parent": 44845272,
    "depth": 1
  },
  {
    "id": 44846805,
    "by": "diggan",
    "timeISO": "2025-08-09T14:35:32.000Z",
    "textPlain": "> Also Tauri apps feel pretty clunky on Linux for me.All of them, or this one specifically? I've developed a bunch of tiny apps for my own usage (on Linux) with Tauri (maybe largest is just 5-6K LoC) and always felt snappy to me, mostly doing all the data processing with Rust then the UI part with ClojureScript+Reagent.",
    "parent": 44846669,
    "depth": 2
  },
  {
    "id": 44846723,
    "by": "c-hendricks",
    "timeISO": "2025-08-09T14:26:13.000Z",
    "textPlain": "Yeah, webkit2gtk is a bit of a drag",
    "parent": 44846669,
    "depth": 2
  },
  {
    "id": 44846342,
    "by": "hoppp",
    "timeISO": "2025-08-09T13:34:45.000Z",
    "textPlain": "I think its an alternative because ollama has no UI and its hard to use for non-developers who will never touch the CLI",
    "parent": 44846208,
    "depth": 2
  },
  {
    "id": 44846210,
    "by": "moron4hire",
    "timeISO": "2025-08-09T13:12:43.000Z",
    "textPlain": "That's not the actual tagline being used in the repo. The repo calls itself an alternative to ChatGPT. Whoever submitted the link changed it.",
    "parent": 44846208,
    "depth": 2
  },
  {
    "id": 44846363,
    "by": "hoppp",
    "timeISO": "2025-08-09T13:38:01.000Z",
    "textPlain": "It probably loads the entire model into ram at once while ollama solves this and does not, it has a better loading strategy",
    "parent": 44845613,
    "depth": 2
  },
  {
    "id": 44846158,
    "by": "SilverRubicon",
    "timeISO": "2025-08-09T13:00:17.000Z",
    "textPlain": "Did you see the feature list?  It does not deny that makes connections to other sites.- Cloud Integration: Connect to OpenAI, Anthropic, Mistral, Groq, and others- Privacy First: Everything runs locally when you want it to",
    "parent": 44845613,
    "depth": 2
  },
  {
    "id": 44846299,
    "by": "trilogic",
    "timeISO": "2025-08-09T13:28:18.000Z",
    "textPlain": "If you looking for privacy there is only 1 app in the whole wide internet right now, HugstonOne (I challenge everyone to find another local GUI with that privacy). That said, Jan is also a good app and deserves credit for being local, there is no app without bugs.",
    "parent": 44845613,
    "depth": 2
  },
  {
    "id": 44846512,
    "by": "apitman",
    "timeISO": "2025-08-09T13:59:48.000Z",
    "textPlain": "Not exactly. OWUI is a server with a web app frontend. Jan is a desktop app you install. But it does have the ability to run a server for other apps like OWUI to talk to.",
    "parent": 44846300,
    "depth": 2
  },
  {
    "id": 44846951,
    "by": "baggiponte",
    "timeISO": "2025-08-09T14:50:50.000Z",
    "textPlain": "Yeah. The docs tell you that you should build it yourself, but…",
    "parent": 44846431,
    "depth": 2
  },
  {
    "id": 44846785,
    "by": "diggan",
    "timeISO": "2025-08-09T14:33:39.000Z",
    "textPlain": "Please do try it out again, if things used to be broken but they no longer are, it's a good signal that they're gaining stability :) And if it's still broken, even better signal that they're not addressing bugs which would be worse.",
    "parent": 44846219,
    "depth": 2
  }
]