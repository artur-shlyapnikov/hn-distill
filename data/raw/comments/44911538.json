[
  {
    "id": 44912783,
    "by": "kohsuke",
    "timeISO": "2025-08-15T14:21:37.000Z",
    "textPlain": "So they run 5 different experiments to test the hypothesis, and they were nothing like what I imagined.For example, in one study, they divide participants into two groups, have one group watch https://www.youtube.com/watch?v=fn3KWM1kuAw (that highlights the high socio-emotional capabilities of a robot), while the other watches https://www.youtube.com/watch?v=tF4DML7FIWk (that highlights the low socio-emotional capabilities of a robot)They are then asked if they agree or disagree with a (presumably hypothetical?) company's proposal to reduce employees' welfare, such as replacing a meal with a shake. Two groups showed a different preference.This makes me think about that old question of whether you thank LLM or not. That is treating LLMs more like humans, so if what this paper found holds, maybe that'd nudge our brain subtly toward dehumanizing other real humans!? That's so counter intuitive...",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912786,
    "by": "skeezyboy",
    "timeISO": "2025-08-15T14:21:50.000Z",
    "textPlain": "Essentially he did a bunch of surveys. Apparently this is science",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912630,
    "by": "cryoshon",
    "timeISO": "2025-08-15T14:09:42.000Z",
    "textPlain": "To the point of the paper, it has been a somewhat disturbing experience to see otherwise affable superiors in the workplace \"prompt\" their employees in ways that are obviously downstream of their (very frequent) LLM usage.",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912698,
    "by": "lordnacho",
    "timeISO": "2025-08-15T14:14:39.000Z",
    "textPlain": "One very new behavior is the dismissal of someone's writing as the work of AI.It's sadly become quite common on internet forums to suppose that some post or comment was written by AI. It's probably true in some cases, but people should ask themselves how the cost/benefit to calling it out looks.",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912611,
    "by": "megamix",
    "timeISO": "2025-08-15T14:08:17.000Z",
    "textPlain": "How do you guys read through an article this fast after it's submitted? I need more than 1 hr to think this through.",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912708,
    "by": "cm2012",
    "timeISO": "2025-08-15T14:15:47.000Z",
    "textPlain": "Interesting theory with insufficient evidence",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912486,
    "by": "temporallobe",
    "timeISO": "2025-08-15T13:56:29.000Z",
    "textPlain": "As a Black Sabbath fan, I love that they envisioned dystopian stuff like this. Check out their Dehumanizer album.",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912370,
    "by": "cratermoon",
    "timeISO": "2025-08-15T13:47:13.000Z",
    "textPlain": "I'm unwilling to accept the discussion and conclusions of the paper because of the framing of how LLMs work.> socio-emotional capabilities of autonomous agentsThe paper fails to note that these 'capabilities' are illusory. They are a product of how the behaviors of LLMs \"hack\" our brains and exploit the hundreds of thousands of years of evolution of our equipment as a social species. https://jenson.org/timmy/",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912306,
    "by": "inquirerGeneral",
    "timeISO": "2025-08-15T13:41:15.000Z",
    "textPlain": "[dead]",
    "parent": 44911538,
    "depth": 1
  },
  {
    "id": 44912764,
    "by": "skeezyboy",
    "timeISO": "2025-08-15T14:20:12.000Z",
    "textPlain": "cos its mostly fluff you can skip over",
    "parent": 44912611,
    "depth": 2
  },
  {
    "id": 44912720,
    "by": "jncfhnb",
    "timeISO": "2025-08-15T14:16:32.000Z",
    "textPlain": "Ask AI to summarize and write a response",
    "parent": 44912611,
    "depth": 2
  },
  {
    "id": 44912464,
    "by": "kohsuke",
    "timeISO": "2025-08-15T13:54:38.000Z",
    "textPlain": "But that's beside the point of the paper. They are talking about how the humans perciving the \"socio-emotional capabilities of autonomous agents\" change their behavior toward other humans. Whether people get that perception because \"LLMs hack our brain\" or something else is largely irrelevant.",
    "parent": 44912370,
    "depth": 2
  },
  {
    "id": 44912463,
    "by": "Isamu",
    "timeISO": "2025-08-15T13:54:37.000Z",
    "textPlain": "No, I think the thesis is that people perceive falsely that agents are highly human, and as a result assimilate downward toward the agent’s bias and conclusions.That is the dehumanization process they are describing.",
    "parent": 44912370,
    "depth": 2
  },
  {
    "id": 44912523,
    "by": "chrisweekly",
    "timeISO": "2025-08-15T13:59:22.000Z",
    "textPlain": "+1 InsightfulYour \"timmy\" post deserves its own discussion. Thanks for sharing it!",
    "parent": 44912370,
    "depth": 2
  },
  {
    "id": 44912518,
    "by": "kingkawn",
    "timeISO": "2025-08-15T13:59:07.000Z",
    "textPlain": "The paper literally spells out that this is a perception of the user and that is the root of the impact",
    "parent": 44912370,
    "depth": 2
  },
  {
    "id": 44912497,
    "by": "stuartjohnson12",
    "timeISO": "2025-08-15T13:57:00.000Z",
    "textPlain": "Your socio-emotional capabilities are illusory. They are a product of how craving for social acceptance \"hacks\" your brain and exploits the hundreds of thousands of years of evolution of our equipment as a social species.",
    "parent": 44912370,
    "depth": 2
  }
]