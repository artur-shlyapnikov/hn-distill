{
  "id": 44834918,
  "title": "How attention sinks keep language models stable",
  "url": "https://hanlab.mit.edu/blog/streamingllm",
  "by": "pr337h4m",
  "timeISO": "2025-08-08T08:53:10.000Z",
  "commentIds": [
    44835762,
    44836836,
    44837863,
    44836310,
    44837403,
    44835732,
    44844032,
    44842811,
    44838291,
    44836029,
    44840413
  ],
  "score": 192,
  "descendants": 31
}