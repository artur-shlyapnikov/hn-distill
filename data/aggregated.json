{
  "updatedISO": "2025-08-07T12:16:49+03:00",
  "items": [
    {
      "id": 44821642,
      "title": "40 Years of the Amiga, from Commodore – By Paul Lefebvre",
      "url": "https://www.goto10retro.com/p/40-years-of-the-amiga-from-commodore",
      "by": "rbanffy",
      "timeISO": "2025-08-07T07:36:15.000Z",
      "postSummary": "В июле 1985 года миру официально представили Commodore Amiga — революционный компьютер с не менее удивительной историей разработки.\n\nБудучи «атари‑человеком» в 80‑х, я знал об Amiga по упоминаниям в журналах Atari и колонках вроде ANALOG Computing и Creative Computing.\n\n«Отцом» Amiga был легендарный разработчик чипов Джей Майнер — главный конструктор Atari 2600/VCS и 8‑битных Atari. В 1982 году он ушёл из Atari и занялся кардиостимуляторами.\n\nВскоре Ларри Каплан (экс‑Atari, сооснователь Activision) предложил Майнеру возглавить железо для новой игровой системы в его компании Hi‑Toro. Из Tonka пришёл Дэвид Морс, компанию вскоре переименовали в Amiga.\n\nРаботая над приставкой, Amiga продавала аксессуары для Atari 2600, чтобы финансироваться. Ранний код «Lorraine» часто всплывал в слухах журналов. Проект задумывался как приставка, но Майнер хотел компьютер; после краха индустрии игр в 1983‑м так и вышло — курс сменили на ПК.\n\nДенег не хватало: разработка дорога. Amiga получила $500 тыс. от Atari с правом Atari использовать технологии Amiga в консолях и компьютерах.\n\nВ начале 1984‑го Джек Трамиел ушёл из Commodore и вскоре купил у Warner компанию Atari, переименовав свою Trammel Technologies в Atari Corp. Примерно через месяц Commodore, не имея своего 16‑битного проекта, купила Amiga за $27 млн. Узнав о займе Warner/Atari, стороны подали иски, из‑за чего Commodore долго не могла публично говорить об Amiga.\n\nТем не менее, 23 июля 1985 года Amiga была официально анонсирована — любопытно, что всего через несколько недель после начала поставок Atari 520ST. Премьеру устроили с размахом в нью‑йоркском Линкольн‑центре с участием Дебби Харри и Энди Уорхола.\n\nИзначально маркетинг упирал на имя Amiga и почти не использовал бренд Commodore: часто говорили «Amiga, from Commodore». К 1987‑му вернулись к «Commodore Amiga». Некоторые ранние ролики были очень странными.\n\nЛично я знал об Amiga лишь по слухам и до сих пор ею не пользовался. Первые подробности прочёл в номере Compute! за сентябрь 1985 — обложка и большой материал о новинке.\n\nЧестно говоря, я тогда немного «горел»: обложка с анонсом вышла за месяц до обзора реально поставляемой модели.",
      "commentsSummary": "- Участники делятся ностальгией и ресурсами по Amiga: рекомендуют книгу “The Future Was Here”, подробно объясняющую железо и знаменитую демо с прыгающим шаром.  \n- Вспоминают опыт с Amiga 2000: особенно с PC bridgeboard на 8088 для запуска MS-DOS и GW-BASIC, что помогало оправдать покупку как “для учебы, не только игр”.  \n- Отмечают сильное представление Amiga на VCF West к 40-летию платформы; обещают видео на YouTube.  \n- Обсуждают свежие новости о бренде: Perifractic приобрел Commodore; команда не исключает возможного приобретения прав на Amiga.  \n- Делятся личными воспоминаниями о разработке на Amiga (Aztec C, ассемблер, собственные библиотеки) и “вечных спорах” Amiga vs Atari.  \n- Технический контекст: ОС намеренно распространяли на носителях, а не в ПЗУ, из-за багов и гибкости обновлений; вопрос стоимости ПЗУ vs RAM упоминается.  \n- Юридическая сторона владения правами на Amiga ссылается на “Amiga Documents” для подробностей.",
      "score": 36,
      "commentsCount": 10,
      "hnUrl": "https://news.ycombinator.com/item?id=44821642",
      "domain": "goto10retro.com"
    },
    {
      "id": 44819968,
      "title": "Running GPT-OSS-120B at 500 tokens per second on Nvidia GPUs",
      "url": "https://www.baseten.co/blog/sota-performance-for-gpt-oss-120b-on-nvidia-gpus/",
      "by": "philipkiely",
      "timeISO": "2025-08-07T02:28:47.000Z",
      "postSummary": "- В день выхода открытой модели вроде gpt-oss-120b мы сразу ускоряем её для клиентов, как партнёры запуска OpenAI. К концу дня запуска стали лидерами на NVIDIA по латентности и пропускной способности по данным OpenRouter.\n\n- Быстрая оптимизация обеспечена гибким стеком инференса и экспертизой команды; за время написания поста прибавили ещё ~100 ток/с при 100% аптайме.\n\n- Работы включали:\n  - Тесты и бенчмарки в TensorRT-LLM, vLLM и SGLang.\n  - Совместимость с архитектурами Hopper и Blackwell.\n  - Интеграцию с нашим стеком (в т. ч. NVIDIA Dynamo).\n  - Оптимизации: маршрутизация с учётом KV-кэша, спекулятивная генерация с Eagle.\n\nШаг 1: Первый инференс\n- Запускаем базовый инференс в любом доступном фреймворке и на нужных GPU/серверных уровнях.\n- Параллелим работу: одни пробуют vLLM и SGLang, другие — TensorRT-LLM; быстрее всего взлетел TensorRT-LLM.\n- Важно обслуживать модель и на Hopper (H100), и на Blackwell (B200) для широкой доступности и максимальной скорости.\n- Гибкость рантайма позволяет быстро переключать инструменты и обновлять матрицу поддержки.\n\nШаг 2: Исправление багов совместимости\n- Новые архитектуры приводят к тонким несовместимостям; GPT OSS добавил, например, Harmony — новый формат ответов.\n- Итеративно чиним и валидируем на скорость и корректность; по возможности контрибутим обратно в open source.\n- Благодаря сообществу есть несколько отличных путей запуска GPT OSS, проблемы быстро выявляются и чинятся.\n\nШаг 3: Оптимизация конфигурации\n- Хотя GPT OSS 120B можно запустить на одном H100, оптимально масштабировать на 4–8 GPU для лучшей латентности/throughput.\n- Рассмотрены два подхода параллелизма для MoE: тензорный и экспертный. Тензорный даёт меньшую задержку, экспертный — выше системную пропускную способность. Мы выбрали тензорный, так как приоритет — латентность.\n- Приняли MoE Backend в TensorRT-LLM (поддерживается на Blackwell, не на Hopper), который добавляет более быстрые CUDA-ядра и превосходит предыдущие решения.",
      "commentsSummary": "- Обсуждение опыта запуска GPT-OSS локально: на MacBook Pro (M4, 128 ГБ) модель быстрая лишь при небольших контекстах; свыше ~10k токенов резко падает скорость, а отсутствие MCP/веб-поиска ухудшает взаимодействие.  \n- Разработчики сравнивают фреймворки: TensorRT-LLM признают самым производительным, но сложным в настройке и иногда отстающим; vLLM и SGLang проще стартовать.  \n- На потребительском железе: 4090 интересует по скоростям; контраст с “широко доступными” H100 вызывает сарказм из‑за цены и доступности.  \n- Отмечают простоту запуска GPT-OSS 20B на Mac (через Llama) и удивление, сколько “допилятий” нужно, чтобы получить хорошее качество — это не “из коробки”.  \n- Поднимается вопрос терминологии GPU: потребительские “игровые” против датацентровых для ИИ, и что “доступный” не равен “дешевый”.  \n- Спекулятивное декодирование вызывает вопросы: как валидировать драфт-токены без фактического прогона целевой модели и где реальная выгода.  \n- Политический контекст: поддержка open-source/open-weight в планах США радует, но OSS от крупных компаний вызывает смешанные чувства; шутки про “очень быстрый генератор отказов” и “освободить” H100.",
      "score": 143,
      "commentsCount": 55,
      "hnUrl": "https://news.ycombinator.com/item?id=44819968",
      "domain": "baseten.co"
    },
    {
      "id": 44819917,
      "title": "We replaced passwords with something worse",
      "url": "https://blog.danielh.cc/blog/passwords",
      "by": "max__dev",
      "timeISO": "2025-08-07T02:19:25.000Z",
      "postSummary": "Слишком многие сервисы используют такой вход:\n- Введите email или телефон\n- Сайт отправит 6‑значный код\n- Введите код для входа\n\nПожалуйста, прекратите.\n\nПочему это плохо для безопасности:\n- Злоумышленник может отправить ваш email на легитимный сервис и заставить вас ввести присланный код в фишинговой форме. Вы не можете быть уверены, где именно нужно вводить код. Менеджеры паролей тут не помогают.\n- Этот метод реально эксплуатируется: вход Microsoft для аккаунтов Minecraft использует такие коды, и уже множество аккаунтов было украдено (есть подтверждения на Reddit и YouTube, а также в документации Microsoft).",
      "commentsSummary": "- Обсуждение критикует вход по одноразовому коду из email/SMS: он легко фишится через «посредника», когда злоумышленник запускает вход на легитимном сайте, а пользователя обманывает ввести код на фальшивом.  \n- Многие отмечают, что это ухудшает привычки безопасности и UX: постоянные коды, путаница с почтой, сбои при переключении аккаунтов, автофил паролей работает лучше.  \n- Предлагаемые смягчения: магические ссылки вместо кодов (меньше риска MITM), полноценные пароли с менеджерами паролей, классическая MFA, а лучше — поведенческое обнаружение «странных» логинов.  \n- Идёт спор, что хуже по факту: фишинг кодов или массовые компромиссы из‑за утечек/повторного использования паролей; часть считает код по email менее опасным для среднего пользователя.  \n- Passkeys вызывают споры: одни «за» (особенно в экосистемах Apple), другие критикуют за проблемы с резервированием/восстановлением, аттестациями и UX; различают синхронизируемые vs. привязанные к устройству ключи.  \n- Дополнительно жалуются на навязывание пароль-less входа сервисами, перенос рисков на почтовых провайдеров, и странные побочки (например, отписка от рассылок ломает вход).  \n- Консенсус отсутствует: «все методы аутентификации плохи», важно комбинировать факторы, делать удобный автофил/менеджеры, уменьшать фишинг через ссылки/пасски, и иметь надёжные сценарии восстановления.",
      "score": 223,
      "commentsCount": 197,
      "hnUrl": "https://news.ycombinator.com/item?id=44819917",
      "domain": "blog.danielh.cc"
    },
    {
      "id": 44811567,
      "title": "Claude Code IDE integration for Emacs",
      "url": "https://github.com/manzaltu/claude-code-ide.el",
      "by": "kgwgk",
      "timeISO": "2025-08-06T13:17:38.000Z",
      "commentsSummary": "- Участники обсуждают интеграцию AI-инструментов (Claude Code, Aider и др.) в Emacs/Vim: это делает «нишевые» редакторы конкурентоспособнее, позволяя им полагаться на внешние IDE‑фичи и сосредоточиться на сильных сторонах редакторов.  \n- Многие считают Emacs идеальной средой для агентов из‑за глубокой кастомизации и доступа к состоянию редактора через elisp; есть уже несколько пакетов интеграции (claude-code.el, claude-code-emacs, ECA, claudemacs и др.).  \n- Есть и обратная сторона: сложность настройки современного Emacs-стека (LSP, tree-sitter, AI) и проблемы UX в терминальных интеграциях, особенно с evil-mode; некоторые предпочитают просто использовать терминал.  \n- Пользователи хотят: интеграцию с org-mode/знаниевой базой и долговременным хранением диалогов, поддержку разных провайдеров/моделей (OpenCode, DeepSeek, OpenAI-совместимые API), а также решения для приватности (изоляция с bubblewrap).  \n- Идут споры о востребованности таких инструментов среди эмаксеров и «профанации» идеалов GNU/FSF; при этом многие отмечают практическую пользу и рост продуктивности.  \n- Поднимаются вопросы оплаты и корпоративного доступа к моделям, локального запуска на доступном железе, а также стандартизации API для «агентских» инструментов наподобие LSP.  \n- Для Neovim/Helix тоже ищут аналогичные решения; часть пользователей сравнивает с gptel/копилотом и просит аргументы для перехода.",
      "score": 654,
      "commentsCount": 220,
      "hnUrl": "https://news.ycombinator.com/item?id=44811567",
      "domain": "github.com"
    },
    {
      "id": 44787738,
      "title": "Debounce",
      "url": "https://developer.mozilla.org/en-US/docs/Glossary/Debounce",
      "by": "aanthonymax",
      "timeISO": "2025-08-04T16:04:13.000Z",
      "postSummary": "Дебаунс — это техника ограничения частоты вызова функции. В течение заданной задержки все входящие вызовы игнорируются, а выполняется только один — либо первый (leading), либо последний (trailing), в зависимости от настроек. Это помогает оптимизировать производительность и избежать лишних вычислений при частых событиях.\n\nПрименение:\n- Обработчики ввода: ждать паузы перед запросом автодополнения.\n- События прокрутки/изменения размера: запускать вычисления после остановки действий пользователя.\n- Клики и сабмиты: предотвращать множественные отправки.\n\nОтличие от троттлинга: троттлинг гарантирует вызовы с фиксированным интервалом, а дебаунс — один вызов после серии событий (или сразу первый, если включен leading).\n\nКлючевые параметры:\n- delay: время ожидания.\n- leading/trailing: когда вызывать — в начале или в конце паузы.\n- maxWait (если предусмотрено): гарантирует вызов, даже если события не прекращаются.",
      "commentsSummary": "- Обсуждение крутится вокруг «дебаунса» API-запросов и UI-событий: приводится статья с примерами на AbortController и таймаутах для подавления лишних fetch-вызовов.  \n- Предупреждение: дебаунс/троттлинг плохо сочетаются с async-функциями — можно получить «нарушение причинности», когда возвращается устаревший Promise и результат.  \n- Возникает спор об аналогии с аппаратным дебаунсом: некоторые считают её некорректной; в электронике применяют асимметричные стратегии (быстрый Make, задержанный Break), что противоположно типичным UI-паттернам.  \n- Другие участники отмечают, что «debouncing» — устоявшийся термин в фронтенде, ближе к управлению обратной связью: сокращение лишних событий вроде oninput или авто-сейвов.  \n- Предлагается использовать реактивные инструменты (например, RxJS switchMap), которые естественно моделируют временные зависимости и отмену предыдущих запросов.  \n- Отмечено, что для поисковых подсказок полный пересчёт на каждый ввод избыточен: важнее показывать итоговое, а не промежуточные шумные результаты.  \n- Запрошены корректные примеры реализации; подчеркивается, что для «задержанного» события в UI уместнее логика «обработать только последний ввод после периода тишины», а не аппаратные схемы типа защёлок.",
      "score": 31,
      "commentsCount": 10,
      "hnUrl": "https://news.ycombinator.com/item?id=44787738",
      "domain": "developer.mozilla.org"
    },
    {
      "id": 44821434,
      "title": "Cracking the Vault: How we found zero-day flaws in HashiCorp Vault",
      "url": "https://cyata.ai/blog/cracking-the-vault-how-we-found-zero-day-flaws-in-authentication-identity-and-authorization-in-hashicorp-vault/",
      "by": "nihsy",
      "timeISO": "2025-08-07T07:01:42.000Z",
      "postSummary": "Введение: когда модель доверия подводит\n\nСекрет-хранилища — опора цифровой инфраструктуры: в них лежат креденшелы, токены и сертификаты, управляющие доступом к системам, сервисам, API и данным. Это не просто часть модели доверия — это и есть модель доверия. Если хранилище взломано, инфраструктура уже потеряна.\n\nПонимая, что такие хранилища — цели высокой ценности, команда Cyata провела углубленную оценку HashiCorp Vault — одного из самых популярных решений.\n\nЗа несколько недель мы выявили девять ранее неизвестных уязвимостей нулевого дня, каждой присвоен CVE через ответственное раскрытие. Совместно с HashiCorp все проблемы были исправлены до публикации.\n\nОбнаруженные изъяны обходят блокировки, политики и позволяют выдавать себя за других. Одна уязвимость ведет к повышению привилегий до root, другая — к первому публичному RCE в Vault, дающему полный захват системы.\n\nМы увидели цепочки логических ошибок, которые по отдельности и в комбинации создают опасные пути атаки — особенно в реальных внедрениях с мисконфигами или избыточными правами.\n\nЭто не были ошибки памяти или гонки, а скрытые логические баги в слоях аутентификации, идентичности и политик Vault. Некоторые существовали почти десятилетие — незаметные, но легко эксплуатируемые после понимания.\n\nПредыдущие исследования (например, Google Project Zero, 2020) касались обходов в IAM-бэкендах облаков (AWS, GCP). Мы нацелились на базовые потоки аутентификации Vault, затрагивающие OSS и Enterprise-версии по разным провайдерам.\n\nДалее — что мы нашли, как нашли и что это значит для инфраструктуры, которую должен защищать Vault.\n\nЧто такое HashiCorp Vault?\n\nVault — открытый инструмент для защиты, хранения и контроля доступа к секретам: API-ключам, паролям БД, сертификатам, ключам шифрования.\n\nЕго используют компании разных масштабов: он централизует управление секретами и применяет детальные политики в распределенных системах.\n\nПо сути — это граница безопасности: аутентифицирует людей и машины, посредничает доступу к чувствительным данным.\n\nВ DevSecOps Vault снижает риски хардкода секретов, расползания и несанкционированного доступа. Его ценят за гибкую интеграцию, точные политики и пригодность для сложных сред. Часто это последний сторож секретов: при определенных настройках компрометация Vault равна компрометации всего.\n\nОсновные возможности Vault\n- Управление секретами и крипто-движок для динамичных мульти-/гибрид-облаков\n- Централизованное хранилище с доступом по API\n- Динамическая выдача учетных данных с автоистечением\n- Идентификационно-ориентированный доступ для людей и машин\n- Шифрование как сервис для данных «в покое» и «в пути»\n- Управление сертификатами: выпуск, ротация, отзыв\n- Распределение, включение/отключение и ротация ключей шифрования\n\nМетодология: как мы нашли то, что другие пропустили\n\nЭто целенаправленное исследование логических уязвимостей Vault — тех, что не видны в сканерах памяти и логах падений, но подтачивают модель доверия.\n\nМы исходили из гипотезы: если Vault — якорь доверия, то малые несогласованности в идентичности, аутентификации или политике могут иметь непропорционально большие последствия.\n\nФокус — базовый поток обработки запросов, особенно файл request_handling.go, «мозг» Vault: маршрутизация, разрешение идентичностей, принятие политик. Неделями изучали логику функций и модулей, отслеживая крайние случаи размывания границ доверия.\n\nНе полагались на фаззинг и автопробинг. Проводили глубокий ручной код-ревью, анализируя не только функции, но и интерпретации идентичности/ввода разными компонентами. Увидев несоответствия в регистре, алиасинге, форматировании — углублялись.\n\nКаждый тест — целевая проверка, основанная на коде. Мы думали как атакующие: начиная с минимальных прав, спрашивали «насколько далеко можно продвинуться отсюда?» И повторяли этот цикл, замечая мелкие несоответствия и прослеживая их последствия.",
      "commentsSummary": "- Обсуждается уязвимость: при непроверяемом режиме (non-CA) злоумышленник с доступом к приватному ключу закреплённого сертификата может подменять CN в клиентском сертификате и заставлять Vault привязывать alias.Name к этому CN.  \n- Отмечают, что если атакующий уже имеет приватный ключ закреплённого сертификата, это указывает на более серьёзный компромисс.  \n- В посте перечислены 9 CVE за май–июнь 2025, включая: обход блокировок (через смену регистра в userpass и несовпадение нормализации в LDAP), тайминговую деанонимизацию пользователей, и цепочку эскалаций до RCE; даны ссылки на отдельные CVE.  \n- Замечание о терминологии: упоминание слова “daka” (минута на иврите) в контексте TOTP-периода кажется читателям неуместным или результатом плохой правки.  \n- Общая критика статьи: чрезмерная многословность, ощущение “ИИ-стиля” текста, дублирование уже обсуждавшихся материалов.  \n- Вопросы по применимости к родственным проектам (напр. Bao) и призыв к тестированию из-за близости кодовой базы.  \n- Вывод: проблема в тонкостях разбора строк/входных данных; отсутствие строгих фузз‑тестов и корректной нормализации часто приводит к таким уязвимостям.",
      "score": 62,
      "commentsCount": 26,
      "hnUrl": "https://news.ycombinator.com/item?id=44821434",
      "domain": "cyata.ai"
    },
    {
      "id": 44777419,
      "title": "Herbie detects inaccurate expressions and finds more accurate replacements",
      "url": "https://herbie.uwplse.org/",
      "by": "bwidlar",
      "timeISO": "2025-08-03T15:54:30.000Z",
      "postSummary": "Herbie: автоматическое повышение точности вычислений с плавающей запятой\n\nНайдите и исправьте проблемы с числами с плавающей точкой:\nsqrt(x+1) - sqrt(x) → 1/(sqrt(x+1) + sqrt(x))\nКрасная формула неточна при x > 1; синяя точна для всех x.\n\nИспользование\n- Веб-демо\n- Установка\n- Новости\n- Блог\n\nОбучение\n- Учебник\n- Заметки о релизах\n- Документация\n- Статьи о Herbie\n\nВклад\n- Исходный код\n- Сообщить об ошибке\n- Лицензия\n\nГрафик: Herbie повышает точность на наборе эталонов «Hamming». Длиннее стрелка — лучше: старт — точность исходного выражения, финиш — точность результата Herbie (на случайных double-входах).\n\nНовости проекта Herbie\n1) 4 авг: вышел Herbie 2.2 с новой платформенной API для подключаемых целевых платформ. Попробуйте!\n2) 17 июл: релиз Herbie 2.1 — быстрее сгенерированный код и сам Herbie.\n3) 30 июн: релиз Herbie 2.0 — оптимизация по точности и скорости, переработанные отчёты и метрики.\n4) 24 июл: пере-релиз Herbie 1.5 из‑за проблем с инфраструктурой; попробуйте установить снова.\n5) 9 июл: релиз Herbie 1.5 — сортировка аргументов, множественные выходы.\n6) 14 июн: Бретт и Оливер доклад на ARITH 2021 о настройке точности в Herbie; есть статья.\n7) 21 июл: Зак и Павел доклад о пяти годах Herbie: доверие, измерения, сообщество, обобщаемость.\n8) 20 июл: релиз Herbie 1.4 — заметные ускорения и улучшения удобства.\n9) 18 ноя: Дэвид о FPBench 1.2 и новшествах Herbie на Correctness 2019 (Денвер).\n10) 17 ноя: Herbie упомянут в докладе Павла на уроке по анализу FP на SC’19.\n11) 1 мая: Павел станет доцентом в Университете Юты, присоединившись к Ганешу и Звонимиру.\n12) 13 мар: Зак — ключевой доклад на CoNGA’19 о многоточности/многоформатных вычислениях и поддержке в Herbie, FPBench и Titanic.\n13) 20 июн: Алекс — доклад о Herbgrind на PLDI’18; как искать неточные FP‑выражения в больших кодовых базах.\n14) 15 июн: релиз Herbie 1.2 — больше креативности и точности, новые ветвления и более точные параметры.\n15) 9 апр: сотрудничество",
      "commentsSummary": "- Участники позитивно оценивают представленный инструмент/работу.  \n- Пользователь @permalaise отмечает, что это выглядит как интересная и ценная работа.  \n- Пользователь @4gotunameagain называет инструмент потрясающим и делится практическим опытом использования.  \n- Он применяет его для моделирования с симплектическими интеграторами на больших временных интервалах.  \n- Основная выгода — снижение накопленной погрешности при длительных симуляциях.",
      "score": 38,
      "commentsCount": 2,
      "hnUrl": "https://news.ycombinator.com/item?id=44777419",
      "domain": "herbie.uwplse.org"
    },
    {
      "id": 44819037,
      "title": "Rules by which a great empire may be reduced to a small one (1773)",
      "url": "https://founders.archives.gov/documents/Franklin/01-20-02-0213",
      "by": "freediver",
      "timeISO": "2025-08-06T23:29:11.000Z",
      "postSummary": "- Сатира «Правила, по которым большая империя может быть уменьшена до малой» была напечатана в Public Advertiser 11 сентября 1773 года как пара к «Эдикту короля Пруссии». Франклин ценил их краткость, ёмкость и необычную форму, но «Правила» предпочитал за разнообразие и «энергичные концовки абзацев». В одной он предлагал взглянуть на политику метрополии глазами колонистов, в другой — вообразить себя колонистами. Цель — заставить публику по‑новому увидеть американский вопрос накануне парламентских дебатов и дела о Хатчинсоне и Оливере. Оба текста быстро разошлись и многократно переиздавались по обе стороны Атлантики.\n\n- Эффект был двояким: сатира редко убеждает — открытых она развлекает, упорных злит. Франклин понимал риск: желая осветить колониальные жалобы, он мог все усугубить. По его мнению, правительство публично игнорировало нападки, чтобы не раздувать их, но именно они во многом объяснили ярость против него в начале 1774 года.\n\n- Содержание «Правил» не было новым: он уже высказывал те же тезисы в несатирической форме. Конституционных тонкостей Бостона почти не касался — их трудно высмеивать, — но собрал привычные темы: торговые ограничения, новые налоги, давление армии и флота, общеколониальные и массачусетские сюжеты. Сатира придала им остроту, но ненадолго: вскоре власти ударили по нему и, ирония судьбы, воплотили многие «правила» в Коэрцитивных актах 1774 года.\n\n- Для Public Advertiser. «Правила, по которым БОЛЬШАЯ империя уменьшается до МАЛОЙ. [Частно представлены одному недавнему министру при вступлении в должность; публикуются впервые.]»\n\n- Преамбула: древний мудрец гордился, что хоть и не умел играть на скрипке, знал, как сделать из малого города большой. Автор, «современный простак», предлагает обратную науку — полезную министрам, у которых слишком много дел, чтобы «играть на скрипке».\n\n- Правило I: большая империя — как большой пирог — легче всего убывает с краёв. Начинайте с дальних провинций: избавляясь от них по периметру, потянутся и следующие.\n\n- Правило II: чтобы возможность отделения всегда сохранялась, не допускайте слияния провинций с метрополией: никаких общих прав и торговых привилегий, более суровые законы, принятые без их участия в выборе законодателей. Подобно пекарю, заранее надрезайте тесто по линиям будущего разлома.",
      "commentsSummary": "- Обсуждение сосредоточено на тексте Франклина 1773 года: он много лет безуспешно убеждал британские власти учесть жалобы колоний, что предвосхищает Декларацию независимости и раскол 1775 года.  \n- Комментаторы отмечают саркастический тон Франклина и идею, что сатира чаще поляризует, чем убеждает; некоторые видят в тексте универсальные «правила» упадка империй и «элитной слепоты».  \n- Обсуждают исторический контекст: в Британии были и политики, понимавшие риск силового давления; упоминаются музей Франклина в Лондоне и популярные подкасты по теме.  \n- Значительная ветка — о типографике XVIII века: длинная s, частая капитализация существительных; приводятся примеры из Конституции и других документов, отмечается стилистический характер этих норм.  \n- Параллели проводят с современностью (Пакс Американа) и вопросом, повторяются ли властные структуры по инерции.  \n- Возникает побочная дискуссия о «непрерывности» Китая: участники спорят о циклах объединения/распада, различиях династий и современного государства, а также о мифе непрерывности для нацстроительства.",
      "score": 155,
      "commentsCount": 96,
      "hnUrl": "https://news.ycombinator.com/item?id=44819037",
      "domain": "founders.archives.gov"
    },
    {
      "id": 44817539,
      "title": "Project Hyperion: Interstellar ship design competition",
      "url": "https://www.projecthyperion.org/",
      "by": "codeulike",
      "timeISO": "2025-08-06T20:40:17.000Z",
      "postSummary": "Проект Hyperion исследует возможность пилотируемых межзвездных полетов на поколенческих кораблях с использованием нынешних и ближайших технологий. Такой корабль рассчитан на многовековой путь: экипаж живет и сменяется поколениями, поддерживая замкнутую экосистему с сельским хозяйством, жильем и системами жизнеобеспечения.\n\nИнициатива i4is объявила победителей международного конкурса дизайна поколенческого корабля для 250‑летнего перелета к обитаемой планете. Междисциплинарные команды проектировали среду, способную поддерживать и развивать общество при жестких ресурсных ограничениях.\n\nУсловия конкурса требовали совместной работы архитекторов, инженеров и социальных ученых над ключевыми аспектами закрытого общества на века, включая:\n- Обитаемость для 1 000 ± 500 человек\n- Искусственную гравитацию за счет вращения\n- Достойные условия жизни и базовые потребности\n- Надежные контуры жизнеобеспечения: пища, вода, отходы, атмосфера\n- Механизмы передачи знаний и культуры\n\nПодробнее о требованиях — по ссылке на документ.\n\nБлагодарности жюри\n\nРаботы оценивали эксперты из архитектуры, инженерии и социальных наук (Университет Хьюстона; NASA‑JPL; Университет штата Аризона; Университет штата Орегон; Университет Южной Калифорнии).\n\n1 место\n\nКоманда: Giacomo Infelise, Veronica Magli, Guido Sbrogio', Nevenka Martinello, Federica Chiara Serpe\n\nОтзыв жюри\n\nChrysalis выделился системной целостностью и инновационной модульной архитектурой, глубокой проработкой (включая производство в космосе и подготовку экипажа в Антарктике). Модульная оболочка гибка и масштабируема; большой Купол придает выразительность. Сильны планирование строительства корабля и защита от радиации; конструктив реалистичен. Культурный блок можно развить, но концепт убедителен и зрелищен, отсылает к «Раме» и мировым кораблям 1980‑х.\n\n2 место\n\nКоманда: Julia Biernacik, Jakub Kot, Aleksandra Wróbel, Jacek Janas, Michał Kucharski, Wiktoria Kuchta, Natalia Łakoma, Katarzyna Śliwa\nНаставник: д-р хаб. Michał Kracik\nФакультет промышленного дизайна (студия «Дизайн для экстремальных сред»), Академия изящных искусств в Кракове\n\nОтзыв жюри\n\nWFP Extreme отмечен за общий уровень и акцент на культуре и обществе: одежда, духовные пространства, «такси‑капсула», персонализированная униформа, защита от радиации. Системная целостность и интерьер при искусственной гравитации требуют доработки, но конструктив уместен для орбитальных применений. Балансирует технические амбиции с тонким видением будущей космической жизни.",
      "commentsSummary": "- Обсуждение вращается вокруг конкурса по проектированию поколенческого космического корабля, вызывая параллели с International Space Settlement Design Competition и напоминая о работах Кима Стэнли Робинсона (Aurora) и фильме Aniara как критике идеи.  \n- Скептики указывают на психические и социальные риски многовекового полёта: скука, конфликты, упадок целей, хрупкость демократии; другие возражают, что люди исторически справлялись с многопоколенческими миссиями и адаптируются.  \n- Обсуждаются биосферы и закрытые экосистемы (Biosphere 2), сложности поддержания океанов и кислотности, а также сомнения в возможности успешной беременности без защитного магнитного поля.  \n- Технические вопросы: несоответствия в расчетах скорости/времени (0.1g → ближе к 0.1c, а не 0.01c), критика вращающихся оболочек на 400 лет, дублирование ядерного синтеза, отсутствие проработки пропульсии; предлагаются альтернативы вроде пульс-ядерных систем, подвоз топлива и «нанобот-строители».  \n- Генетика и демография: для экипажа 1,000±500 человек предлагают использовать эмбрио-банки для поддержания разнообразия; спорят о минимально жизнеспособной популяции и рисках инбридинга.  \n- Экономика и реализм: гигантская масса (порядка миллионов тонн) и стоимость запусков на триллионы долларов делают проект малореалистичным без прорывов в физике или стоимости вывода.  \n- Мнения поляризованы: одни вдохновлены дизайнами и культурным аспектом, другие считают межзвёздные полёты фантазией; звучат призывы «сначала починить Землю», но также — аргументы, что найдутся добровольцы для таких миссий.",
      "score": 246,
      "commentsCount": 189,
      "hnUrl": "https://news.ycombinator.com/item?id=44817539",
      "domain": "projecthyperion.org"
    },
    {
      "id": 44819738,
      "title": "A candidate giant planet imaged in the habitable zone of α  Cen A",
      "url": "https://arxiv.org/abs/2508.03814",
      "by": "pinewurst",
      "timeISO": "2025-08-07T01:42:18.000Z",
      "postSummary": "- Сообщается о коронографических наблюдениях ближайшей солнечноподобной звезды α Cen A инструментом MIRI на JWST в августе 2024, феврале и апреле 2025. Достигнута чувствительность для обнаружения планет с T_eff≈225–250 K (1–1,2 R_Jup) на угловых расстояниях 1\"–2\" и пыли экзозодикального диска на уровнях >5–8 яркостей солнечной зодиакальной пыли. Отсутствие экзозоди даёт рекордный верхний предел — всего в несколько раз выше солнечной зодиакальной, что в ≥10 раз чувствительнее предыдущих измерений для иных систем.\n\n- В августе 2024 обнаружен точечный источник S1 с F_ν(15,5 мкм)=3,5 мЯн на расстоянии 1,5\" от α Cen A. Единственный успешный ролл-угол не позволяет однозначно подтвердить, что это планета. Анализ исключает фон/передний план. В феврале и апреле 2025 S1 не найден. Если S1 — то же, что объект C1 из VLT/NEAR (2019), то существует 52% вероятность, что кандидата S1+C1 не увидели в двух последующих наблюдениях JWST/MIRI из‑за орбитального смещения.\n\n- С учётом ненахождений получены семейства динамически устойчивых орбит для S1+C1 с периодами 2–3 года. Они указывают на эксцентриситет e≈0,4 и значительное наклонение относительно плоскости орбиты α Cen AB (взаимный наклон i≈50° или ≈130°). По фотометрии и орбитальным свойствам кандидат может иметь T≈225 K, радиус ≈1–1,1 R_Jup и массу 90–150 M_⊕, что согласуется с пределами по РВ.\n\n- Принято в ApJL; 34 стр., 22 рисунка, 10 таблиц. Тематики: экзопланеты и звёздная/солнечная астрофизика. DOI: 10.48550/arXiv.2508.03814. Версия v1 от 5 августа 2025.",
      "commentsSummary": "- Обсуждают кандидата в планеты с температурой около 225 K (~−48 °C), радиусом примерно 1–1.1 радиуса Юпитера и массой 90–150 земных масс; данные согласуются с ограничениями по лучевой скорости.  \n- Один из участников надеется, что у планеты могут быть интересные спутники.  \n- Вычислили оценку ускорения свободного падения на «поверхности»: около 9.7 м/с² при массе ~120 M⊕ и радиусе ~1 R♃.  \n- Другой участник уточнил единицы: правильно писать м/с².  \n- Отмечено, что температура далека от «уютной».  \n- Подчёркнуто, что у газового гиганта нет твёрдой поверхности, так что «поверхность» условна.",
      "score": 65,
      "commentsCount": 19,
      "hnUrl": "https://news.ycombinator.com/item?id=44819738",
      "domain": "arxiv.org"
    },
    {
      "id": 44807868,
      "title": "Show HN: Kitten TTS – 25MB CPU-Only, Open-Source TTS Model",
      "url": "https://github.com/KittenML/KittenTTS",
      "by": "divamgupta",
      "timeISO": "2025-08-06T05:04:36.000Z",
      "commentsSummary": "- Сообщество обсуждает KittenTTS — сверхмалый (около 25 МБ) офлайн TTS под Apache-2.0, который работает на CPU и потенциально на очень слабом железе; ключевое — открытая лицензия и автономность.  \n- Пользователи делятся демо и веб-версией; бенчмарки показывают низкую латентность (~315 мс) и генерацию быстрее реального времени на мощном ноутбуке, но качество голоса оценивают как «приемлемое для размера», местами механическое, с ошибками на числах и коротких фразах.  \n- Отмечают проблемы с установкой зависимостей и несовместимостью версий Python; звучит запрос на ONNX/gguf-порт и упрощение интеграции.  \n- Идут сравнения с более крупными/качественными моделями (f5-tts, fish-speech, XTTS, piper/kokoro): KittenTTS — не SOTA по естественности, но ценен размером, скоростью и CPU-режимом, особенно для встраиваемых и офлайн-сценариев.  \n- Много вопросов о мультиязычности, обучающих данных, планах релиза кода для тренировки/тонкой настройки и возможности локального клонирования голоса.  \n- Отдельно упоминают, что для STT многие используют Whisper; просят рекомендации SOTA TTS для средних ноутбуков и отмечают важность доступности/скорости над предельной натуральностью.  \n- Энтузиасты экспериментируют со стилевыми векторами и предлагают улучшения; общий настрой — проект впечатляет для своего класса и открывает путь к «голосу везде» без облака и GPU.",
      "score": 845,
      "commentsCount": 333,
      "hnUrl": "https://news.ycombinator.com/item?id=44807868",
      "domain": "github.com"
    },
    {
      "id": 44816755,
      "title": "Litestar is worth a look",
      "url": "https://www.b-list.org/weblog/2025/aug/06/litestar/",
      "by": "todsacerdoti",
      "timeISO": "2025-08-06T19:43:01.000Z",
      "postSummary": "- Несколько лет назад мне выпал шанс выбрать async‑first, типизированный Python‑фреймворк для веба. Я взял Litestar — без хайпа и ракет в твитах — и не пожалел: уже около 18 месяцев все мои новые рабочие проекты на нём.\n\n- Даже если вы пишете асинхронные веб‑приложения на Python, вы могли пройти мимо Litestar. Хочу это исправить.\n\n- Вкус демо: простой файл\n  ```\n  from litestar import Litestar, get\n\n  @get(\"/greet\")\n  async def greet(name: str) -> str:\n      return f\"Hi, {name}!\"\n\n  app = Litestar([greet])\n  ```\n  Запускаете через litestar run или любой ASGI‑сервер. /greet?name=Bob вернёт «Hi, Bob!». Без name — HTTP 400: параметр обязателен. Да, похоже на FastAPI и на знакомые по Spring/ASP.NET MVC подходы с аннотациями — и FastAPI тоже так умеет. Но у Litestar есть свои сильные стороны.\n\n- Про название: раньше проект назывался Starlite, потому что изначально строился на Starlette (как и FastAPI). Позже зависимость убрали, а чтобы не путать со Starlette, в релизе 2.0 (2023) переименовали в Litestar.\n\n- Масштабирование кода, а не трафика:\n  - Django плохо «масштабируется вниз»: «правильный» старт быстро разрастается в десяток файлов и папок. Однофайловые трюки работают, но против шерсти.\n  - Микрофреймворки — наоборот: стартуют в одном файле, но по мере роста кода расползаются и начинают мешать.\n  - В FastAPI маршруты обычно вешаются декораторами на объект приложения. Это удобно в одном файле, но при разбиении на модули ведёт к циклическим импортам. Решение — «вторичные» реестры маршрутов (APIRouter, blueprint): нужны, потому что декораторы привязаны к app. Litestar же позволяет описывать обработчики отдельно и передавать их приложению списком, что естественно масштабируется от одного файла к структуре проекта без костылей.",
      "commentsSummary": "- Обсуждение сравнивает FastAPI, Litestar, Starlette и Django для построения сложных бэкендов на Python; многие критикуют FastAPI за неудобство масштабирования структуры, зависимостей и слабую практическую документацию.  \n- Несколько участников хвалят Litestar: быстрее FastAPI, хорошо подходит для JSON и шаблонов HTML, поддерживает контроллеры, плагины (включая HTMX), события, а также развивается вместе с Advanced Alchemy; однако отмечают, что его документации не хватает “how-to” руководств.  \n- Часть разработчиков предпочитает минималистичный Starlette для небольших и крупных проектов, считая “микро”-подход и явную композицию более управляемыми, чем «все-в-одном» фреймворки.  \n- Обсуждается работа с БД: сравнивают SQLAlchemy и Django ORM; мнения разделены — SQLAlchemy мощнее, но сложнее и «с сюрпризами», Django ORM проще и сбалансированней; некоторые рекомендуют писать SQL вручную поверх моделей SQLAlchemy.  \n- Поднимаются архитектурные вопросы: разделение моделей API и БД с самого начала, репозитории/сервисные слои, spec-first подход (Connexion), обработка ошибок при стриминге, деплой (в т.ч. NGINX Unit).  \n- Есть отзывы о миграции с FastAPI на Litestar без сожалений, но также скепсис: не всем ясно, дает ли Litestar достаточно преимуществ над Starlette или Django для смены стека.  \n- Общий лейтмотив: популярность FastAPI не всегда коррелирует с удобством для больших кодовых баз; ценятся четкая структура, полноценная API-справка и предсказуемые инструменты для реальных проектов.",
      "score": 262,
      "commentsCount": 66,
      "hnUrl": "https://news.ycombinator.com/item?id=44816755",
      "domain": "b-list.org"
    },
    {
      "id": 44813854,
      "title": "Jules, our asynchronous coding agent",
      "url": "https://blog.google/technology/google-labs/jules-now-available/",
      "by": "meetpateltech",
      "timeISO": "2025-08-06T16:05:39.000Z",
      "postSummary": "Google представила Jules — асинхронного ИИ-агента для программирования — для всех пользователей, завершив публичную бету. Агент выполняет задачи в фоновом режиме: пишет и рефакторит код, правит баги, настраивает пайплайны и документирует изменения, не требуя постоянного участия разработчика. Это помогает параллелить работу, ускорять итерации и снижать контекстные переключения.\n\nJules интегрируется с инструментами разработчиков, может брать на себя длинные задачи, делить их на шаги, сообщать о прогрессе и запрашивать уточнения только при необходимости. Доступен через Google Labs и ориентирован на повышение продуктивности как отдельных инженеров, так и команд, позволяя запускать больше экспериментальных веток и быстрее проводить ревью.",
      "commentsSummary": "- Пользователи обсуждают запуск/состояние Google Jules (асинхронного кодового агента) и в целом запутанность подписок Google: разные продукты (Jules, Gemini App, Notebook, Gemini CLI, Code Assist) живут в несогласованных экосистемах Workspace vs GCP, цены и доступ спрятаны и завязаны на биллинг/термины.  \n- Опыт сильно разнится: часть хвалит удобство асинхронной работы (ставишь задачи в дороге, получаешь PR вечером; хорошо справляется с множеством мелких правок и тестами), другие называют качество кода слабым, нестабильным, с тупиками/лупами и плохим UI; многие считают Claude Code заметно лучше.  \n- Несоответствия: у некоторых Jules генерирует хуже, чем Gemini CLI/Claude при том же якобы модели; проблемы в монорепах, отсутствие STOP и тонкой обратной связи по PR-комментариям, частые сбои и «съедание» кредитов.  \n- Ограничения и политика: лимит задач на бесплатном плане уменьшили с 60 до 15; у Workspace и GCP разные продукты/ограничения, что вызывает конфуз и фрустрацию.  \n- Конкурентный ландшафт: сравнивают с Codex, Claude Code, Crush от Charm; часть считает изоляцию облачных ассистентов безопаснее локальной интеграции, но сомневаются в идее «дай ТЗ и уходи».  \n- Брендинг/нейминг критикуют за подростковость и схожесть с другими (Junie/«Jules»), шутят про частые переименования Google и ностальгируют по Ask Jeeves.  \n- Общий вывод: потенциал у формата «асинхронного код-агента» есть, но у Jules сейчас слабое качество кода, UX и интеграции; пользователи ждут консолидации линейки и прозрачной цены.",
      "score": 285,
      "commentsCount": 190,
      "hnUrl": "https://news.ycombinator.com/item?id=44813854",
      "domain": "blog.google"
    },
    {
      "id": 44813789,
      "title": "Writing a Rust GPU kernel driver: a brief introduction on how GPU drivers work",
      "url": "https://www.collabora.com/news-and-blog/blog/2025/08/06/writing-a-rust-gpu-kernel-driver-a-brief-introduction-on-how-gpu-drivers-work/",
      "by": "losgehts",
      "timeISO": "2025-08-06T16:00:54.000Z",
      "postSummary": "Это вторая часть серии о разработке Tyr — современного GPU‑драйвера на Rust для ядра Linux с поддержкой Arm Mali на CSF.\n\nРазберем, как работают GPU‑драйверы, на примере VkCube — простого приложения на Vulkan, рисующего вращающийся куб. Простота сцены помогает понять путь данных и команд от приложения к GPU.\n\nUMD и KMD\n- UMD (usermode) реализует API вроде Vulkan/OpenGL/OpenCL и преобразует команды приложений в низкоуровневые команды для GPU. В нашем случае это panvk из Mesa.\n- KMD (kernel mode) соединяет UMD с железом: инициализирует устройство, управляет памятью, очередями, планированием и уведомлениями. В нашем случае это Tyr, нацеленный попасть в основное дерево Linux.\n\nЧто делает UMD\n- Подготавливает данные: геометрию, текстуры, машинный код шейдеров, матрицы трансформаций.\n- Просит KMD разместить их в памяти GPU, создает VkCommandBuffer с командами отрисовки, настраивает состояние конвейера, указывает, куда писать результат, и как получать сигнал о завершении.\n\nПро шейдеры\n- Это полноценные программы на GPU. Для VkCube им нужны хотя бы геометрия, цвета и матрица вращения, чтобы расположить и раскрасить куб и крутить его.\n\nЧто делает KMD\n- Выделяет и отображает память, изолируя процессы в отдельных контекстах/VM.\n- Принимает работу от UMD, ставит в аппаратные очереди, отслеживает зависимости и завершение.\n- Планирует выполнение на массово параллельном, асинхронном железе, соблюдая порядок и справедливое распределение ресурса между клиентами.\n- Инициализирует устройство: тактирование, питание, стартовые процедуры; обеспечивает совместный и честный доступ приложений к GPU.\n\nКлючевой вывод\n- Основная сложность — в UMD, который переводит высокоуровневые API в команды GPU. Но KMD обязан предоставить надежные примитивы: память, очереди, синхронизацию, планирование и разделение ресурсов, чтобы UMD было реально реализовать.\n\nИнтерфейс драйвера\n- На основе этих задач KMD экспонирует минимальный набор операций: запрос сведений об устройстве, создание/уничтожение VM, привязка/отвязка памяти к VM, получение состояния VM, отправка работ в очереди и механизмы уведомлений — тот же API, что у C‑драйвера Panthor для того же железа.",
      "commentsSummary": "- Участники хвалят статью, но считают её слишком короткой и ждут продолжения и следующих частей.  \n- Обсуждают, что речь идёт о драйвере panthor для ARM Mali CSF, соответствующем ожиданиям userspace/Mesa, а не о panfrost; отмечена путаница с RK3588.  \n- Поднимается вопрос, стоило ли использовать io_uring/uring_cmd вместо ioctl; мнения сходятся, что выгода мала, так как GPU уже асинхронны и ioctl в основном лишь пишет команды в очередь.  \n- Некоторые критикуют акцент на «Rust GPU driver» как кликбейт, но другие подчёркивают значимость того, что это один из первых GPU-драйверов Linux на Rust.  \n- Обсуждение технического уровня: текущая часть описывает границу user/kernel, очереди и буферы; «экшен» ожидается при разборе выполнения команд GPU в следующих частях.  \n- Пользователи делятся багами в реальном использовании (черные/прозрачные патчи в Firefox), хотя им указывают на неверную привязку к другому драйверу.  \n- Тон местами спорный: напоминают о сложности современных GPU-драйверов и огромном объёме кода в ядре.",
      "score": 258,
      "commentsCount": 32,
      "hnUrl": "https://news.ycombinator.com/item?id=44813789",
      "domain": "collabora.com"
    },
    {
      "id": 44816692,
      "title": "We'd be better off with 9-bit bytes",
      "url": "https://pavpanchekha.com/blog/9bit.html",
      "by": "luu",
      "timeISO": "2025-08-06T19:39:20.000Z",
      "postSummary": "- В 70‑х некоторые системы (например, PDP‑10) имели 9‑битовые байты, но стандарт закрепился за 8 битами. Если бы байт был 9‑битным, ряд исторических случайностей сыграли бы нам на руку.\n\n- IPv4: при 9‑битовых байтах адрес IPv4 был бы 36‑битным (~64 млрд адресов). Этого хватило бы до 2030‑х без массового NAT и тормозов с IPv6; позже проблему решили бы мягкими рыночными механизмами.\n\n- UNIX time: 32‑битные метки ломаются в 2038, а 36‑битные прожили бы до 3058. Отрицательные охватывали бы времена с 882 года — достаточно для исторических нужд.\n\n- Юникод: вместо 16‑битных 65 тыс. символов было бы 18‑битных 262 тыс. — хватило бы без болезненной унификации CJK; сейчас всех символов ~155 тыс. UTF‑9 стал бы скорее компрессией и уступил бы GZip; либо однобайтно‑двухбайтная схема при умеренной экономии на эмодзи.\n\n- Указатели и память: 36‑битные ОС дали бы до 32 ГБ на процесс (вместо 2 ГБ у 32‑битных). Серверы всё равно виртуализируют; меньшие указатели экономят память и ускоряют код, хотя строки стали бы длиннее — общий баланс близок к нулю.\n\n- Прочие выигрыши:\n  - 18‑битные AS‑номера не иссякли бы; порты/PID/UID просторнее.\n  - Кодирование инструкций x86/A64 чуть опрятнее; Thumb работал бы лучше.\n  - Полуточные 18‑битные числа прижились бы раньше; экзотика 4–5 бит не взлетела бы.\n  - Расширенный ASCII влез бы с греческим и стал бы «натовской» кодовой страницей; UTF‑9 привилегировал бы почти всю Западную Европу.\n  - Права Unix умещались бы в один байт (без «липких» битов). Оctal стал бы нормой вместо hex.\n  - 18‑битный цвет 6/6/6 даёт различия на грани восприятия; потеря альфа‑канала неприятна.\n\n- Издержки? Существенных нет: адресация по битам не используется; деления на девять не требуется; размеры страниц/блоков ОС могли бы остаться прежними, ядру не пришлось бы менять основы работы.",
      "commentsSummary": "- Обсуждение крутится вокруг гипотезы: что было бы, если байт состоял из 9 бит, и помогло бы это избежать исторических “узких мест” вроде 8/32-битных границ, IPv4 и кодировок символов.  \n- Критики указывают, что 9-битные единицы неудобны для железа: схемы деления/умножения и адресации любят степени двойки; добавочный 12.5% бит часто не даёт реальной выгоды, но удорожает память и логические блоки.  \n- Многие отмечают, что “чуть больше пространства” не решает корневую проблему неверных прогнозов размеров; при 9 бит мы всё равно выбрали бы неправильные пороги, только другие.  \n- Идеи в поддержку: 9-й бит для варинтов (продолжение числа/инструкции), отдельного бита для ECC/контроля, редкие реальные примеры (например, 9-й бит в памяти N64 для GPU).  \n- Контраргументы по сетям: с 9-битными байтами IPv4 мог бы быть 36-битным, но исчерпание всё равно пришло бы, а альтернативные размеры (27 бит) сделали бы хуже; переходы вроде IPv6 вряд ли зависят от размера байта.  \n- Исторические примеры показывают разнообразие: 6-битные коды, 12/36-битные слова, “октет” для однозначности 8 бит; выбор степени двойки оказался практичнее.  \n- Общий вывод большинства: 9-битные байты дали бы сомнительную выгоду и дополнительные издержки; важнее правильно оценивать масштабы и проектировать системы гибко, чем «прибавлять один бит».",
      "score": 143,
      "commentsCount": 258,
      "hnUrl": "https://news.ycombinator.com/item?id=44816692",
      "domain": "pavpanchekha.com"
    },
    {
      "id": 44821869,
      "title": "OpenAI's new GPT-5 models announced early by GitHub",
      "url": "https://www.theverge.com/news/752091/openai-gpt-5-model-announcement-github-leak",
      "by": "bkolobara",
      "timeISO": "2025-08-07T08:06:48.000Z",
      "postSummary": "GitHub преждевременно раскрыл новые модели OpenAI GPT-5.",
      "commentsSummary": "- Утечка страницы с анонсом GPT-5 выглядит сдержанной: акцент на «улучшенном рассуждении», без громких заявлений об AGI; многие ждут официального анонса.  \n- Пользователи заметили, что промо-изображение похоже на отредактированный скриншот с GitHub Models (с заменой id модели), и привели ссылку на архив удалённой записи GitHub.  \n- На изображении сравнение проводится с Llama 4 и Cohere v2, что вызвало вопросы о корректности/маркетинговости сравнения.  \n- Мнения разделились: одни ожидают хайп, но сомневаются, что новая модель обгонит конкурентов вроде Opus 4.1; другие рады появлению новой версии и считают, что использовать её — личный выбор.  \n- В треде есть ироничные и резкие комментарии, отражающие усталость от «непросимого» прогресса и напряжённость в обсуждении.",
      "score": 22,
      "commentsCount": 10,
      "hnUrl": "https://news.ycombinator.com/item?id=44821869",
      "domain": "theverge.com"
    },
    {
      "id": 44815702,
      "title": "A fast, growable array with stable pointers in C",
      "url": "https://danielchasehooper.com/posts/segment_array/",
      "by": "ibobev",
      "timeISO": "2025-08-06T18:21:28.000Z",
      "postSummary": "Моя предыдущая статья о обобщённых структурах данных в C готовила почву к теме: структура, которая заменяет динамические массивы, даёт стабильные указатели и хорошо работает с аренными аллокаторами. Её переоткрывали много раз под разными именами: “levelwise-allocated pile” (2001), в Zig — Segmented List, частично похожая на C++ std::deque. Мне нравится название Per Vognsen — Segment Array.\n\nСкачать мой однофайловый заголовок segment_array.h можно, подписавшись на рассылку.\n\nИдея проста: фиксированный массив указателей на сегменты; каждый следующий сегмент вдвое больше предыдущего; новые сегменты выделяются по мере необходимости. Поскольку элементы не двигаются, указатели на них стабильны, не остаются “дыры” в арене, а доступ по индексу — за O(1).\n\nРеализация\n\nСтруктура на C:\n\ntypedef struct {\n    u32 count;\n    int used_segments;\n    u8 *segments[26];\n} SegmentArrayInternal;\n\nПочему всего 26 сегментов? Из 64 бит указателя обычно реально используются 48, так что 49 сегментов уже перекрывают адресное пространство (~256 ТиБ). Я предпочитаю индекс u32 (до ~4 млрд элементов) — это даёт 32 сегмента. Ещё убираем 6 маленьких (1..32), начинаем с 64, остаётся 26 сегментов — хватает для 4 294 967 232 элементов (чуть меньше UINT32_MAX). Фиксированный массив рядом со структурой снижает риск промаха кэша.\n\nРазмеры сегментов — степени двойки: проще математика и быстрые сдвиги для индексов.\n\n#define SMALL_SEGMENTS_TO_SKIP 6\n\n#define log2i(X) ((u32) (8*sizeof(unsigned long long) \\\n    - __builtin_clzll((X)) - 1))\n\nu32 capacity_for_segment_count(int segment_count) {\n    return ((1 << SMALL_SEGMENTS_TO_SKIP) << segment_count)\n        - (1 << SMALL_SEGMENTS_TO_SKIP);\n}\n\nvoid *_sa_get(SegmentArrayInternal *sa, u32 index, size_t item_size) {\n    int segment = log2i((index >> SMALL_SEGMENTS_TO_SKIP) + 1);\n    u32 slot = index - capacity_for_segment_count(segment);\n    return sa->segments[segment] + item_size*slot;\n}\n\nlog2i использует __builtin_clzll (подсчёт ведущих нулей) для быстрого вычисления номера сегмента.\n\nClang оптимизирует _sa_get до ~10 инструкций x86-64 (-O3), так что узким местом будет память, а не вычисления индекса. При последовательной итерации можно обходить сегменты напрямую; в segment_array.h есть макрос.\n\nВыделение нового элемента:\n\nu32 slots_in_segment(int segment_index) {\n    return (1 << SMALL_SEGMENTS_TO_SKIP) << segment_index;\n}\n\nvoid *_sa_alloc(SegmentArrayInternal *sa, size_t item_size) {\n    if (sa->count >= capacity_for_segment_count(sa->used_segments)) {\n        size_t segment_size = item_size * slots_in_segment(sa->used_segments);\n        sa->segments[sa->used_segments++] = malloc(segment_size);\n    }\n    sa->count++;\n    return _sa_get(sa, sa->count-1, item_size);\n}\n\nЗамечание: можно сделать ёмкость строго степенью двойки, если первые два сегмента одинакового размера. Код станет менее изящным, но это спасает от ~50% потерь памяти при использовании как массива бакетов в хеш-таблице со степенью двойки.\n\nДженерики\n\nЯ применяю технику из прошлой статьи для типобезопасного хранения любого типа. Макрос связывает тип с общей структурой:\n\n#define SegmentArray(type) \\\n    union { \\\n        SegmentArrayInternal internal; \\\n        type *payload; \\\n    }\n\nДальше макросы используют payload, чтобы передавать сведения о типе…",
      "commentsSummary": "- Обсуждаемая структура данных — сегментированный «массив» с экспоненциально растущими сегментами; многие отмечают, что корректнее называть его списком/деками, так как нет сплошной памяти и привычной семантики массива.  \n- Сравнения: упоминаются std::deque (фиксированные блоки, поддержка prepend), rope (сбалансированное дерево с O(log n) вставками/удалениями), Zig std.SegmentedList, plf::colony, rust-array-stump; мнения расходятся, насколько это «вариант deque».  \n- Плюсы и производительность: быстрый доступ с небольшой ценой вычисления индекса; однако в горячих циклах накладные инструкции могут быть заметны в L1, а непредсказуемость адресов ухудшает кэш-предвыборку при последовательной итерации.  \n- Виртуальная память как альтернатива: резерв больших диапазонов и поэтапная коммит/популяция страниц (mmap/MAP_POPULATE, mremap) обеспечивает истинную непрерывность и стабильные указатели, но не подходит для встраиваемых/wasm.  \n- Недостатки: отсутствие непрерывности и стабильных API для срезов, невозможность прозрачной передачи как C-массива, потенциальный оверхед макросов/typeof (C23), фрагментация/пустое пространство при экспоненциальных сегментах.  \n- Вопросы дизайна: когда лучше экспоненциальный размер сегментов, нужен ли минимум/слияние мелких сегментов, и насколько велик реальный перерасход памяти; для больших объемов это «почти непрерывно», но не для всех алгоритмов.  \n- Практика: std::deque имеет разные реализации и ограничения (напр. в MSVC), важно понимать детали контейнера; код примера у некоторых не компилируется; терминология clz/BSR/LZCNT уточняется.",
      "score": 181,
      "commentsCount": 68,
      "hnUrl": "https://news.ycombinator.com/item?id=44815702",
      "domain": "danielchasehooper.com"
    },
    {
      "id": 44787073,
      "title": "Scientists just recreated the Universe's first molecule",
      "url": "https://www.sciencedaily.com/releases/2025/08/250803011840.htm",
      "by": "LAsteNERD",
      "timeISO": "2025-08-04T15:20:51.000Z",
      "postSummary": "- Исследователи воссоздали первое молекулярное соединение во Вселенной — ион гелий-гидрида (HeH⁺) — в ультрахолодной установке, смоделировав условия более чем 13 млрд лет назад. Выяснилось, что эта молекула гораздо эффективнее, чем считалось, охлаждала раннюю космическую среду, помогая газовым облакам коллапсировать и запускать рождение первых звезд.\n\n- После рекомбинации и наступления «темных веков» дальнейшее охлаждение стало возможным главным образом за счет молекул, способных излучать энергию через вращательные и колебательные переходы. Благодаря выраженному дипольному моменту HeH⁺ особенно эффективен при низких температурах, а его концентрация могла существенно влиять на скорость раннего звездообразования.\n\n- Ключевой путь разрушения HeH⁺ в ту эпоху — столкновения со свободными атомами водорода, образующие нейтральный гелий и ион H2⁺; тот далее реагирует с H, давая молекулярный водород H2 и протон. В эксперименте MPIK исследовали аналогичную реакцию с дейтерием: HeH⁺ + D → He + HD⁺, воспроизводя условия ранней Вселенной.\n\n- Измерения в криогенном кольце хранения (CSR, MPIK, Гейдельберг) показали, что реакция быстрая и протекает без энергетического барьера — вопреки прежним теоретическим ожиданиям. Это пересматривает модели химии ранней Вселенной и механизм охлаждения газа, уточняя путь от «темноты» к зажиганию первых звезд.",
      "commentsSummary": "- Вопрос: существует ли гелиевый гидрид (HeH+) в природе сейчас и почему его «пришлось» воссоздавать.  \n- Ответы: это один из самых ранних соединений во Вселенной; он образовался вскоре после Большого взрыва.  \n- На Земле в значимых количествах не встречается: молекула чрезвычайно реакционноспособна и распадается/протонирует почти всё, с чем сталкивается.  \n- В природе сегодня HeH+ встречается в основном в межзвёздной среде, где условия разрежены и холодны.  \n- Новизна упомянутого эксперимента не в «впервые созданном» HeH+: его изучают в лабораториях уже около века.  \n- Инновация в конкретной работе — измерение скоростей реакций (в т.ч. с дейтерием) при сверхнизких температурах в условиях, имитирующих космос (CSR в Гейдельберге), что важно для моделей ранней Вселенной.",
      "score": 8,
      "commentsCount": 5,
      "hnUrl": "https://news.ycombinator.com/item?id=44787073",
      "domain": "sciencedaily.com"
    },
    {
      "id": 44817583,
      "title": "The Bluesky Dictionary",
      "url": "https://www.avibagla.com/blueskydictionary/",
      "by": "gaws",
      "timeISO": "2025-08-06T20:43:08.000Z",
      "postSummary": "- время — 4732 использ.; последнее появл. 08/07/2025 08:49\n- для — 4751; последнее 08/07/2025 08:49\n- медитация — 509; последнее 08/07/2025 08:49\n- неделя — 4017; последнее 08/07/2025 08:49\n- война — 3974; последнее 08/07/2025 08:49\n- трамп — 4711; последнее 08/07/2025 08:49\n- ии — 4565; последнее 08/07/2025 08:49\n- после — 4649; последнее 08/07/2025 08:49\n- просто — 4748; последнее 08/07/2025 08:49\n- последний — 4454; последнее 08/07/2025 08:49\n- как — 4747; последнее 08/07/2025 08:49\n- который — 4514; последнее 08/07/2025 08:49\n- о — 4745; последнее 08/07/2025 08:49\n- the — 4757; последнее 08/07/2025 08:49\n- торговля — 2083; последнее 08/07/2025 08:49\n- эффект — 1653; последнее 08/07/2025 08:49\n- президент — 3584; последнее 08/07/2025 08:49\n- тарифы — 2665; последнее 08/07/2025 08:49\n- io — 2480; последнее 08/07/2025 08:49\n- расширяется — 95; последнее 08/07/2025 08:49\n- пошлины — 639; последнее 08/07/2025 08:49\n- полночь — 1772; последнее 08/07/2025 08:49\n- ошеломляющий — 439; последнее 08/07/2025 08:49\n- страны — 4866; последнее 08/07/2025 08:49\n- взяли — 8866; последнее 08/07/2025 08:49\n- начать — 2796; последнее 08/07/2025 08:49\n- объявил — 3688; последнее 08/07/2025 08:49\n- мужчина — 4577; последнее 08/07/2025 08:49\n- снег — 958; последнее 08/07/2025 08:49\n- анан — 76; последнее 08/07/2025 08:49\n- снеговик — 202; последнее 08/07/2025 08:49\n- развлечения — 3310; последнее 08/07/2025 08:49\n- ich — 3267; последнее 08/07/2025 08:49\n- die — 4390; последнее 08/07/2025 08:49\n- mein — 2276; последнее 08/07/2025 08:49\n- мастурбация — 712; последнее 08/07/2025 08:49\n- sind — 5177; последнее 08/07/2025 08:49\n- сила — 3583; последнее 08/07/2025 08:49\n- сам — 2763; последнее 08/07/2025 08:49\n- друзья — 3607; последнее 08/07/2025 08:49\n- гигант — 1239; последнее 08/07/2025 08:49\n- вместе — 3278; последнее 08/07/2025 08:49\n- месяцы — 2845; последнее 08/07/2025 08:49\n- вещи — 4425; последнее 08/07/2025 08:49\n- смотреть — 4485; последнее 08/07/2025 08:49\n- демократия — 2165; последнее 08/07/2025 08:49\n- однажды — 3766; последнее 08/07/2025 08:49\n- те — 4467; последнее 08/07/2025 08:49\n- что-либо — 4208; последнее 08/07/2025 08:49\n- делаю — 4378; последнее 08/07/2025 08:49",
      "commentsSummary": "- Обсуждают сайт, который сканирует посты Bluesky и отмечает слова из словаря, впервые встреченные в ленте; многих удивило, что среди «невиданных» есть вполне обычные слова.  \n- Возникают вопросы точности: случаи с омонимами (французский пост с «mouch», группа «Eluvium») и ложные классификации; также шутки и смешные названия.  \n- Техническая сторона: автор подтвердил, что использует Jetstream, SQLite и простые таблицы со статистикой; обработка ~4.9 млн постов (около 0.28% от ~1.7 млрд).  \n- Пользователи обсуждают инфраструктуру Bluesky: доступность firehose/jetstream, пропускную способность и как платформа тянет полный стрим.  \n- Делятся советами по реализации: хэш-таблицы/хэш-сеты для слов, трипы (tries) как компромисс по памяти, токенизация как главный CPU-узкий участок; объёмы памяти оцениваются как небольшие (порядка десятков МБ).  \n- Отмечены проблемы у некоторых: нули в счётчиках из‑за блокировки скриптов, задержка загрузки, предположение о необходимости аккаунта (на деле не требуется).  \n- Общий тон — любопытство и одобрение дизайна, наряду с размышлениями о тренде к закрытым API и границах допустимого использования постов для NLP/LLM.",
      "score": 154,
      "commentsCount": 48,
      "hnUrl": "https://news.ycombinator.com/item?id=44817583",
      "domain": "avibagla.com"
    },
    {
      "id": 44819962,
      "title": "Mac history echoes in current Mac operating systems",
      "url": "http://tenfourfox.blogspot.com/2025/08/mac-history-echoes-in-mac-operating.html",
      "by": "classichasclass",
      "timeISO": "2025-08-07T02:27:51.000Z",
      "postSummary": "Ars Technica отметила, что в macOS Tahoe старые значки жёстких дисков заменяют более общими и скучными. Если вы на Sequoia и хотите сохранить их, возьмите из:\n/System/Library/Extensions/IOStorageFamily.kext/Contents/Resources\nТекст на этикетке проработан, и даже винты Torx. Достаньте T8 MacCracker для этого диска:\n\n[Изображение 1]\n\nВ системе сохранились и другие отголоски прошлого. The Spacebar заметил, что в шрифте Apple Symbols до сих пор есть старые, «устаревшие» пиктограммы, полезные разве что пользователям Power Mac в веб-браузерах.\n\n[Изображение 2]\n\nИ это ещё не всё: в файле больше значков, чем он показал. Вот что я нашёл — возможно, обнаружите больше.\n\n[Изображение 3]\n\nПо порядку: логотип PowerPC; композитный видео‑выход/вход; S‑Video выход/вход (как на поздних PowerBook); модемный порт; совмещённый модем/принтер (Duo 2300); принтер; SCSI; Ethernet/AAUI; три глифа ADB; сервер; контурное радужное яблоко; Balloon Help (System 7); Apple Guide (7.5); дискетa 5,25\" (скорее для Apple II); две лампочки Newton; undo, extras, dates, names Newton; дискета 3,5\" HD; «растерянный» компактный Mac (намёк на мигающий вопрос при отсутствии загрузочного тома); классический логотип QuickTime; «часы занятости»; порт Apple Pro Speakers (iMac G4, MDD G4); FireWire; значок программистской клавиши; две версии reset (для них есть аналоги в Unicode или геометрические фигуры; иногда были отражены).\n\nПримечание: большинство этих символов не привязаны к кодовым точкам Unicode; это отдельные глифы. Font Book их покажет, но копировать нельзя. Ultra Character Map позволит взять графику и вставить, как я сделал здесь.\n\nИ это ещё не всё. Загляните в /System/Library/CoreServices/CoreTypes.bundle/Contents/Resources — там тоже клад. Особенно впечатляют «мульти‑размеры» для разных экранов; ниже — 1024×1024 144 dpi Retina из Sequoia.\n\n[Изображение 4] eMac,\n\n[Изображение 5]\n\n[Изображение 6]",
      "commentsSummary": "- Обсуждают, почему в macOS до сих пор остаются старые иконки/ассеты устройств: они используются Finder для сетевых томов и определяются через Bonjour (_device-info._tcp) или настройки серверов (например, Samba vfs_fruit с fruit:model).  \n- Многие видели, как NAS/AFP/SMB-сервера отображаются как Xserve, «CRT с BSOD» для Windows-шар, и другие ретро-иконки; Synology/QNAP иногда «маскируются» под Xserve.  \n- Похожая «кладезь» старых ассетов есть и в Windows (старые иконки/проги остаются ради совместимости и минимизации рисков), поэтому их сохранение — дешевле, чем чистить.  \n- Упоминают, что ряд неосязаемых «эхов истории» живёт и в UX: Return/Enter — переименование, Cmd-O — открытие; критикуют давние проблемы управления окнами.  \n- Замечают артефакты эпох NeXT/Platinum: старые виджеты и иконки всё ещё прячутся в assets.car; есть примеры хаков, заставляющих систему использовать эти стили.  \n- Ностальгия по дизайну Apple прошлых лет; разочарование «однообразием» современных MacBook/iPhone.  \n- Мелкие уточнения: iPhone 3G/3GS — после оригинального «iPhone» (без «2G» в названии); стандартные иконки дисков пропали в Tahoe beta; часть иконок также фигурирует в «Об этом Mac».",
      "score": 112,
      "commentsCount": 33,
      "hnUrl": "https://news.ycombinator.com/item?id=44819962",
      "domain": "tenfourfox.blogspot.com"
    },
    {
      "id": 44788997,
      "title": "SQLite offline sync for Android quick start",
      "url": "https://github.com/sqliteai/sqlite-sync/tree/main/examples/android-integration",
      "by": "marcobambini",
      "timeISO": "2025-08-04T17:34:19.000Z",
      "commentsSummary": "- Пользователь mjadobson заметил сходство API с cr-sqlite и спросил о возможной связи; автор пояснил, что сходство из-за общей научной основы (ссылка на статью), а не из-за кода cr-sqlite.  \n- anty спросил о поддержке внешних ключей/UNIQUE и о реализации приватности на уровне строк; автор ответил, что подробности по ограничениям скоро добавят, а row-level security реализована (запрещённые строки не синхронизируются, шифрование — TLS).  \n- Обсуждалась лицензия: проект использует Elastic License 2 для защиты инвестиций и предотвращения коммерческой эксплуатации крупными компаниями.  \n- Были замечания о «не open source»; автор уточнил, что код открыт и дал ссылку на репозиторий sqlite-sync.  \n- Возникла тревога насчёт возможного нарушения торговой марки SQLite; автор заявил, что проект поддержан Ричардом Хиппом и имеет право использовать имя SQLite, предложено прояснить это в README.  \n- Сообщество отметило альтернативы (например, LiteSync) и поздравило с запуском.",
      "score": 28,
      "commentsCount": 17,
      "hnUrl": "https://news.ycombinator.com/item?id=44788997",
      "domain": "github.com"
    },
    {
      "id": 44782229,
      "title": "What is the average length of a queue of cars? (2023)",
      "url": "https://e-dorigatti.github.io/math/2023/11/01/queue-length.html",
      "by": "alexmolas",
      "timeISO": "2025-08-04T04:55:11.000Z",
      "postSummary": "Некоторое время назад я ехал по извилистой горной дороге и застрял в медленной очереди машин — обгонять было небезопасно. От скуки я задумался: сколько машин в такой очереди и какова средняя длина очередей на этой дороге?\n\nСформализуем задачу. Дорога одна, без съездов, бесконечной длины. Каждая машина при въезде имеет свою среднюю скорость. Быстрые догоняют медленных и, не имея возможности обгона, выстраиваются за ними. Со временем возникает «стационарное» состояние: формируются группы машин, движущиеся со скоростью самого медленного спереди. Вопрос: какова средняя длина таких групп?\n\nИнтуитивный (но неверный) подход\n--------------------------------\nПусть скорости v_i i.i.d. Очередь образуется, если v_2 ≤ v_1, и v_3 ≤ v_1, и т. д. Каждое сравнение, по симметрии распределения (достаточно обменности), имеет вероятность 1/2. Тогда P{длина ≥ k} = (1/2)^(k-1), а матожидание длины равно 2. То же самое можно увидеть, считая длину геометрической с параметром 1/2. Но это не совпадает с ощущениями.\n\nСимуляция\n---------\nЯ написал симуляцию и получил иные результаты.\n\n- Скорости берутся из равномерного распределения на [0,1].\n- В 100 000 прогонах растим очередь, пока новая машина не медленнее «эталонной» v0 (первой в очереди): пока v_i ≥ v0, добавляем машину; иначе очередь заканчивается.\n- Результат:\n  - средняя длина ≈ 10.69,\n  - медиана = 2, квартиль 75% = 4,\n  - максимум наблюдался 22 849,\n  - распределение хвостатее, чем геометрическое с p=1/2; предсказанная геометрией вероятность длинных очередей убывает слишком быстро.\n\nКорректное решение\n------------------\nИнтуитивная причина ошибки: выбор очереди «смещён». Если видим длинную очередь, то ведущая машина почти наверняка очень медленная; условие «v0 маленькая» резко повышает шансы, что последующие v_i окажутся ≥ v0, удлиняя хвост распределения. Нельзя просто умножить независимые вероятности сравнения без учёта того, что v0 в длинных очередях не типична. Нужно условное распределение длины по v0 и затем усреднение по плотности v0, взвешенной вероятностью породить длинную очередь. Именно этот эффект отбора даёт тяжёлый хвост и среднюю длину существенно больше 2.",
      "commentsSummary": "- Обсуждение касается неверной интерпретации формулы в блоге: приведённая сумма 1 + 1/2 + 1/3 + ... описывает ожидаемое число колонн (очередей) машин, а не что-то иное.  \n- Аргумент: первая машина всегда начинает колонну; вторая начинает колонну с вероятностью 1/2 (если медленнее первой); третья — с вероятностью 1/3 (если самая медленная из первых трёх), и так далее.  \n- Таким образом, ожидание числа колонн равно гармонической сумме по числу машин.  \n- Отмечена шутливая критика допущений модели: «дорога с одним въездом, без выездов и бесконечной длины» — не хватает предположения об «неупругости» и «отсутствии массы» дороги.  \n- Ещё одна ироничная реплика продолжает научно-шуточный тон: «сферические машины тоже?» (намёк на упрощающие физические модели).",
      "score": 18,
      "commentsCount": 4,
      "hnUrl": "https://news.ycombinator.com/item?id=44782229",
      "domain": "e-dorigatti.github.io"
    },
    {
      "id": 44820341,
      "title": "Show HN: Rust framework for advanced file recognition and identification",
      "url": "https://crates.io/crates/magical_rs",
      "by": "reimisdev",
      "timeISO": "2025-08-07T03:38:18.000Z",
      "postSummary": "- Rust-фреймворк для распознавания файлов с высокой расширяемостью и кастомизацией.\n\nУровни использования\n\n- Уровень 1: встроенное определение по сигнатурам (~50 типов).\n  - Используйте API `magical_rs`, список поддерживаемых форматов см. по ссылке в репо.\n  - Можно вносить новые сигнатуры через PR.\n  - Пример:\n    ```\n    use magical_rs::magical::bytes_read::{read_file_header, with_bytes_read};\n    use magical_rs::magical::magic::FileKind;\n\n    let max_byte_read = with_bytes_read();\n    let bytes = read_file_header(\"img/2.iso\", max_byte_read).unwrap();\n\n    match FileKind::match_types(&bytes) {\n        Some(k) => println!(\"{k:?}\"),\n        None => println!(\"Could not detect ISO file.\"),\n    }\n    ```\n  - Больше примеров в examples/dyn_magic.\n  - Поддерживает no_std.\n\n- Уровень 2: безграничная компиляционная кастомизация с функциями-указателями.\n  - Кастомные сигнатуры, смещения, сложная логика через указатели на функции и макросы.\n  - Позволяет детектировать любые типы на этапе компиляции.\n  - Пример:\n    ```\n    use magical_rs::{any_matches, magic_custom, match_custom};\n\n    #[derive(Clone, Copy, PartialEq, Eq, Debug)]\n    enum FileKind { Shoujo, UnknownFallback }\n\n    fn is_shoujo(bytes: &[u8]) -> bool { bytes.starts_with(b\"Magic!\") }\n    fn is_not_shoujo(bytes: &[u8]) -> bool { !bytes.starts_with(b\"Magic!\") }\n\n    pub fn magic_custom_any() {\n        let rule = magic_custom!(\n            signatures: [],\n            offsets: [0],\n            max_bytes_read: 2451,\n            kind: FileKind::Shoujo,\n            rules: any_matches!(is_shoujo, is_not_shoujo)\n        );\n\n        let result = match_custom!(\n            bytes: b\"Magic!\",\n            rules: [rule],\n            fallback: FileKind::UnknownFallback\n        );\n\n        assert_eq!(result, FileKind::Shoujo);\n    }\n    ```\n  - Варианты реализации в examples/magic_custom.\n  - Поддерживает no_std.\n\n- Уровень 3: произвольная логика во время выполнения.\n  - Полная свобода: любые проверки, ИИ, сетевые запросы, процессы и т.д.\n  - Включение: `cargo add magical_rs --features magical_dyn`\n  - Пример:\n    ```\n    use magical_rs::magical::dyn_magic::DynMagicCustom;\n\n    fn my_detect_rule() -> impl Fn(&[u8]) -> bool {\n        let require_bytes = b\"MagicalGirl\";\n        |bytes: &[u8]| bytes.starts_with(require_bytes) && bytes.len() == require_bytes.len()\n    }\n\n    fn detect_custom_file(file_bytes: &'static [u8]) -> bool {\n        let detect_fn = my_detect_rule();\n        let rule = DynMagicCustom::new(detect_fn, String::from(\"Is Mahou Shoujo Detect.\"), 32);\n\n        let kind = rule.kind_downcast_ref::<String>();\n        match kind {\n            Some(k) => println!(\"{k}\"),\n            None => println!(\"Kind not found.\"),\n        }\n        rule.matches(file_bytes)\n    }\n    ```\n  - Примеры в examples/dyn_magic.\n  - Предупреждение: использовать, только если понимаете последствия.\n\n- Уровень 4: асинхронные правила без ограничений.\n  - Проектирование правил в async-среде любой сложности. Используйте, только если действительно нужно и хватает опыта.\n  - Включение: `cargo add magical_rs --features magical_async_dyn`\n  - Пример (фрагмент):\n    ```\n    use async_std::task;\n    use magical_rs::magical::async_dyn_magic::AsyncDynMagic;\n    use magical_rs::magical::async_dyn_magic::match_dyn_types_as;\n    use std::time::Duration;\n\n    async fn magic_async_detect() {\n        let func_detect = |bytes: &[u8]| {\n            let owned_bytes = bytes.to_vec();\n            Box::pin(async move {\n                println!(\"Rest for 1 second\");\n                task::sleep(Duration::from_millis(1000)).await;\n                owned_bytes.starts_with(b\"Magical\")\n            })\n        };\n    }\n    ```",
      "commentsSummary": "- Один из участников отметил, что самореклама вроде «один из лучших фреймворков» выглядит отталкивающе и предложил сразу переходить к сути и преимуществам.  \n- Другой участник спросил, чем проект отличается от crates вроде theseus-rs/file-type в синхронном std-контексте, если не важна зависимость.  \n- Автор согласился с критикой формулировки и пообещал её исправить.  \n- Автор пояснил дифференциацию: file-type — лёгкий, статичный детектор; magical_rs — более «фреймворк», поддерживает пользовательские правила, DSL-логику и встраивание кастомных функций.  \n- Вывод: magical_rs уместен для сложных форматов, edge-case’ов и внутреннего туллинга с глубоким контролем, тогда как file-type подходит для простого и лёгкого определения типов.",
      "score": 30,
      "commentsCount": 4,
      "hnUrl": "https://news.ycombinator.com/item?id=44820341",
      "domain": "crates.io"
    },
    {
      "id": 44814596,
      "title": "Multics",
      "url": "https://www.multicians.org/multics.html",
      "by": "unleaded",
      "timeISO": "2025-08-06T16:57:55.000Z",
      "postSummary": "- Логотип Multics\n\n- Домой\n  - История »\n    - Возможности\n    - Мифы\n    - Project MAC\n    - Даты\n    - Глоссарий\n    - Проект истории\n    - Последний сайт\n  - Люди »\n    - Истории\n    - Фотографии\n    - Юмор\n    - Памятные вещи\n  - Библиотека »\n    - Статьи и доклады\n    - Технические статьи\n    - Документы разработки\n    - Исходники\n    - Симулятор\n  - Сайты »\n    - Хронология площадок\n    - AFDSC (Пентагон, Вашингтон)\n    - ASEA (Вестерос, Швеция)\n    - Avon (Бристоль, Англия)\n    - Bell Canada (2 площадки)\n    - CISL (Кембридж, Массачусетс)\n    - CNO (Миннеаполис, Миннесота)\n    - DND-H (Галифакс, Канада)\n    - DOCKMASTER (АНБ, Мэриленд)\n    - FORD (Детройт, Мичиган)\n    - GM (Детройт, Мичиган)\n    - Майнц (Германия)\n    - MIT (Кембридж, Массачусетс)\n    - NWGS (ВМС США, 4 площадки)\n    - OU (Рочестер, Мичиган)\n    - PRHA (Сан-Хуан, Пуэрто-Рико)\n    - RADC (Рим, Нью-Йорк)\n    - RAE (Фарнборо, Англия)\n    - STC (Лондон, Англия)\n    - System-M (Финикс, Аризона)\n    - Systeme X (Лувесьен, Франция)\n    - UC/ACTC (Калгари, Канада)\n    - USGS (3 площадки)\n    - USL (Лафайет, Луизиана)\n    - VPI (Блэксберг, Вирджиния)\n  - О сайте »\n    - Изменения\n    - Новости\n    - Ссылки\n    - Галерея\n    - Карта сайта\n\n- Поиск\n- Меню: История: Возможности | Мифы | Project MAC | Даты",
      "commentsSummary": "- Обсуждение посвящено наследию Multics: многие отмечают его огромное влияние на ОС и безопасность; упоминаются проекты-наследники вроде SCOMP/STOP и активность симулятора DPS8M.  \n- Пользователи делятся воспоминаниями об использовании Multics в университетах (Бристоль, Лидс, RPI) в 80–90-х: система считалась быстрой для своего времени, апгрейды памяти были заметны, ценили терминал-терминал сообщения и удалённый доступ по JANET.  \n- Один участник критикует учебник создателей Multics за «всё-в-одном» подход, связывая это с усложнением дизайна и мотивацией появления UNIX.  \n- Другие, напротив, выделяют сильные стороны Multics, которые хотелось бы видеть в Unix/Linux: кольцевую модель привилегий, обязательный контроль доступа и ACL, сегментированную память, защиту от переполнений, гибкие имена команд.  \n- Делятся полезными ссылками: мифы о Multics, оценка безопасности B2, страница по безопасности данных (AIM и MAC), «Три вопроса» для багов, меморабилия и список изменений сайта.  \n- Отмечают грустный аспект страницы «Recent Changes» — фиксируется уход многих участников проекта; некоторые узнают о смерти бывших преподавателей.  \n- Вопросы о текущей «активности разработки» сводятся к тому, что Multics как система закрыта, но сохраняется через документацию, симуляторы и исследования; последний реальный сайт Multics закрыт в 2000 году.",
      "score": 117,
      "commentsCount": 25,
      "hnUrl": "https://news.ycombinator.com/item?id=44814596",
      "domain": "multicians.org"
    },
    {
      "id": 44777086,
      "title": "Automerge 3.0",
      "url": "https://automerge.org/blog/automerge-3/",
      "by": "surprisetalk",
      "timeISO": "2025-08-03T15:08:58.000Z",
      "postSummary": "Automerge — это движок синхронизации данных с приоритетом локальной работы, упрощающий создание коллаборативных приложений. Выпущена версия 3.0.\n\nГлавное обновление — резкое снижение потребления памяти. Ранее хранение полной истории документов могло приводить к гигабайтам в ОЗУ. В 3.0 память сокращена более чем в 10 раз (иногда значительно больше), что делает Automerge применимым в куда большем числе сценариев.\n\nТакже упразднены избыточные API, особенно при работе со строками.\n\nЕсли вы уже используете Automerge, обновляйтесь: формат файлов тот же, API почти полностью обратно совместим. Подробности — в руководстве по миграции. Если вы ещё не пробовали, сейчас хорошее время — производительность и надежность сильно выросли.\n\nЧтобы узнать, как достигнуты улучшения, читайте далее.\n\n- Улучшенное использование памяти\n  - Automerge хранит каждое изменение для офлайн-работы, конфликтов и истории; это требует большого объёма метаданных.\n  - Раньше: сжатый колоночный формат «на диске», но при загрузке в память — несжатый вид, из-за чего ОЗУ раздувалось.\n  - Теперь: сжатое представление используется и во время выполнения, давая огромную экономию. Пример: вставка «Моби Дика» — было ~700 МБ в v2, стало ~1,3 МБ в v3.\n  - Меньше памяти — стабильнее нагруженные сервера синхронизации.\n  - Для документов с длинной историей существенно ускорена загрузка (пример: с «не загрузилось за 17 часов» до 9 секунд).\n\n- Упрощение API\n  - Два типа строк: «коллаборативные» (сливают правки) и «неколлаборативные».\n  - В 1.0: обычные строки для неколлаборативных, класс Text — для коллаборативных.\n  - В 2.0 (namespace next): сделали коллаборативный текст по умолчанию — строки для него, RawString для неколлаборативного.\n  - В 3.0: закрепили новый подход — удалён Text, API next стал дефолтным; RawString переименован в ImmutableString.\n\n- Попробовать\n  - Automerge 3.0 используется по умолчанию в последних `@automerge/automerge-repo` и `@automerge/react` (версия `2.1.0`).\n  - Новичкам — туториал. Существующим кодовым базам — руководство по миграции; если зависите от `@automerge/automerge-repo`, выполните `npm update @automerge/automerge`.\n  - Проблемы — создавайте issue; вопросы — в Discord.",
      "commentsSummary": "- Обсуждение вокруг релиза Automerge 3.0 и смежных проектов: отмечают огромные улучшения по памяти и времени загрузки (пример с «Моби Диком»: ~700 МБ в v2 против ~1.3 МБ в v3), но просят бенчмарки против yjs и упоминание альтернатив вроде jsonjoy.  \n- Сравнивают подходы: для совместного редактирования rich‑text подходят Automerge/yjs; для «server‑authoritative» локально‑первых приложений — ElectricSQL; в целом экосистема синх‑движков ширится (Convex, Zero).  \n- Вопросы интеграции: есть примеры с React и ProseMirror; TipTap можно подключить, обернув схему и подменив undo/redo; интересуются поддержкой «permissioned» блоков внутри документа и операцией move для деревьев (есть прототипы у Клеппмана, но в Automerge пока не включено).  \n- API и языки: ядро на Rust; основной дружественный интерфейс — JavaScript; есть C API-обёртка (статус для 3.0 уточняется).  \n- Архитектура CRDT: спрашивают о структуре полуре́шётки и типе регистра в map (MV‑register vs LWW); даны ссылки на документацию по конфликтам.  \n- Практические кейсы: для командного редактирования документов и локально‑первых приложений; технические писатели интересуются версионированием секций — сообщество просит конкретизировать требования, т.к. пригодность зависит от модели прав и истории.  \n- Инфраструктура: интерес к требованиям к sync‑серверу и масштабируемости чтений/записей; также спрашивают о возможности терминальных UI на основе Rust/C API.",
      "score": 303,
      "commentsCount": 28,
      "hnUrl": "https://news.ycombinator.com/item?id=44777086",
      "domain": "automerge.org"
    },
    {
      "id": 44778898,
      "title": "Comptime.ts: compile-time expressions for TypeScript",
      "url": "https://comptime.js.org/",
      "by": "excalo",
      "timeISO": "2025-08-03T19:11:40.000Z",
      "postSummary": "![Изображение 1: Hyperactive](https://raw.githubusercontent.com/feathers-studio/comptime.ts/master/docs/comptime.ts.svg)\n\nПростой компилятор TypeScript для вычисления выражений с пометкой comptime на этапе сборки. Полезно для переноса вычислений из рантайма в компиляцию. Вдохновлено Bun macros и Zig comptime.\n\nВнимание: вы сами отвечаете за безопасность выражений, вычисляемых на этапе компиляции. Изоляции нет. Импорты comptime допускаются только в файлах проекта (не в node_modules), но можно импортировать из node_modules как comptime.\n\nСодержание\n- Что такое comptime.ts?\n- Примеры: 1) простая сумма; 2) CSS без рантайма; 3) константы во время сборки\n- Установка\n- Использование: Vite, Bun, CLI, API\n- Принудительная оценка и промисы, отказ от «вирусности»\n- Запуск кода после comptime, как работает, ограничения, практики, отладка, поддержка, лицензия\n\nЧто это\ncomptime.ts вычисляет выражения при компиляции, сокращая работу в рантайме.\n\nПримеры\n1) Простая сумма\nimport { sum } from \"./sum.ts\" with { type: \"comptime\" };\nconsole.log(sum(1, 2));\n// => console.log(3);\n\n2) Emotion CSS без рантайма\nimport { css } from \"@emotion/css\" with { type: \"comptime\" };\nconst style = css`color: red; font-size: 16px;`;\ndiv({ class: style });\n// => const style = \"css-x2wxma\"; div({ class: style });\n\nПримечание: импорт @emotion/css удаляется. Стили нужно вывести отдельно (после comptime или плагином бандлера).\n\n3) Константы на этапе сборки\nimport { ms } from \"ms\" with { type: \"comptime\" };\nconst HOUR = ms(\"1 hour\");\n// => const HOUR = 3600000;\n\nПоддерживаются многие выражения (включая индексацию и импортированные константы), результат должен быть сериализуем в JSON. Импорты с type: \"comptime\" удаляются; лишнее убирает ваш бандлер.\n\nУстановка\nbun add comptime.ts\npnpm add comptime.ts\nnpm install comptime.ts\n\nИспользование\n- Vite:\nimport { comptime } from \"comptime.ts/vite\";\nexport default defineConfig({ plugins: [comptime()] });\n\nТолько в прод-сборке, если поведение совпадает с рантаймом:\nexport default defineConfig({ build: { rollupOptions: { plugins: [comptime()] } } });\n\n- Bun:\nimport { comptime } from \"comptime.ts/bun\";\nawait Bun.build({ entrypoints: [\"./index.ts\"], ou ... })",
      "commentsSummary": "- Участники обсуждают идею “comptime”/макросов в JS: одни хотят агрессивные условные вычисления на этапе компиляции, как в Zig или Rust proc macros, чтобы заменить препроцессорные трюки в JS.  \n- Критикуют использование import-атрибута type: 'comptime' как злоупотребление зарезервированным полем, которое в веб-спеке связано с MIME-типами (json/css), хотя есть позиция, что спецификация оставляет атрибуты обобщёнными.  \n- Приводят практические кейсы: предкомпиляция Markdown, JSX без отдельного TSX, возврат именованных функций; обсуждают ограничения — поддержка типов/генериков на уровне компиляции как в Zig пока под вопросом.  \n- Уточняют синтаксис import with и ссылки на его спецификацию/включение в ES2026, отмечают нехватку документации и путаницу в терминологии “макросов” у Bun.  \n- Предлагают альтернативы: sweet.js (хотя проект застопорился), lite-jsx/core, а также Rust-фреймворки Dioxus/Leptos; поднимают тему WASM и опыт с C++/Emscripten.  \n- Возникают споры о целесообразности: почему не настроить обычный JSX-лоадер вместо макроса; вопросы о сложности поддержания замыканий и безопасных гарантий при переносе функций между процессами JS.  \n- В целом консенсус: идея компилятора/макросов в JS привлекательна, но терминология, совместимость со спекой и гарантии безопасности/типов остаются нерешёнными.",
      "score": 127,
      "commentsCount": 27,
      "hnUrl": "https://news.ycombinator.com/item?id=44778898",
      "domain": "comptime.js.org"
    },
    {
      "id": 44812695,
      "title": "Breaking the sorting barrier for directed single-source shortest paths",
      "url": "https://www.quantamagazine.org/new-method-is-the-fastest-way-to-find-the-best-routes-20250806/",
      "by": "baruchel",
      "timeISO": "2025-08-06T14:43:02.000Z",
      "postSummary": "Если хотите решить сложную задачу, полезно разложить ее на части и идти от простого к сложному. Но сортировка частей тоже стоит времени: можно потратить его больше на упорядочивание, чем на решение.\n\nЭто особенно заметно в культовой задаче информатики — поиске кратчайших путей от одной вершины графа до всех остальных. Интуитивно проще сначала находить ближайшие цели, затем более дальние. Но для этого нужно постоянно определять, какая вершина ближе, то есть фактически сортировать по расстоянию. Возникает «барьер сортировки»: алгоритм, зависящий от сортировки, не может быть быстрее, чем сама сортировка.\n\nКоманда исследователей предложила новый алгоритм, который обходится без сортировки и работает быстрее всех «сортирующих» методов, преодолев сорокалетний барьер. Роберт Тарьян назвал результат поразительным.\n\nГрафы описывают вершины и ребра с весами (длина, время и т.п.). Задача: по данному источнику найти кратчайшие пути до всех вершин. Алгоритм Дейкстры (1956) идет «волной» наружу: зная оптимальные пути к ближайшим, находит пути к дальним. Но конечный результат — упорядоченный набор кратчайших расстояний, и потому скорость ограничена сортировкой. В 1984 году Тарьян с соавтором улучшили Дейкстру до этого предела: чтобы ускориться дальше, нужно избегать сортировки.\n\nВ конце 1990-х — начале 2000-х Торуп и другие обошли барьер для частных случаев, вводя ограничения на веса. Обобщить техники на произвольные веса не удавалось, и прогресс застопорился. Ран Дуань не согласился с пессимизмом и стремился сломать барьер для всех графов — и прошлой осенью добился цели.\n\nИдея Дуани (созревшая к 2021 году): вместо того чтобы на каждом шаге сканировать всю «границу» уже исследованной области, как делает Дейкстра (что со временем замедляет ход), группировать соседние граничные вершины в кластеры и рассматривать по одному представителю из каждого. Это уменьшает число кандидатов и может вести не к ближайшей вершине — значит, зависимость от сортировки исчезает. Главная трудность — доказать, что кластеризация действительно ускоряет процесс на каждом шаге и в сумме.\n\nЗа следующий год Дуань проработал идею и к осени 2022-го был уверен, что технические барьеры преодолимы.",
      "commentsSummary": "- Обсуждение вокруг нового алгоритма SSSP из препринта arXiv:2504.17033, дающего детерминированное время O(m log^(2/3) n) и тем самым впервые асимптотически обходящего Дейкстру на разреженных графах.  \n- Участники спорят о практической значимости: на плотных графах m доминирует и выигрыш может исчезнуть; на дорожных сетях m ≈ O(n), что даёт реальную выгоду до O(n log^(2/3) n).  \n- Поднимаются вопросы корректности/глобального оптимума по сравнению с Дейкстрой и опасений, что «склеивание фронтира» может пропускать решения — предлагается обратиться к статье за деталями.  \n- Некоторые замечают, что метод сложнее Дейкстры, но это ожидаемо; звучат идеи о гибридизации с рандомизацией для дополнительных ускорений.  \n- Есть комментарии о том, что для задач вроде TSP с почти полный графом (m ~ n^2) выигрыш не очевиден.  \n- Отмечается «незамысловатость» используемой математики и удивление, что такое могли открыть ещё десятилетия назад; приводятся ссылки на препринт и HN-поиск.  \n- В стороне обсуждают вклад Тарьяна, общую обучаемость Дейкстры и аналогии с практическими алгоритмами вроде TimSort.",
      "score": 147,
      "commentsCount": 45,
      "hnUrl": "https://news.ycombinator.com/item?id=44812695",
      "domain": "quantamagazine.org"
    },
    {
      "id": 44811280,
      "title": "303Gen – 303 acid loops generator",
      "url": "https://303-gen-06a668.netlify.app/",
      "by": "ankitg12",
      "timeISO": "2025-08-06T12:50:06.000Z",
      "postSummary": "303Gen",
      "commentsSummary": "- Автор поделился незавершённым веб-синтом с тремя «303»-движками, добавил полифилл для cancelAndHoldAtTime (Firefox), улучшил мобильную версию и интерфейс регенерации/крутилок.  \n- Сообщество в основном в восторге: хвалят музыкальность, полиритмы, общий лад/масштаб, роли бас/лид/дрон, ностальгию по ReBirth/90‑м и вдохновение вернуться к электронике.  \n- Запросы/идеи: открытый исходный код, экспорт/сохранение (MIDI, паттерны), визуальный вывод паттернов, MIDI sync/transport и BPM‑синх, не сбрасывать темп при Regenerate и не останавливать воспроизведение, локальная/плагин‑версия, возможность 150 BPM, автоматика модуляций, добавление 909‑кита и новых ладов (гарм./мелод. минор).  \n- Технические замечания: в Firefox отсутствует cancelAndHoldAtTime (Mozilla пообещала реализовать); баги со Stop и эхом в Chromium; пожелание, чтобы Regenerate не прерывал проигрывание.  \n- Некоторые отмечают недостатки эмуляции TB‑303 (особенно поведение accent/атак), но при этом хвалят «склейку» дроном и общий саунд.  \n- Проект вдохновил на обмен ссылками (Endless Acid Banger), идеями семплинга, а также вопросами, как начать делать электронную музыку (упоминают Renoise).  \n- Итог: инструмент воспринимается как «лучшая находка», музыкальный и играбельный, со спросом на открытие кода и функции экспорта/синхронизации для более широкого использования.",
      "score": 201,
      "commentsCount": 68,
      "hnUrl": "https://news.ycombinator.com/item?id=44811280",
      "domain": "303-gen-06a668.netlify.app"
    },
    {
      "id": 44820325,
      "title": "FDA approves eye drops that fix near vision without glasses",
      "url": "https://newatlas.com/aging/age-related-near-sighted-drops-vizz/",
      "by": "geox",
      "timeISO": "2025-08-07T03:34:58.000Z",
      "postSummary": "FDA одобрила глазные капли VIZZ для облегчения пресбиопии\n\n- VIZZ — новые рецептурные капли для улучшения близорукости, связанной с возрастом (пресбиопии), позволяющие читать и работать вблизи без очков.\n- Препарат временно повышает глубину резкости за счет сужения зрачка (фармакологическая миозия); эффект наступает быстро и держится несколько часов.\n- Клинические испытания показали статистически значимое улучшение зрения вблизи у большинства участников по сравнению с плацебо.\n- Наиболее частые побочные эффекты: головная боль, покалывание в глазах, покраснение, снижение качества зрения при слабом освещении; не рекомендуется для ночного вождения.\n- Капли не лечат причину пресбиопии и не заменяют консультацию офтальмолога; подходят как альтернатива или дополнение к очкам/линзам.\n- Ожидается коммерческий запуск в США после финализации маркировки и логистики; доступ по рецепту.",
      "commentsSummary": "- Обсуждают одобрение FDA новых глазных капель для пресбиопии на основе данных компании; рецензируемые публикации часто выходят после регуляторного одобрения, что вызвало вопросы о причинах такой последовательности.  \n- Один из ответов поясняет: публикация занимает больше времени, чем ревью FDA; компании подают досье вскоре после результатов испытаний, а ускоренное одобрение может занять 3–4 месяца.  \n- Препарат работает за счет сужения зрачка, увеличивая глубину резкости; комментаторы отмечают возможное снижение количества света на сетчатке и ухудшение зрения в тусклом освещении, сравнивая эффект с ярким светом или «пинхол»-щелью.  \n- Пользователи обсуждают стоимость и «подписочную» модель: озвучены цены около $79 за 25 доз в месяц или $198 за 3 месяца; сравнивают с дешевыми «читателями» за $15 и альтернативами вроде ИОЛ/лазерной коррекции.  \n- В ветке про моновижн делятся опытом: некоторым требуется период адаптации (иногда сначала неудачно, потом успешно), есть кейсы с разной коррекцией для каждого глаза и рекомендацией пробовать контактные линзы перед хирургией.  \n- Поднимают вопросы безопасности длительного сужения зрачка и «перекоррекции»; отвечают, что «перебор» скорее приведет к нехватке света, а не к оптической ошибке, но риски в темноте остаются.  \n- Присутствует скепсис к FDA и намеки на рыночные/биржевые мотивы и упаковки на 28 дней, а также ироничные комментарии про «бутылочное прищуривание».",
      "score": 86,
      "commentsCount": 42,
      "hnUrl": "https://news.ycombinator.com/item?id=44820325",
      "domain": "newatlas.com"
    },
    {
      "id": 44812985,
      "title": "Zig Error Patterns",
      "url": "https://glfmn.io/posts/zig-error-patterns/",
      "by": "Bogdanp",
      "timeISO": "2025-08-06T15:03:19.000Z",
      "postSummary": "Введение\n\nЯ часто использую отладчик, но привык и к выводной отладке, особенно в юнит-тестах. Хотелось улучшить её и чаще подключать отладчик.\n\nУлучшение выводной отладки\n\nГлавная проблема — «шум»: в цикле интересна одна итерация, а печатается всё. Или удобнее читать форматированную структуру, но приходится раскидывать print’ы по коду. В Zig тесты используют error’ы, значит можно печатать только при падении теста через errdefer:\n\ntest {\n    errdefer std.debug.print(\"{f}\", .{ast});\n    // ...\n}\n\nТак контекст появляется только при ошибке, без засорения лога.\n\nЗапуск тестов в отладчике\n\nПросто запустить seergdb или gdb -tui неудобно: тестовые бинарники лежат в zig-cache. Трюк из ziggит: build.zig может запускать команды и передавать путь артефакта:\n\n// seergdb — GUI фронтенд для gdb\nconst debugger = b.addSystemCommand(&.{ \"seergdb\", \"--run\", \"--\" });\ndebugger.addArtifactArg(exe_unit_tests);\n\nconst debug_step = b.step(\"debug\", \"Run unit tests under debugger\");\ndebug_step.dependOn(&debugger.step);\n\nЭто запускает правильный бинарник. Но отладчик сработает лишь на брейкпоинте или панике, тогда как раннер тестов «проглатывает» ошибки.\n\nКомбинация трюков\n\nДобавим @breakpoint через errdefer:\n\ntest {\n    errdefer @breakpoint();\n}\n\nТак мы попадаем в точку ошибки, видим контекст и вывод std.testing.expect*. Минус: при zig build test отчёт показывает падение всего шага тестов, а не отдельных кейсов. Нужна возможность включать брейкпоинты выборочно.\n\nУсловная компиляция\n\nЧерез build options пробрасываем флаг, решающий, вызывать ли @breakpoint в тестах.\n\nМинимальный скрипт сборки, запускающий тесты, дополняем опциями:\n\nconst std = @import(\"std\");\n\npub fn build(b: *std.Build) void {\n    const target = b.standardTargetOptions(.{});\n    const optimize = b.standardOptimizeOption(.{});\n\n    const lib = b.addModule(\"zig-test-patterns\", .{\n        .root_source_file = b.path(\"src/root.zig\"),\n        .target = target,\n        .optimize = optimize,\n    });\n\n    const options = b.addOptions();\n    options.addOption(bool, \"debugger\", false);\n    lib.addImport(\"config\", options.createModule());\n\n    const mod_tests = b.addTest(.{ .root_module = lib });\n    const run_mod_tests = b.addRunArtifact(mod_tests);\n\n    const test_step = b.step(\"test\", \"Run tests\");\n    test_step.dependOn(&run_mod_tests.step);\n}\n\nВ коде тестов:\n\nconst std = @import(\"std\");\nconst config = @import(\"config\");\n\ntest \"errdefer @breakpoint()\" {\n    errdefer if (config.debugger) @breakpoint();\n    return error.FixMe;\n}\n\ntest \"no breakpoint\" {\n    return error.FixMe;\n}\n\nzig build test — без брейкпоинтов. Но менять значение флага так — значит пересобирать build.zig. Добавим опцию прямо в систему сборки:\n\nvar options = b.addOptions();\nconst use_debugger = b.option(\n    bool,\n    \"debugger\",\n    \"Enables code intended to only run under a debugger\",\n) orelse false;\noptions.addOption(bool, \"debugger\", use_debugger);\n\nТеперь можно переключать поведением командой:\n\nzig build -Ddebugger test\n\nИ, при желании, привязать шаг запуска отладчика к этому флагу.",
      "commentsSummary": "- Участники хвалят целостный дизайн Zig: базовые блоки языка логично сочетаются, errdefer считают «вещью, которая должна быть в каждом языке», а советы по отладке и интеграции debugger’а в build.zig — очень полезными.  \n- Отмечают приятный дизайн сайта/блога: шрифты (Berkeley Mono), цветовую схему и «ретро»-оформление.  \n- Поднимается спорная тема: в Zig нельзя прикреплять payload к ошибкам; это называют слабым местом системы ошибок.  \n- Сообщество объясняет идиоматичный паттерн: возвращать «чистую» ошибку, а подробные данные — через дополнительный аргумент-указатель (или отдельный diagnostics-объект, как в std.json).  \n- Делятся ресурсами и паттернами: ссылки на issue, статьи/видео про «скрытые» payload’ы, и раздел руководства по правилам именования.  \n- Обсуждают стиль кода: смешение camelCase в stdlib и snake_case у авторов — вопрос предпочтений, но возможен дискомфорт от несогласованности.  \n- Итог по философии ошибок Zig: ошибки — для управления потоком (try/catch/errdefer); детальные данные возвращают отдельно — напрямую, через out-параметры или контекст.",
      "score": 138,
      "commentsCount": 40,
      "hnUrl": "https://news.ycombinator.com/item?id=44812985",
      "domain": "glfmn.io"
    },
    {
      "id": 44815046,
      "title": "AI in Search is driving more queries and higher quality clicks",
      "url": "https://blog.google/products/search/ai-search-driving-more-queries-higher-quality-clicks/",
      "by": "thm",
      "timeISO": "2025-08-06T17:32:42.000Z",
      "postSummary": "- Генеративный ИИ в Поиске увеличивает общее число запросов и приводит к более качественным кликам. Пользователи задают больше сложных, многосоставных вопросов и чаще продолжают сессию последующими уточнениями.\n\n- Мы по‑прежнему каждый день отправляем миллиарды переходов на сайты и встраиваем ссылки на источники прямо в ИИ‑ответы. Приоритет — поддержка открытой сети: улучшаем видимость издателей, экспертов и создателей контента.\n\n- Ранние данные показывают рост времени взаимодействия и удовлетворённости: люди быстрее находят нужное, чаще кликают по результатам с высокой релевантностью и реже возвращаются к той же теме.\n\n- ИИ‑обзор помогает в «мутных» запросах: сравнение вариантов, планирование, пошаговые инструкции. Он предлагает краткий ответ с цитируемыми источниками, после чего люди переходят глубже по ссылкам.\n\n- Бизнесы видят более качественный трафик: больше кликов с высокой вероятностью конверсии. Продолжаем расширять рекламные форматы, сохраняя чёткую маркировку рекламы и органики.\n\n- Мы тестируем и улучшаем модели, учитывая отзывы пользователей и издателей, чтобы поддерживать полезность, точность и безопасность ИИ‑ответов.",
      "commentsSummary": "- Обсуждение вращается вокруг заявлений Google, что AI-обзоры в поиске повышают количество запросов и качество кликов; многие участники сомневаются, приводя контрпримеры и ссылки на отчеты о падении кликов.  \n- Пользовательские кейсы разделились: часть людей читает только AI-саммари и не кликает дальше, другие — кликают при сложных запросах; некоторые отмечают, что саммари помогают быстрее выбрать ссылку.  \n- Критика фокусируется на галлюцинациях и неточностях AI-ответов, примерах вводящих в заблуждение рекомендаций, а также на риске подрыва экосистемы веба и мотивации авторов контента.  \n- Звучит опасение, что Google преследует монетизацию: удержание пользователей на своей площадке, будущая интеграция рекламы в саммари, приоритет партнеров и крупных сайтов.  \n- Ряд комментаторов винит прежнюю оптимизацию поиска под SEO-спам и считает, что AI частично лечит симптом, но может уничтожать нишевые, «человеческие» знания сообществ.  \n- Есть и позитив: для базовых фактов AI-обзоры экономят время и упрощают навигацию, однако для ответственных задач пользователи предпочитают проверять первоисточники.  \n- В целом тон дискуссии скептический: требуют прозрачных данных от Google, указывают на маркетинговую риторику и сравнивают нынешний опыт с «лучшим Google» прошлых лет.",
      "score": 64,
      "commentsCount": 90,
      "hnUrl": "https://news.ycombinator.com/item?id=44815046",
      "domain": "blog.google"
    },
    {
      "id": 44817725,
      "title": "301party.com: Intentionally open redirect",
      "url": "https://301party.com/",
      "by": "nahikoa",
      "timeISO": "2025-08-06T20:54:39.000Z",
      "postSummary": "### 301party.com: намеренно открытый редирект\n\nПримеры:\n- /redirect?url=https://example.com&type=302\n- /{301,302,303,307,308}?url=http://example.com\n- /metadata: ярлык для /redirect?url=http://169.254.169.254/latest/meta-data/\n- /metadata6: ярлык для /redirct?url=http://[fd00:ec2::254]/latest/meta-data/\n- /localhost: ярлык для /redirect?url=http://127.0.0.1\n- /zeroes: ярлык для /redirct?url=http://0.0.0.0\n- /passwd: ярлык для /redirect?url=file:////etc/passwd\n- /services: ярлык для /redirct?url=file:///etc/services\n- /environ: ярлык для /redirect?url=file:///self/proc/environ\n\nБонусные DNS-записи:\n- localhost.301party.com: 127.0.0.1\n- metadata.301party.com: 169.254.169.254\n- ipv6.metadata.301party.com: [::169.254.169.254]\n\nDIY: https://gitlab.com/wtfismyip/301party/",
      "commentsSummary": "- Обсуждают сервис 301party для тестирования редиректов; приводят примеры забавных трюков: нестандартные коды в http.Redirect, XSS-подобная ссылка с javascript: и почти бесконечные циклические 301, из-за которых браузер сдаётся.  \n- Замечают, что редирект на file: в браузерах блокируется без понятного сообщения, но бэкенд-библиотеки могут слепо следовать редиректам (например, к AWS metadata 169.254.169.254 или file:///etc/passwd), что опасно.  \n- Обсуждают DNS/адреса: отдельные имена для IPv4/IPv6 (169.254.169.254 и ::169.254.169.254), зачем не объединить A/AAAA, и возможный шутливый подтекст; упоминают полезность гарантированного адреса под конкретный стек.  \n- Шутят про баг-баунти и open redirect, предлагают «репортить» на localhost.301party.com; также отмечают опечатки «redirct».  \n- Отмечают ограничение «нельзя 127.0.0.1/localhost как callback» и намекают на способы обойти подобные проверки (через поддомены/варианты).  \n- Упоминают аналог/сервис redirect.pizza и что 301party создан wtfismyip.com; один участник спрашивает базовое «что это?» — отвечают: «утилита для тестирования 301-редиректов», что проясняет юзкейс.",
      "score": 81,
      "commentsCount": 14,
      "hnUrl": "https://news.ycombinator.com/item?id=44817725",
      "domain": "301party.com"
    },
    {
      "id": 44781343,
      "title": "Compaq’s Rod Canion broke IBM's hold on the PC market",
      "url": "https://every.to/feeds/b0e329f3048258e8eeb7/the-man-who-beat-ibm",
      "by": "vinnyglennon",
      "timeISO": "2025-08-04T01:31:42.000Z",
      "postSummary": "История персонального компьютера — это не только технологии, но и видение, доверие и смелость противостоять монополии. В новом материале для The Crazy Ones Гарет Эдвардс рассказывает, как Compaq бросила вызов доминированию IBM в 1980-х. Когда IBM попыталась вернуть контроль над рынком с помощью закрытых технологий, CEO Compaq Род Кэнион создал открытый стандарт и поделился им с конкурентами — фактически «отдал семейные драгоценности», чтобы сохранить инновации. Эдвардс показывает, как стиль лидерства Кэниона создал любимую культуру и хребет, чтобы противостоять гиганту. Если бы победила IBM, наш технологический ландшафт мог бы быть совсем иным.\n\nВ сентябре 1988-го Кэниону позвонил Билл Лоу, глава PC-направления IBM. Он предложил Compaq эксклюзивный доступ к новой закрытой платформе IBM в обмен на отмену пресс-конференции, на которой Compaq с девятью крупными производителями собирались закрепить открытый стандарт PC вопреки IBM. По сути: отказаться от союзников и разделить рынок на двоих. Финансово — подарок. Но Кэнион вежливо отказал. Лоу вздохнул: «Вы ошибаетесь». Через четыре дня Кэнион вышел на сцену в Нью-Йорке и объявил открытую войну IBM.\n\nЭто история Рода Кэниона и Compaq — борьбы за душу персонального компьютера и за то, чтобы IBM не восстановила полный контроль над технологией. Она основана на материалах New York Times, Time, PC Magazine, Byte, Infoworld; книгах Blue Magic (Джеймс Чпоски, Тед Леонсис), The Fate of IBM (Роберт Хеллер), Big Blues (Пол Кэрролл), Open (Род Кэнион), а также интервью с Беном Розеном, Л.Дж. Севином (для фильма Silicon Cowboys и Музея компьютерной истории) и беседах автора с самим Кэнионом.\n\nНачало компании\n\nРод Кэнион, Джим Харрис и Билл Мурто — «корпоративные» люди из Texas Instruments. К началу 1981-го, в сорок с лишним, в костюмах и галстуках, они устали от скучного начальства и, навещая подрядчиков в Кремниевой долине, видели парковки с Porsche и Ferrari. За ужином у Мурто решили: пора создавать свою компанию. Идею мексиканского ресторана быстро отбросили — их стихия компьютеры. Они нацелились на IBM PC.\n\nPC был открыт для расширения: любые компании могли делать платы, диски и аксессуары. Для IBM это был нетипичный шаг, но Дон Эстридж считал, что успех на рынке дома и малого бизнеса возможен только на базе стандартной, собираемой из отраслевых компонентов платформы. К осени 1981-го PC становился хитом, с продажами к 250 тысячам.\n\nКэнион в TI руководил проектом жесткого диска, с ним же работали Харрис и Мурто — значит, опыт переносим на PCs. Но денег не было, венчурный капитал — зарождающийся и в основном в Калифорнии, связей — никаких. Удачей стала встреча с Порцией Айзексон — ветераном армии США и программистом, работавшей в Bell Helicopter и Lock...",
      "commentsSummary": "- Обсуждение началось с удивительного тезиса: версии MS-DOS, начиная с 2.0, фактически разрабатывались Compaq, что многих удивило и вызвало споры о датировках (скорее 1983, чем 1982).\n- Несколько участников делятся ностальгией и опытом: от посещений фабрики Compaq в Сингапуре в 1992 и ее закрытия в 1999 до практических проблем с качеством комплектующих (дешевые винты корпусов).\n- Рекомендуют материалы по теме: документальный фильм Silicon Cowboys и интервью Рода Канайона в подкасте How I Built This; упоминают ос2museum как источник технического разбора багов DOS.\n- Отмечают влияние решения Compaq лицензировать свой DOS обратно Microsoft, что укрепило доминирование MS и, по мнению некоторых, принесло отрасли долгосрочные проблемы.\n- Обсуждают вертикальную интеграцию: несмотря на поражение IBM в PC, сегодня она фактически победила в мобильной и частично в ПК/серверном мире, хотя экосистема ПК остаётся модульной.\n- В ветке о процессорах спорят о стратегиях Intel: отказ от RISC-ставки (i860) в пользу обратной совместимости x86 оказался выигрышным; позднее даже Intel приняла AMD64.\n- Общий вывод: обратная совместимость и правильные партнерства/лицензии сильно определили траекторию ПК-индустрии, а бренд Compaq прошёл путь от инноваций и качества к размыванию имиджа в потребительском сегменте и поглощению HP.",
      "score": 70,
      "commentsCount": 27,
      "hnUrl": "https://news.ycombinator.com/item?id=44781343",
      "domain": "every.to"
    },
    {
      "id": 44818957,
      "title": "Out-Fibbing CPython with the Plush Interpreter",
      "url": "https://pointersgonewild.com/2025-08-06-out-fibbing-cpython-with-the-plush-interpreter/",
      "by": "Bogdanp",
      "timeISO": "2025-08-06T23:18:07.000Z",
      "postSummary": "August 6th, 2025\n\nВ прошлой записи я рассказывал о Plush — игрушечном языке с акторным параллелизмом. Реализация ещё сырая, но уже можно писать забавные программы с 2D/3D‑графикой и распараллеливать задачи на несколько ядер. Хочу ради развлечения сделать софтварный рендер вращающегося куба, но сперва немного ускорю интерпретатор, чтобы не терять лишнюю производительность.\n\nМой научрук обожал рекурсивный микробенчмарк Fibonacci — «fib». При каждом разговоре о компиляторах он стремился запустить этот крошечный тест и сравнить скорости, нередко со своим Scheme‑компилятором — то ли в шутку, то ли всерьёз.\n\n```\nfun fib(n)\n{\n    if (n < 2)\n        return n;\n\n    return fib(n - 1) + fib(n - 2);\n}\n```\n\nМикробенчмарки не отражают общую производительность, но полезны: здесь «fib» резко подчёркивает стоимость вызовов функций — важного источника накладных расходов.\n\nВ Plush fib(38) занял 9.10 с в релизной сборке — это 126+ млн вызовов, около 14 млн/с. Python 3.13.5 сделал то же за 5.70 с, Plush на ~60% медленнее. Учитывая, что CPython тоже токен‑трединговый интерпретатор, сравнение честное. Я решил посмотреть, можно ли парой простых трюков обогнать CPython на «fib».\n\nБайт‑код для fib содержит 18 инструкций. Как и в CPython, VM стековая: get_arg кладёт аргумент, push — константу, lt — сравнение и т. п. Бросилось в глаза, что перед вызовом я кладу на стек константу‑функцию, а затем делаю call. В этом месте функция известна заранее, значит можно слить push+call в call_direct с зашитой целью. Это убрало две инструкции и ускорило с 9.10 с до 8.44 с.\n\nПочему быстрее? Главная потеря в интерпретаторах — диспетчеризация инструкций. Чем «толще» инструкция, тем реже диспетчеризация и тем больше шансов у компилятора оптимизировать блок кода целиком.\n\nДальше я профилировал Linux perf. В Plush функции лениво компилируются в байт‑код при первом вызове: парсим всё в AST, но компилируем по требованию — экономим время/память и получаем больше информации для оптимизаций. Инструкция call при вызове смотрит в хеш‑таблицу: скомпилирована ли функция и куда прыгать (PC). Этот поиск оказался ощутимой нагрузкой. Я добавил инструкцию call_pc — вызов функции, уже имеющей байт‑код, — и сделал так, чтобы call_direct инициировал компиляцию при первом обращении и затем переходил на call_pc, убирая последующие хеш‑поиски.",
      "score": 31,
      "commentsCount": 0,
      "hnUrl": "https://news.ycombinator.com/item?id=44818957",
      "domain": "pointersgonewild.com"
    },
    {
      "id": 44813905,
      "title": "Show HN: Sinkzone DNS – Forwarder that blocks everything except your allowlist",
      "url": "https://github.com/berbyte/sinkzone",
      "by": "dominis",
      "timeISO": "2025-08-06T16:08:23.000Z",
      "commentsSummary": "- Пользователи хвалят Sinkzone за удобный фокус-режим и расписания, считая его более практичным, чем массовые блоклисты hosts или переключения правил в OpenSnitch; отмечают, что это проще для «allowlist‑сначала» подхода.  \n- Обсуждают ограничения: приложения могут подключаться напрямую по IP (мимо DNS), поэтому для полного контроля всё равно нужен файрвол; спрашивают про DoH и объясняют, что можно настраивать апстрим‑резолверы.  \n- Сравнивают с Pi-hole, AdGuard Home и NextDNS: те можно настроить, но чаще ориентированы на сеть в целом или «blocklist‑сначала»; преимущество Sinkzone — локально на машине, не ломает интернет для семьи/коллег и проще для allowlist‑воркфлоу.  \n- Запросы на платформы и интеграции: Windows поддерживается; интерес к iOS/брaузерной стороне, интеграции с Apple Shortcuts и помодоро/кастомными расписаниями; автор говорит, что это в планах.  \n- Вопрос о совместимости с корпоративным VPN и приватными зонами: предполагается возможность поставить Sinkzone перед VPN‑резолвером, но это пока не тестировалось.  \n- Некоторые предпочитают редактировать /etc/hosts или использовать Fort, Portmaster, simplewall; считают Sinkzone более «элегантным» и удобным.  \n- Замечают, что без блокировки на телефоне эффект ограничен; предлагаются обходы через NextDNS/мобильный VPN к домашнему DNS, а автор планирует поддержку телефонов и мульти‑тенантные профили для семьи.",
      "score": 75,
      "commentsCount": 40,
      "hnUrl": "https://news.ycombinator.com/item?id=44813905",
      "domain": "github.com"
    },
    {
      "id": 44800746,
      "title": "Open models by OpenAI",
      "url": "https://openai.com/open-models/",
      "by": "lackoftactics",
      "timeISO": "2025-08-05T17:02:02.000Z",
      "postSummary": "Открытые модели OpenAI\n\nПродвинутые модели с открытыми весами для любого кейса и запуска где угодно.\n\nСсылки:\n- Загрузить на Hugging Face\n- Исходники на GitHub\n- Попробовать демо\n\nМодели:\n- gpt-oss-120b — крупная модель для дата-центров и мощных ПК/ноутбуков.\n- gpt-oss-20b — средняя модель, работает на большинстве ПК/ноутбуков.\n\nПреимущества:\n- Разрешительная лицензия: Apache 2.0 — свободная разработка, без копилефта и патентных рисков; подходит для экспериментов, кастомизации и коммерческого использования.\n- Для агентных задач: сильное следование инструкциям и работа с инструментами в ходе рассуждений (веб-поиск, запуск Python-кода).\n- Глубокая настраиваемость: выбор уровня «усилия рассуждений» (низкий/средний/высокий) и полно-параметрический финтюнинг под ваш кейс.\n- Полная «цепочка рассуждений»: доступна для удобной отладки и повышения доверия к ответам.\n\nИнтерактивное демо:\n- Простой playground для запуска обеих моделей в браузере.",
      "commentsSummary": "- Обсуждение вокруг релиза open-weight моделей OpenAI (gpt-oss 20B и 120B): многие считают их конкурентными с о3/о4-мини и лучшими среди открытых, с хорошими бенчмарками (MMLU, GPQA), хотя ждут независимых сравнений.  \n- Практика: 20B уже успешно гоняют локально на Mac (M1/M3) и телефонах; есть поддержка в llama.cpp, Ollama, LM Studio; отмечают быстрый инференс на Groq/Cerebras через OpenRouter, но возможны долгие префилы при больших контекстах.  \n- Техдетали: стандартный GQA, MoE с низким числом активных параметров для скорости; Harmony формат ответов, растущая ставка OpenAI на Rust (harmony, tiktoken, части Codex); частично MXFP4, пока без sm120 для RTX 50xx.  \n- Мнения разнятся: часть хвалит OpenAI за «настоящую» открытость и полезные инструменты (инструкции, датасеты, фт), другие видят стратегический ход перед большим закрытым релизом и попытку задать «пол» рынка.  \n- Применение и экономика: растет интерес к гибридным архитектурам — локальная модель решает простое и готовит контекст, а облачная — сложное; спорят, выгоднее ли самохостинг 20B при высокой конкуренции цен.  \n- Ограничения: есть жалобы на галлюцинации у 120B на фактических запросах и на резкую/перекалиброванную безопасность; производительность варьируется по железу (некоторые GPU дают неожиданные результаты).  \n- Общий вывод: релиз может сместить баланс в пользу открытых моделей на рынке, ускоряя локальные и дешевые пайплайны, но требуется больше независимых бенчмарков и доработок инференса/совместимости.",
      "score": 2075,
      "commentsCount": 840,
      "hnUrl": "https://news.ycombinator.com/item?id=44800746",
      "domain": "openai.com"
    },
    {
      "id": 44816977,
      "title": "The History of F1 Design",
      "url": "https://www.espn.com/espn/feature/story/_/id/43832710/how-f1-evolved-1950-where-headed-2026",
      "by": "anonyonoor",
      "timeISO": "2025-08-06T20:01:37.000Z",
      "commentsSummary": "- Обсуждение сосредоточено на статье об истории F1 с красивой графикой, но большинство жалуется на «скролл-джек» и ломкий интерактив: у многих страница не прокручивается или открывается пустой блок (особенно в Firefox с блокировкой автоплей), ломается баннер cookies.  \n- Часть пользователей отмечает, что на iOS/iPad всё работает и выглядит впечатляюще: аккуратные слои иллюстраций и параллакс, «арт-директорская» подача.  \n- Много критики за контентные решения: пропущена эпоха доминирования Ферстаппена и RB19, спорны выборы вроде Prost вместо Senna и отсутствие культовых машин (например, MP4/4).  \n- Обсуждают техническую историю F1: запрещённые инновации (активная подвеска, «ground skirts», доп. педали тормоза), ссылки на FW14 и интерес к инженерной стороне.  \n- Есть ностальгические комментарии о прошлых гонщиках и обсуждение звука моторов (V10/V12), впечатления от громкости на трассе.  \n- Советы по материалам: книги Адриана Ньюи «How to Build a Car», Росса Брауна «Total Competition», «The Mechanic» Марка Присли.  \n- Предлагают решения: режим чтения в Firefox, инкогнито, отключить адблокер; просят добавить переключатель на «обычный» макет без навязчивого скролла.",
      "score": 62,
      "commentsCount": 55,
      "hnUrl": "https://news.ycombinator.com/item?id=44816977",
      "domain": "espn.com"
    },
    {
      "id": 44820619,
      "title": "Actual LLM agents are coming",
      "url": "https://pleias.fr/blog/blogactual-llm-agents-are-coming",
      "by": "whoami_nr",
      "timeISO": "2025-08-07T04:38:08.000Z",
      "postSummary": "Агенты повсюду, но самое важное развитие в области агентных LLM почти не замечено.\n\nВ январе 2025 OpenAI выпустила DeepResearch — специализированный вариант O3 для веб- и документного поиска. Благодаря обучению с подкреплением на задачах браузинга модель умеет планировать стратегию поиска, сверять источники и нишевые факты по промежуточной обратной связи. Claude Sonnet 3.7, похоже, применяет тот же рецепт для кода и превосходит оркестровки прошлых моделей на длинных цепочках программных задач. Как метко сказано: «LLM‑агенты могут работать над длинными многошаговыми задачами».\n\nЭто ставит вопрос: что такое LLM‑агенты? Anthropic определяет их как системы, где LLM сами направляют процессы и использование инструментов, контролируя способ выполнения задач. В отличие от «наших» систем с заранее прописанными кодовыми путями. Модные workflow‑агенты вроде Manus AI страдают старыми проблемами AutoGPT, особенно в поиске:\n- Не умеют планировать и застревают.\n- Плохо держат задачу дольше 5–10 минут.\n- Длинные действия рушатся из‑за накопления ошибок.\n\nДалее — краткий разбор нового сильного определения агентов, с опорой на крупные лаборатории, открытые репликации и немного спекуляций.\n\nГорький урок простых LLM‑агентов\n--------------------------------\nКлассические агенты живут в ограниченных средах: лабиринт, физика, правила игры. Они ищут оптимальные пути, запоминают ходы, вырабатывают эвристики — это и есть «поиск». История алгоритмов поиска (A*, Q*) иллюстрирует процесс проб и ошибок.\n\nБазовые языковые модели устроены наоборот:\n- Агенты запоминают среду; базовые модели зависят от окна контекста.\n- Агенты ограничены рациональностью; LLM генерируют правдоподобный текст без жестких гарантий, могут «съезжать» по стилю.\n- Агенты планируют надолго и умеют бэктрекать; LLM быстро насыщаются на многошаговом рассуждении и связаны правилами текста, а не среды.\n\nПопытка «примирения» через заранее прописанные промпты и правила ведет к Горькому уроку Саттона: встраивание знаний помогает сразу, но в долгую даёт плато и мешает прогрессу. «Мы должны усвоить, что построение систем на том, как нам кажется мы думаем, не работает в долгосрочной перспективе… прорывы приходят не от ручного знания, а от методов, масштабируемых с вычислениями и данными».",
      "commentsSummary": "- Автор согласен, что прежние методы обучения языковых моделей перестали быть эффективными.  \n- Он с друзьями ищет новые подходы к обучению моделей.  \n- В качестве перспективного направления он выделяет топологию как следующий прорыв в архитектуре ЯМ.  \n- Приглашает заинтересованных к обсуждению и сотрудничеству.",
      "score": 10,
      "commentsCount": 1,
      "hnUrl": "https://news.ycombinator.com/item?id=44820619",
      "domain": "pleias.fr"
    },
    {
      "id": 44808794,
      "title": "I gave the AI arms and legs then it rejected me",
      "url": "https://grell.dev/blog/ai_rejection",
      "by": "serhack_",
      "timeISO": "2025-08-06T07:25:43.000Z",
      "postSummary": "- Сгенерированное ИИ изображение, где ИИ руками «отвергает» меня. Очень мета.\n\nВ октябре 2024 Anthropic представила «Claude Computer Use», позволяющую ИИ управлять компьютером, копировать данные из браузера в таблицы и т.п. Я поддерживаю библиотеку для управления компьютером и этой весной решил разобраться, как они это делают. К моему удивлению, Anthropic использует мою библиотеку enigo.\n\nПроверить использование enigo в Claude Desktop для macOS можно так:\n- 7z x Claude.dmg\n- perl -nle 'print $& while /.{0,67}enigo.{0,30}/g' Claude/Claude.app/Contents/Resources/app.asar.unpacked/node_modules/claude-native/claude-native-binding.node\nВывод содержит путь к enigo-0.2.1/src/macos/macos_impl.rs\n\nНа Windows:\n- 7z x Claude-Setup-x64.exe\n- 7z x AnthropicClaude-0.11.6-full.nupkg\n- perl -nle 'print $& while /.{0,75}enigo.{0,26}/g' Claude-Setup-x64/AnthropicClaude-0.11.6-full/lib/net45/resources/app.asar.unpacked/node_modules/claude-native/claude-native-binding.node\nВывод указывает на enigo-0.2.1/src/win/win_impl.rs\n\nЯ горжусь, что enigo дорос до продакшена у компании с огромным бюджетом. Эмуляция ввода сложна из‑за слабой документации и платформенных особенностей. На мой взгляд, enigo — отличный выбор: работает на Windows, macOS, *BSD и Linux (Wayland, X11, libei) без root; написан на Rust (безопасность памяти, высокая скорость); самый популярный на crates.io (~300k загрузок, 1200+ звёзд). И всё же тревожно, что мой хобби‑проект установлен на тысячах устройств.\n\nСколько я на этом заработал? Нисколько: enigo под MIT‑лицензией — можно бесплатно использовать. Взамен — звёзды на GitHub и счётчик загрузок.\n\nИнтересно, что Claude Desktop — Electron‑приложение, но есть только для macOS и Windows. Сообщество запустило его на Linux, заменив вызовы enigo заглушками, хотя enigo кроссплатформенна — любопытный выбор.\n\nЧерез знакомых я узнал об открытой роли в команде, делавшей секретную, ещё не выпущенную функцию Claude Desktop с enigo. Подал заявку, ждал. В итоге пришло письмо: команда не успевает рассматривать дополнительные заявки.\n\nЯ бы с радостью поработал в Anthropic: сделать аналог Computer Use, довести Claude Desktop до Linux, вложить свой опыт в эмуляцию ввода и полноценно отполировать enigo, чтобы Anthropic концентрировалась на моделях, а не на капризах ввода.\n\nВ целом я счастлив, что enigo в Claude Desktop, и всем об этом рассказываю. Забавно думать, что я метафорически дал Claude руки и ноги — и получить отказ. Письмо написал человек или сам Claude? По крайней мере, теперь я, наверное, в безопасности…",
      "commentsSummary": "- Обсуждение крутится вокруг автора OSS-библиотеки enigo, которую использует Claude Desktop: он подал заявку в Anthropic, но получил автоматический отказ без рассмотрения, что вызвало возмущение у комментаторов.  \n- Многие считают, что HR/ATS и автоматизация отбора убивают шанс на качественные кандидаты; советуют просить «тёплый интро» к менеджеру нанимающей команды вместо подачи через портал.  \n- Обсуждается несправедливость: компании пользуются открытым кодом без благодарности, контрибьютов или оплаты; звучат призывы хотя бы предложить автору консультацию или интервью.  \n- Тема лицензий: часть выступает против слишком разрешительных (MIT), предлагая GPL/MPL/EUPL или «fair source», чтобы стимулировать возврат изменений или ограничить корпоративное использование.  \n- Предполагаемые причины отказа: геолокация/визы (автор из Мюнхена), переполненная воронка кандидатов, несоответствие профиля AI-ролям, «низкопрофильные» предпочтения некоторых команд.  \n- Общий вывод: современный найм в IT часто нерационален; чтобы «пробиться», полезны публичные посты, прямые контакты и нетворкинг, а открытое ПО без защиты может усиливать дисбаланс в пользу бигтеха.  \n- Побочный тезис: пересмотр отношения к open source и моделям монетизации может быть необходим, чтобы разработчики не работали бесплатно на крупные корпорации.",
      "score": 752,
      "commentsCount": 372,
      "hnUrl": "https://news.ycombinator.com/item?id=44808794",
      "domain": "grell.dev"
    },
    {
      "id": 44818734,
      "title": "Git-fetch-file – Sync files from other repos with commit tracking and safety",
      "url": "https://github.com/andrewmcwattersandco/git-fetch-file",
      "by": "andrewmcwatters",
      "timeISO": "2025-08-06T22:45:27.000Z",
      "commentsSummary": "- Обсуждение о способах заимствования отдельных файлов из других репозиториев без тяжелых механизмов вроде git submodules или экосистемных менеджеров зависимостей.  \n- Один участник делится кейсом с бинарными тестовыми данными из апстрим-репо и идеей валидации через CI по контрольным суммам вместо субмодулей.  \n- Автор топика хочет удобный способ «прикреплять» конкретные файлы из чужих репозиториев с возможностью пиновать версию и без притягивания лишнего.  \n- Пользователи выражают благодарность и интерес: для некоторых это «именно то, что нужно».  \n- Звучат креативные предложения — например, файловая система FUSE поверх такого решения.  \n- Один комментатор просит уточнить поведение команды push (включая режим —dry-run) и судьбу самих файлов vs. метаданных (.git-remote-files) в коммитах.  \n- Автор позитивно реагирует на идеи и обратную связь, обещая улучшения.",
      "score": 37,
      "commentsCount": 14,
      "hnUrl": "https://news.ycombinator.com/item?id=44818734",
      "domain": "github.com"
    }
  ]
}