{
  "id": 44819968,
  "lang": "ru",
  "summary": "- В день выхода открытой модели вроде gpt-oss-120b мы сразу ускоряем её для клиентов, как партнёры запуска OpenAI. К концу дня запуска стали лидерами на NVIDIA по латентности и пропускной способности по данным OpenRouter.\n\n- Быстрая оптимизация обеспечена гибким стеком инференса и экспертизой команды; за время написания поста прибавили ещё ~100 ток/с при 100% аптайме.\n\n- Работы включали:\n  - Тесты и бенчмарки в TensorRT-LLM, vLLM и SGLang.\n  - Совместимость с архитектурами Hopper и Blackwell.\n  - Интеграцию с нашим стеком (в т. ч. NVIDIA Dynamo).\n  - Оптимизации: маршрутизация с учётом KV-кэша, спекулятивная генерация с Eagle.\n\nШаг 1: Первый инференс\n- Запускаем базовый инференс в любом доступном фреймворке и на нужных GPU/серверных уровнях.\n- Параллелим работу: одни пробуют vLLM и SGLang, другие — TensorRT-LLM; быстрее всего взлетел TensorRT-LLM.\n- Важно обслуживать модель и на Hopper (H100), и на Blackwell (B200) для широкой доступности и максимальной скорости.\n- Гибкость рантайма позволяет быстро переключать инструменты и обновлять матрицу поддержки.\n\nШаг 2: Исправление багов совместимости\n- Новые архитектуры приводят к тонким несовместимостям; GPT OSS добавил, например, Harmony — новый формат ответов.\n- Итеративно чиним и валидируем на скорость и корректность; по возможности контрибутим обратно в open source.\n- Благодаря сообществу есть несколько отличных путей запуска GPT OSS, проблемы быстро выявляются и чинятся.\n\nШаг 3: Оптимизация конфигурации\n- Хотя GPT OSS 120B можно запустить на одном H100, оптимально масштабировать на 4–8 GPU для лучшей латентности/throughput.\n- Рассмотрены два подхода параллелизма для MoE: тензорный и экспертный. Тензорный даёт меньшую задержку, экспертный — выше системную пропускную способность. Мы выбрали тензорный, так как приоритет — латентность.\n- Приняли MoE Backend в TensorRT-LLM (поддерживается на Blackwell, не на Hopper), который добавляет более быстрые CUDA-ядра и превосходит предыдущие решения.",
  "inputHash": "c7498336e214000f7cdbf431a49fe7c9c9e44c4a223008cee914ba9aeaebc8ad",
  "model": "openrouter/horizon-beta",
  "createdISO": "2025-08-07T08:56:24.580Z"
}