{
  "id": 44900340,
  "lang": "ru",
  "summary": "**Краткий перевод и сжатие**\n\n**Суть претензии к статье ASU**  \nАвторы обучили крошечную модель (600 k параметров) решать алфавитные задачи вида «A B C D [M1] → B C D E» и выводить цепочки мыслей. Они показали, что при малейшем сдвиге распределения (новая последовательность операций, лишний токен, увеличение длины) модель ломается. Отсюда вывод: «рассуждения» — это лишь копирование шаблонов из обучения, а не логический вывод.\n\n**Почему это неубедительно**  \n1. **Без языка нет рассуждений**  \n   Настоящие цепочки мыслей полны «подожди», «а если…» и самокоррекции. Задача «сдвинь буквы» — это вычисление, а не рассуждение.  \n2. **Слишком маленькая модель**  \n   У 600 k параметров просто не хватит «мозгов» разложить сложное правило на части. Способность к рассуждению появляется у крупных моделей.  \n3. **Сравнение с человеком отсутствует**  \n   Люди тоже путаются при новых формулировках и учатся на примерах. Без измерения человеческих ошибок утверждение «это мираж» не имеет опоры.\n\n**Вывод**  \nНа игрушечной задаче нельзя судить о природе рассуждений в больших языковых моделях.",
  "inputHash": "7ada00d8ef47b701d6c72aa74f34d889bfbd7fb4c5624b7171c0d451d8219322",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-14T15:27:26.014Z"
}