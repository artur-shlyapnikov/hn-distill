{
  "id": 44902148,
  "lang": "ru",
  "summary": "- Команда выпустила сверхкомпактную 270-миллионную модель Gemma 3 (241 МБ), рассчитанную на дообучение под конкретные задачи.  \n- Пользователи отмечают скорость и малый вес, но и «галлюцинации» при общении; зато хорошо работает суммаризация, автодополнение и перевод с редких языков.  \n- Популярные идеи для fine-tune: классификация/тегирование статей, NER, сегментация событий в потоках данных, «edge»-задачи на телефонах и ноутбуках.  \n- Появились первые демо на Android и iPhone (≈ 80 ток/сек), но для продакшена нужен дообученный вариант.  \n- Сообщество просит туториалы по локальному fine-tune, примеры дообученных весов и более ясные бенчмарки.",
  "sampleComments": [
    44902240,
    44903731,
    44902980,
    44903495,
    44904181
  ],
  "inputHash": "226f5baf16c80a6af2243ee238a38280d8a731ab3dd12fb14508fff4a8d20ef6",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-15T03:25:49.279Z"
}