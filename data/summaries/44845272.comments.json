{
  "id": 44845272,
  "lang": "ru",
  "summary": "- Пользователи жалуются на то, что Jan не умеет параллельно общаться с несколькими моделями и «зависает» при переключении между чатами.  \n- Частые проблемы с запуском: не стартует llama-server, требует 30 ГБ ОЗУ/VRAM даже для 30B-моделей, в то время как Ollama справляется на 10 ГБ VRAM.  \n- UI ранее был багованным, но, по отзывам, улучшился; приложение на Tauri многим кажется «глючным» в Linux.  \n- Jan позиционируется как «дружелюбный» десктоп-аналог LM Studio с поддержкой удалённых провайдеров, но при этом не всегда корректно коннектится к локальному Ollama (нужны переменные `OLLAMA_HOST` и `OLLAMA_ORIGINS`).  \n- Некоторые участники подчёркивают, что принципы проекта звучат красиво, но команда из Сингапура/Вьетнама «исчезла» после обещаний, что ставит под сомнение их реальное следование этим принципам.",
  "sampleComments": [
    44846669,
    44847724,
    44845613,
    44846208,
    44847197
  ],
  "inputHash": "2df517d5ac3468daecb595f626a8f42482914cdd4b00a6ae8a3d0e75302b1f47",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-09T20:16:10.749Z"
}