{
  "id": 44813627,
  "lang": "ru",
  "summary": "- Обсуждают малый открытый модель Qwen3-4B (в т.ч. «Thinking/Instr»), её доступность в LM Studio и на Hugging Face, возможность запуска на ПК, Mac (mlx 4–8 бит) и даже на слабом железе; полный контекст 262k токенов может требовать десятки ГБ RAM.  \n- По отзывам: модель быстрая, компактная и по многим бенчмаркам заметно улучшена; в ряде метрик приближается к старой 30B MoE-версии при ~7,5× меньшем размере, но новая 30B-A3B всё же сильнее.  \n- Практический опыт: хороша в анализе задач, но встречаются галлюцинации в предложениях/советах.  \n- Идёт сравнение с Gemma 3n: на общих тестах (напр. AIME, LiveCodeBench) Qwen3-4B-Thinking показывает значительно более высокие результаты.  \n- Обсуждают надёжность метрик: многие бенчмарки оцениваются GPT‑4.1; возникают вопросы о возможной адаптации моделей под «угодные» ответы и нехватке ручного аудита.  \n- Для «народных» оценок советуют LM Arena, Artificial Analysis, OpenRouter stats и r/LocalLlama, но подчёркивают ограниченную надёжность толпы.  \n- Вопросы пользователей: как соотносится контекст и RAM; варианты для iPhone/Apple Silicon; ссылки на готовые gguf и mlx-сборки предоставлены.",
  "sampleComments": [
    44816148,
    44815355,
    44814443,
    44814505,
    44814376
  ],
  "inputHash": "8ad64febfc2c15b9adf467a125b8d5a9a4b40a05aae7dff162229b3dea67720a",
  "model": "openrouter/horizon-beta",
  "createdISO": "2025-08-07T12:40:25.969Z"
}