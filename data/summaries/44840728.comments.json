{
  "id": 44840728,
  "lang": "ru",
  "summary": "- OpenAI и Google тратят десятки миллиардов долларов на GPU-кластеры (H100 по 20–40 k$ за штуку, миллионы долларов за стойку) и инфраструктуру, чего нет у обычного пользователя.  \n- Основной «секрет» — масштабное батчирование запросов: одновременная обработка тысяч пользователей позволяет заполнять GPU на 100 % и амортизировать стоимость.  \n- Используются оптимизации: Mixture-of-Experts, спекулятивное декодирование, KV-кэш, конвейерная обработка слоёв, bare-metal CUDA-оптимизации.  \n- Большинство пользователей ChatGPT активны лишь доли процента времени, поэтому общая нагрузка оказывается меньше, чем кажется по 700 млн «weekly users».  \n- В итоге экономия на масштабе + параллельная обработка дают 3–6 порядков эффективности по сравнению с локальным запуском одного запроса.",
  "sampleComments": [
    44840935,
    44840970,
    44840989,
    44841828,
    44844180
  ],
  "inputHash": "fb1e359922908ef4c24ba8f9bdb92c9c46fbb70818ef78c2f80ecc4deece2321",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-09T11:24:29.503Z"
}