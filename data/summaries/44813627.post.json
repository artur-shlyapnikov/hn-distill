{
  "id": 44813627,
  "lang": "ru",
  "summary": "- За 3 месяца мы масштабировали «мышление» Qwen3-4B: выше качество и глубина рассуждений. Представляем Qwen3-4B-Thinking-2507:\n  - Существенно лучше на задачах логики, математики, науки, кода и академических бенчмарках.\n  - Улучшены общие навыки: следование инструкциям, инструменты, генерация текста, согласование с предпочтениями.\n  - Расширено понимание длинного контекста: 256K.\n  - Версия с увеличенной длиной «мышления» — рекомендуем для сложных задач.\n\n- Обзор модели:\n  - Тип: Causal LM; Этапы: пре-/посттренировка.\n  - Параметры: 4.0B (без эмбеддингов 3.6B); Слоёв: 36; GQA: 32 Q / 8 KV.\n  - Контекст: 262 144 токенов.\n  - Поддерживается только режим «thinking»; enable_thinking=True не нужен. Шаблон чата добавляет <think> автоматически; нормален вывод, содержащий только </think>.\n  - Подробности: блог, GitHub, документация.\n\n- Производительность (избранное):\n  - Знания: MMLU-Pro 74.0; MMLU-Redux 86.1; GPQA 65.8.\n  - Рассуждения: AIME25 81.3; HMMT25 55.5; LiveBench 71.8.\n  - Код: LiveCodeBench v6 55.2; CFEval 1852; OJBench 17.9.\n  - Алайнмент: IFEval 87.4; Arena-Hard v2 34.9; WritingBench 83.3.\n  - Агенты: BFCL-v3 71.2; TAU1/2 — лучшие в ряде доменов.\n  - Мультиязычность: MultiIF 77.3; PolyMATH 46.2.\n  - Примечания: выигрыш на Arena — GPT-4.1; для сложных задач — вывод до 81 920 токенов, иначе 32 768.\n\n- Быстрый старт:\n  - Нужен свежий transformers (иначе KeyError: 'qwen3').\n  - Пример кода: загрузить AutoTokenizer/AutoModelForCausalLM, применить chat template, сгенерировать до 32 768 новых токенов, выделить «thinking»-часть до токена </think> (ID 151668) и основное содержимое.\n  - Для продакшна: sglang>=0.4.6.post1 или vllm>=0.8.5; можно поднять OpenAI-совместимый сервис.",
  "inputHash": "bd15b587877a883b56c8910a6e3ad5d56427e80c43ccfcab53fe2ba318cad9d4",
  "model": "openrouter/horizon-beta",
  "createdISO": "2025-08-07T12:40:18.849Z"
}