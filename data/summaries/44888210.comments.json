{
  "id": 44888210,
  "lang": "ru",
  "summary": "- Все LLM рассматриваются как потенциально скомпрометированные: риски варьируются от утечки данных до «ошибок» и prompt-инъекций.  \n- Обсуждаются атаки на этапе предобучения (data poisoning) и возможные «бэкдоры» в моделях, особенно в контексте геополитики.  \n- Подчеркивается, что «open weights» ≠ «open source», а скрытый CoT усиливает беспокойство.  \n- Утверждение «человек в цикле делает безопасно» подвергается сомнению: люди тоже ошибаются, но LLM действуют быстрее и без усталости.  \n- Смягчающие аргументы (аналогия с gain-of-function, «vibe-coding») не отменяют главного вывода: доверие к LLM должно быть минимальным.",
  "sampleComments": [
    44888370,
    44893792,
    44889064,
    44888357,
    44891549
  ],
  "inputHash": "cc9f21637e401f903c3bce476f1a9fc3b8e00dd304de77a6c0eccae77f4096d3",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-13T21:24:23.117Z"
}