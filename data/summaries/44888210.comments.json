{
  "id": 44888210,
  "lang": "ru",
  "summary": "- Все LLM рассматриваются как потенциально скомпрометированные: они могут утечь данные, удалять базы или «ошибаться» из-за prompt-injection и галлюцинаций.  \n- Обсуждаются атаки на этапе дообучения: конкуренты могут «отравлять» общедоступные данные, чтобы снизить качество чужих моделей.  \n- Недоверие вызывают модели, скрывающие цепочку мыслей (CoT), и возможные «бэкдоры» в китайских LLM для обхода систем безопасности.  \n- Участники спорят, достаточно ли «человек в цикле»: люди тоже ошибаются, но LLM действуют быстрее и без усталости.  \n- Подчёркивается, что «open weights» ≠ «open source», и проблема доверия к LLM глобальна, а не ограничена одной страной.",
  "sampleComments": [
    44888370,
    44889064,
    44891549,
    44888357,
    44888283
  ],
  "inputHash": "04f9f81e31422bf02e905dd71c6fc06d3c085583fa4055212a96a5ad679d0093",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-13T19:20:31.733Z"
}