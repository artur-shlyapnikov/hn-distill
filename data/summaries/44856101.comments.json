{
  "id": 44856101,
  "lang": "ru",
  "summary": "- Участники сомневаются, что диффузионные модели хуже запоминают данные и требуют на 16–4700× больше FLOPs при генерации, чем авторегрессивные.  \n- Некоторые считают, что метрики и «in/out of distribution» в работе описаны расплывчато, без указания состава обучающих данных.  \n- Предложено заменить диффузию на итеративную авторегрессию с «цепочкой мыслей», но критики отмечают, что CoT ≠ диффузия и рано «похороны» целому классу моделей.  \n- В обсуждении подчёркивают: KV-кэш нельзя использовать в диффузии, а дальнейшие эпохи обучения 1B-модели могли бы прояснить картину.",
  "sampleComments": [
    44857283,
    44856906,
    44857195,
    44858276,
    44860626
  ],
  "inputHash": "eac7722a91cd7b985abbdde483f8e7a3ef86d5e5839906406d4eee37d89d1dc5",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-11T12:56:02.136Z"
}