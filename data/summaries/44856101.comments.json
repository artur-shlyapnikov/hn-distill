{
  "id": 44856101,
  "lang": "ru",
  "summary": "- Участники обсуждают, почему диффузионные модели проигрывают авторегрессивным по потерям при одинаковом объёме токенов: версия — меньшая способность к запоминанию и отсутствие KV-кеша.  \n- Отмечают экспоненциальный рост FLOPs у диффузионных моделей при генерации длинных последовательностей (×16–4700) из-за их не-каузальной природы.  \n- Сомневаются в корректности выводов работы: неясны определения «in/out-of-distribution» и состав обучающих данных.  \n- Хотели бы видеть больше эпох обучения 1B-модели на 10B датасете, но сомневаются, что это радикально изменит картину.",
  "sampleComments": [
    44857283,
    44856906,
    44858276,
    44857195,
    44857412
  ],
  "inputHash": "d0497b07632cf4cbd008dbffe61f427b91a4ffc6f12eaf0b3faf4245b1595b17",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-10T23:23:33.890Z"
}