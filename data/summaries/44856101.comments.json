{
  "id": 44856101,
  "lang": "ru",
  "summary": "- Участники сомневаются, что диффузионные модели уступают авторегрессивным по памяти и вычислительной эффективности: FLOPs растут суперлинейно, KV-кэш недоступен.  \n- Некоторые считают, что стоит продолжить обучение 1B-модели на 10B токенов, поскольку улучшения продолжаются эпоха за эпохой.  \n- Поднимается вопрос корректности терминов «in/out of distribution» без раскрытия состава обучающих данных.  \n- Предложено заменить диффузионные модели на итеративную авторегрессию с chain-of-thought, но критики считают это преждевременным.",
  "sampleComments": [
    44857283,
    44856906,
    44858276,
    44857195,
    44860626
  ],
  "inputHash": "0238649c995b2f6ad38e40db050a03986e76a2d127514e2b035c3df9e8d321ab",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-11T09:35:06.010Z"
}