{
  "id": 44830418,
  "lang": "ru",
  "summary": "**Сжатая суть статьи**\n\nИдентификация нарушающей политику рекламы требует глубокого контекста и культурной чувствительности — сильные стороны LLM. Однако дообучение требует дорогих, качественных разметок, а политика и типы нарушений постоянно меняются. Мы предложили масштабируемый процесс активного обучения, который сводит объём данных с 100 000 до менее 500 примеров и повышает согласованность с экспертами до 65 %. В продакшене крупные модели используют в 10 000 раз меньше данных без потери качества.\n\n**Процесс курирования**\n1. Нулевой LLM размечает весь трафик (1).  \n2. Кластеризуем «нарушения» и «безопасные» примеры; пересечения кластеров указывают на неуверенность модели (2).  \n3. Внутри пересечений выбираем пары близких, но по-разному размеченных примеров (3).  \n4. Эксперты размечают приоритетные пары (4).  \n5. Полученные метки делятся: часть — для дообучения, часть — для оценки по двум метрикам: внутренняя согласованность экспертов и согласованность «модель ↔ человек». Итерации повторяются до плато.\n\n**Метрика**  \nИспользуем Cohen’s Kappa: 0 — случайное совпадение, >0,8 — отлично. Не требует «золотого стандарта».\n\n**Эксперименты**  \nСравнили Gemini Nano-1 (1,8 B) и Nano-2 (3,25 B) на двух задачах разной сложности. Базовые модели дообучались на ~100 k разметок краудсорсом. Курированные модели — на ~400 примерах за 6 итераций. Все модели вышли на плато, не догнав внутреннее согласие экспертов.",
  "inputHash": "8b19c03236111b221620f9dc3b5f3c8ac0a4791d77c076e9744983ab3929852b",
  "model": "moonshotai/kimi-k2",
  "createdISO": "2025-08-07T23:56:18.368Z"
}