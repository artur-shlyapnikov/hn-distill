{
  "id": 44854518,
  "lang": "ru",
  "summary": "- @antirez и другие приводят контрпримеры: даже крошечные трансформеры выучивают внутренние 8×8 «карты» позиций шахмат, а SOTA-модели действительно играют корректные ходы.  \n- @ordu, @skeledrew и @otabdeveloper4 спорят о «правильности» подхода: одни считают LLM «по-человечески» предиктивными, другие подчеркивают разницу в архитектуре и обучении.  \n- @ameliaquining выделяет единственное конкретное предсказание поста — «LLM никогда не справятся с большими кодовыми базами автономно» — и даёт ему 80 % на разобьются за два года.  \n- @libraryofbabel, @joe_the_user и @yosefk обсуждают интерпретабельность: наличие внутренних представлений не означает полноценной «модели мира», а измерения Elo и «автономность» нуждаются в точных определениях.  \n- @DennisP, @GaggiX, @og_kalu приводят ссылки на Genie-3, свежие arXiv-работы и видео, показывающие, что LLM (и мультимодальные модели) уже умеют играть в шахматы и кодить.",
  "sampleComments": [
    44885872,
    44885214,
    44881849,
    44857725,
    44859163
  ],
  "inputHash": "26080000e29b0c2a5cd16cd53187afc2e0224c2ebf55a5556ef157e1f93b6ffb",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-13T09:28:43.247Z"
}