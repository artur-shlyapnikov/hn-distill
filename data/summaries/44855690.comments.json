{
  "id": 44855690,
  "lang": "ru",
  "summary": "- GPT-OSS не впечатлил: в бенчмарках провал, при агентном использовании тормозит и зацикливается.  \n- Qwen3 (особенно 30-32 B) выигрывает по скорости, точности следования инструкции и «живости» кода; локально запускается даже на RTX 3090/32 ГБ ОЗУ.  \n- Архитектурных прорывов нет: обе модели берут один и тот же набор трюков (RoPE, SwiGLU, GQA, MoE), разница в основном в данных, RL и калибровке экспертов.  \n- MXFP4-квант и 5-битные варианты экономят память почти без потери качества, что делает Qwen3-coder 30B-A3B практичным выбором для локальной разработки.  \n- Сообщество делится конфигами под 12–20 ГБ VRAM и советует отказаться от GPT-OSS в пользу Qwen3 для повседневного кодинга.",
  "sampleComments": [
    44860707,
    44856128,
    44857190,
    44856661,
    44858834
  ],
  "inputHash": "58a97e906ca1752d7c4772a42f6efd8f44043a9c0f0f0b1c60a6dd657c23ab8f",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-11T11:23:20.311Z"
}