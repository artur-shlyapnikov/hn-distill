{
  "id": 44855690,
  "lang": "ru",
  "summary": "- Практически все участники сходятся: локальный Qwen3 (особенно 30–32 B) заметно точнее, быстрее и «органичнее» GPT-OSS.  \n- GPT-OSS 120 B/20 B проваливается на логических задачах и агентных сценариях, хотя иногда сравним по математике с DeepSeek R1.  \n- Различие скорее в данных, RL-тренировке и плотности модели: Qwen3 плотный, GPT-OSS — разреженный MoE, что даёт экономию, но не качество.  \n- Локальные 4–30 B варианты Qwen3 комфортно запускаются на 32 ГБ RAM/RTX 3090 и уже полезны в продакшене.  \n- Некоторые жалуются, что Qwen3 медленнее или плохо работает с diff-форматами, но общий консенсус: «если надо кодить локально — бери Qwen3».",
  "sampleComments": [
    44856128,
    44857190,
    44856661,
    44858834,
    44857029
  ],
  "inputHash": "70be888132d43db8ea97fedff86d7bc5defaed76907170d26d665de5d0bec4c2",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-11T02:07:35.737Z"
}