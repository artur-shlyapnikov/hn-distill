{
  "id": 44855690,
  "lang": "ru",
  "summary": "- Практически все участники сходятся: локальная Qwen3 (особенно coder-варианты 30–32 B) заметно быстрее и точнее следует инструкциям, чем GPT-OSS любого размера.  \n- GPT-OSS критикуют за «залипание» на простых запросах, провалы в логических задачах и слабую пригодность для агентного кода.  \n- Скорость/память: qwen3-coder-30b-a3b-5bit укладывается в 20 ГБ RAM, а 4-битные квантизации Ollama ещё меньше, что делает модель доступной на 32-ГБ Mac.  \n- Общее мнение: различия реже в архитектуре, чем в данных, RL-тюнинге и синтетических датасетах; китайские модели быстро догоняют или перегоняют западные.",
  "sampleComments": [
    44857190,
    44856128,
    44856661,
    44857029,
    44858198
  ],
  "inputHash": "56a81e5438d228a376c784e204be9e67701aef391a5fff6fce00b52888e93158",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-10T22:22:43.830Z"
}