{
  "id": 44798624,
  "lang": "ru",
  "summary": "- Обсуждают идею добавить LLM «токен backspace», чтобы модель могла откатываться назад, а не только дописывать текст.  \n- @dev_hugepages привёл статью, где такой механизм уже исследуется в рамках IL/RL.  \n- @_diyar и @imtringued указывают, что в текущих LLM контекст линейный и append-only, поэтому простой backspace неэффективен и требует O(n²) ресурсов.  \n- namibj замечает, что кэшировать промпт можно, но кэш сгенерированных токенов придётся сбрасывать.  \n- Параллельно отмечают, что люди и диффузионные модели решат задачи итеративно, в отличие от «один проход сверху-вниз» у LLM при редактировании кода.",
  "sampleComments": [
    44844798,
    44843910,
    44844174,
    44842969,
    44846153
  ],
  "inputHash": "e528adf950e2595a1a413cd84003a9720bbedc0734d5cd57369d292159b2acf0",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-09T13:37:16.616Z"
}