{
  "id": 44827862,
  "lang": "ru",
  "summary": "- **Цель**: создать единый фреймворк для тестов производительности Ollama на двух конфигурациях:  \n  1) настольная материнка (1×CPU, 1×GPU, 128 ГБ ОЗУ);  \n  2) кластер из 4 узлов (по 64 ГБ ОЗУ, 1×GPU, 10 GbE).  \n\n- **Методика**  \n  - Одинаковые образы Docker/Podman на обеих платформах.  \n  - Набор моделей: llama3.1:8b, codellama:13b, mistral:7b, qwen2.5:32b.  \n  - Метрики: t/s, TTFT, TPS, Watts, $/1k токенов.  \n  - Повторять 3×, усреднять, выводить ±σ.  \n\n- **Автоматизация**  \n  - Ansible-playbook разворачивает Ollama, node-exporter, prometheus, grafana.  \n  - Скрипт `run-suite.sh` последовательно запускает каждую модель с 512, 2 048, 4 096 токенов ввода/вывода.  \n  - Результаты пишутся в CSV и публикуются в PR как `results-<platform>-<date>.md`.  \n\n- **Сравнение**  \n  - Построить графики «токен/с vs. Watts» и «$/1k токенов vs. модель».  \n  - Выделить break-even точку, где кластер начинает выигрывать по стоимости при одновременной обработке ≥3 моделей.",
  "inputHash": "a27dff358728f81b99563e31b9281280a34e060c3a80434c0d9ee797a79ffc89",
  "model": "moonshotai/kimi-k2",
  "createdISO": "2025-08-07T23:55:47.920Z"
}