{
  "id": 44847741,
  "lang": "ru",
  "summary": "- Основной спор: автор утверждает, что «учиться использовать LLM в коде тривиально», но большинство комментаторов считает это ошибкой — нужны месяцы экспериментов, чтобы понять, что делегировать, как формулировать контекст и как контролировать вывод.  \n- Многие предупреждают: бездумное доверие LLM приводит к ужасному коду и техническому долгу; эффективность появляется только после итераций «делегируй-проверь-откати».  \n- Утверждение, что LLM «заставляют» выбирать только мейнстрим-стек, опровергают разработчики на Clojure, D и других нишевых языках — модели помогают, если правильно подать контекст.  \n- Практики делятся опытом: сначала самостоятельно проектируют архитектуру, затем LLM ускоряет рутинные задачи; кто-то использует Claude-Code в VS Code с диффами, кто-то предпочитает OpenAI Codex или Kilo Code.  \n- Общий вывод: LLM — полезный инструмент, но не волшебная палочка; требуется навык, дисциплина и понимание границ возможностей модели.",
  "sampleComments": [
    44856160,
    44849147,
    44853504,
    44848846,
    44856223
  ],
  "inputHash": "d516a7eb5348db40dea41c204d831e72c0e53bbb3cd7c3c5205225a27be4407e",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-10T17:23:24.980Z"
}