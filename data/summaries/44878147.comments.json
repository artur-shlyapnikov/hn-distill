{
  "id": 44878147,
  "lang": "ru",
  "summary": "- Anthropic открыла 1-миллионный контекст в API, но цена растёт квадратично и доступен только высоким тир-4.  \n- Пользователи жалуются: при >100–200 k токенов качество падает, модель «теряется» в шуме и дорого стоит.  \n- Рабочий хак — сохранять контрольные точки и «rewind» в Claude Code, чтобы не переплачивать за токены.  \n- Лучше всего LLM помогают в «зелёном поле» и при быстрых «how-to», но масштабные кодовые базы всё ещё требуют ручной разметки и RAG.  \n- Итог: 1 M — маркетингово круто, но без улучшенного ретривала и скорости это как «отдать джуну весь репозиторий и сказать разбирайся».",
  "sampleComments": [
    44890464,
    44878643,
    44879053,
    44878453,
    44881226
  ],
  "inputHash": "18b1353b497efd4a72f4c3cd1607130e2cc17e6d958321de5cf4d9ffcbeefbb9",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-13T16:28:51.969Z"
}