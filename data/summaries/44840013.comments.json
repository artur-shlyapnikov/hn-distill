{
  "id": 44840013,
  "lang": "ru",
  "summary": "- Проект фокусируется на локальной «песочнице» для приватного AI-воркспейса с инструментом coderunner.  \n- Основной узкий момент — железо: 80B-модели требуют 80+ ГБ RAM, что дорого и редко для потребителей.  \n- Дополнительно обсуждают RAG-знания (личные файлы, e-mail) и проблему масштабного векторного хранилища.  \n- Пользователи делятся опытом: Ollama/Open-WebUI на M1 32 ГБ, RTX 3090/4090, NAS-контейнеры, Kasm, MLX, Cerebras/Groq.  \n- Некоторые просят Docker-вариант `docker compose up -d`, другие спорят, стоит ли доверять облачным «быстрым» провайдерам.",
  "sampleComments": [
    44841209,
    44841291,
    44845799,
    44840240,
    44840833
  ],
  "inputHash": "6a7dc904eb2071f3cf03f047d72dad03623825827de32e79fa923d58bbc0ed9e",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-10T13:38:08.589Z"
}