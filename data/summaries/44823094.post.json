{
  "id": 44823094,
  "lang": "ru",
  "summary": "- Пару дней назад OpenAI впервые за долгое время выпустила открытый языковой модуль. Сроки откладывали из‑за «безопасности». Они много говорят о безопасности — удобно для пиара: на вопросы об этике можно показывать на эти работы и будто бы закрывать тему. Но под «этикой» люди чаще имеют в виду не мат, фильтры и троллейбусные дилеммы, а реальность: управление и подотчётность, использование данных, перераспределение власти и денег, влияние на занятость. Вопрос: что делают люди, управляющие моделями, и как это влияет на общество?\n\n- Такой подменой уже пользовались в теме приватности. В 1990‑х телемаркетинг покупал клиентские базы у компаний, которые не понимали ценность данных. Возмущение породило шаблон: «мы не делимся данными с третьими сторонами». Непроизнесённая часть: «им проще купить нас целиком — это и есть стратегия выхода». Сегодня, говоря о приватности, людей волнует, что делает с их данными именно текущая компания/приложение: школьное, парковочное, для проезда. Но разговор сводят к «чтобы посторонние не получили доступ», а не к «что конкретно делает эта компания». В итоге возникает индустрия соответствия и тестирования, честно решающая второстепенную задачу, чтобы не решать главную. Как политик, который на «поднимете ли налоги?» отвечает «мы вырастим экономику».\n\n- С ИИ иначе лишь потому, что тема новая, и мы опирались на sci‑fi мысленные эксперименты. Они увлекательны и безопасны для бизнеса: никто не хочет «бумажкоскрепочную» катастрофу или симуляцию Black Mirror, а обсуждать это — выгодный пиар и бесплатное внимание прессы. Но такое сужение смещает фокус с реальных последствий и распределения ответственности на удобные, далекие от практики сценарии.",
  "inputHash": "ba248dfe4de51b8bb6e3964852574e956901fb741179a528366bf6b12a8316c4",
  "model": "openrouter/horizon-beta",
  "createdISO": "2025-08-07T12:24:08.302Z"
}