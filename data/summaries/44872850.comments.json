{
  "id": 44872850,
  "lang": "ru",
  "summary": "- Критика: выводы из «игрушечных» GPT-2 (4 слоя, 32 скрытых) не обобщаются на промышленные LLM.  \n- Участники сомневаются, что LLM умеют рассуждать; считают их «базой знаний без понимания».  \n- Примеры задач (вращение букв) подчеркивают слабость токен-моделей.  \n- Некоторые утверждают: статья устарела, игнорирует RL и переоценивает SFT.  \n- Спор о «катастрофическом коллапсе» при дообучении на собственных выходах: мелкие модели ≠ крупные.",
  "sampleComments": [
    44873038,
    44873130,
    44873095,
    44873308,
    44872901
  ],
  "inputHash": "c4ea7a272362e346cc016593a4f6b48a7ca30aa6afde332df5802c4a36cac721",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-12T07:25:14.013Z"
}