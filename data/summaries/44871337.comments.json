{
  "id": 44871337,
  "lang": "ru",
  "summary": "- В GLM-4.5 при подсчёте параметров исключены word embeddings и выходной слой, что согласуется с расчётами участников.  \n- Модель вызывает восторг: статья подробно описывает «как», а не только «что»; кодинг-способности ставят её на уровень Sonnet 4, особенно в агент-режимах.  \n- Пользователи отмечают, что Claude всё же лучше справляется с большими контекстами, а GLM-4.5 иногда деградирует при росте объёма кода.  \n- Сообщество радуется Apache-лицензии и надеется в течение пары лет запускать такие модели локально на $2000-станциях.  \n- Некоторые замечают, что Qwen3-Coder всё-таки присутствует в бенчмарках (раздел 4.3.2), но GLM-4.5 чаще выигрывает в агентных циклах.",
  "sampleComments": [
    44874657,
    44874852,
    44871980,
    44871910,
    44874236
  ],
  "inputHash": "f6b9f07637c1e48be098cedef31938774b9abb0a6d8216703f72acb1487406f2",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-12T11:21:05.911Z"
}