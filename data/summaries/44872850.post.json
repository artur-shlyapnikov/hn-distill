{
  "id": 44872850,
  "lang": "ru",
  "summary": "- Исследователи из Университета Аризоны показали: «цепочка мыслей» в LLM — хрупкая иллюзия.  \n- Модель хорошо копирует примеры из обучения, но при малейшем отклонении задачи логика рушится.  \n- Для проверки создали DataAlchemy: обучали крошечные LLM двум простым преобразованиям текста (ROT-шифр и циклический сдвиг), затем давали задания вне этой области.  \n- Даже умеренный сдвиг распределения резко снижал точность, подтверждая, что «рассуждение» — лишь имитация известных шаблонов.",
  "inputHash": "f6a03ccd5a6f00093060d5999cd7346901d66944ca2c8e444f2e4a643955e002",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-12T06:37:21.645Z"
}