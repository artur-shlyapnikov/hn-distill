{
  "id": 44854518,
  "lang": "ru",
  "summary": "LLMs не строят модель мира. Это не значит, что они бесполезны, а лишь то, что они не понимают, как устроена реальность, даже виртуальная.\n\n**Шахматы.** Два года назад я сыграл с LLM: первые ходы она делала уверенно, но уже на 10-м ходе попыталась походить конём, которого не было на доске, и быстро проиграла. Повторил эксперимент сейчас — к 9-му ходу модель теряет позицию. Проанализировав триллион партий, LLM так и не выучила главное: чтобы ходить, нужно знать, где стоят фигуры. Это не требуется для предсказания текста партии.\n\n**Графика.** Спросил, как работает «Normal blending» в Krita. Ответ: «цвет верхнего слоя просто отображается, возможно, с учётом прозрачности, без формул и вычислений».  \nМодель не понимает:\n\n- Цвета в компьютере — это числа.  \n- Любое «влияние» прозрачности — это математическая операция.  \n- Если видно нижний слой, значит, итоговый цвет зависит от обоих слоёв.\n\nМожно заставить LLM процитировать формулу альфа-смешивания, но это лишь показывает, что она умеет подобрать слова, а не понимает смысл.\n\nЛюди тоже могут путаться, но при достаточной мотивации разберутся. У LLM мотивация была: 200 млрд долларов на оборудование.",
  "inputHash": "14b3392a68dfeda3f3d0b4f569d9b537ad92d819c84351ccfa7d2eb77ea61434",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-10T20:29:29.153Z"
}