{
  "id": 44867238,
  "lang": "ru",
  "summary": "- Ollama отказалась от использования llama.cpp как библиотеки и перешла на прямую работу с ggml, что вызывает обвинения в «изобретении велосипеда» и несовместимости с GGUF-моделями.  \n- Разработчики Ollama утверждают, что llama.cpp слишком нестабилен для их целей, поэтому они создали собственную реализацию, но при необходимости всё ещё возвращаются к llama.cpp.  \n- Пользователи жалуются, что из-за форков ggml Ollama не может запускать новые SOTA-модели без конвертации в проприетарный формат.  \n- Часть комментаторов считает это «теневыми» действиями, другие — обычной практикой форка ради быстрой совместимости.",
  "sampleComments": [
    44869466,
    44867259,
    44869432,
    44871237,
    44868084
  ],
  "inputHash": "3b55cd350cfb4a9660db13626f47e876055665018a9595d9cdf503e189744636",
  "model": "moonshotai/kimi-k2:free",
  "createdISO": "2025-08-12T01:56:12.445Z"
}